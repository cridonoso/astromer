{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a3199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.bugstromer import get_ASTROMER, build_input\n",
    "from src.data import pretraining_pipeline\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d0f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 20:20:09.801060: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-19 20:20:09.801124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: f24a753cc649\n",
      "2023-04-19 20:20:09.801133: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: f24a753cc649\n",
      "2023-04-19 20:20:09.801328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
      "2023-04-19 20:20:09.801355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
      "2023-04-19 20:20:09.801362: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
      "2023-04-19 20:20:09.801765: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using PE with c: 2.0\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<src.models.bugstromer.Encoder object at 0x7fbe7f873520> and <src.models.bugstromer.RegLayer object at 0x7fbe7f8738b0>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbe6c600e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 200\n",
    "\n",
    "astromer =  get_ASTROMER(num_layers=2,\n",
    "                         d_model=256,\n",
    "                         num_heads=4,\n",
    "                         dff=128,\n",
    "                         base=1000,\n",
    "\n",
    "                         maxlen=window_size)\n",
    "\n",
    "astromer.load_weights('./weights/weights/macho/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25af227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(1e-3, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "astromer.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554c1d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Repeating dataset x1 times\n",
      "[INFO] Sampling random windows\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/records/macho/'\n",
    "data = dict()\n",
    "for subset in ['test']:\n",
    "    data[subset] = pretraining_pipeline(os.path.join(data_dir, subset), \n",
    "                                        16, window_size, .5, .2, .2,\n",
    "                                        sampling=True, shuffle=True, repeat=1, num_cls=None,\n",
    "                                        normalize='zero-mean', cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57dbfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using PE with c: 2.0\n",
      "    467/Unknown - 35s 73ms/step - loss: 0.1402 - r_square: 0.8082"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mastromer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1715\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1716\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1717\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1718\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "astromer.evaluate(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faaa7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = astromer.fit(data['train'], epochs=1, validation_data=data['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ca5ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "\n",
    "# min_index = tf.argmin(hist.history['val_loss'])\n",
    "# {\n",
    "#  'train_loss':hist.history['loss'][min_index],\n",
    "# 'train_r2':hist.history['r_square'][min_index],\n",
    "# 'val_loss':hist.history['val_loss'][min_index],\n",
    "# 'val_r2':hist.history['val_r_square'][min_index]   \n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "633884a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c6ab8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers.attention import HeadAttentionMulti\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0432b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0 = HeadAttentionMulti(256, 4) # + (mask * -1e9)\n",
    "layer_1 = HeadAttentionMulti(256, 4, mode=1) # input * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98542bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones([2, 5, 1], dtype='float32')\n",
    "mask = np.array([[0, 0, 0, 1, 1], [1, 0, 0, 0, 1]], dtype='float32')[..., None]\n",
    "\n",
    "output_0, weights_0 = layer_0(x, mask)\n",
    "output_1, weights_1 = layer_1(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89c1da31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 5, 5), dtype=float32, numpy=\n",
       " array([[[0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ]],\n",
       " \n",
       "        [[0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ]],\n",
       " \n",
       "        [[0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ]],\n",
       " \n",
       "        [[0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "         [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 256), dtype=float32, numpy=\n",
       " array([[ 0.01728809,  0.08394676,  0.08468733, ...,  0.13319936,\n",
       "          0.01509266, -0.15529563],\n",
       "        [ 0.01728809,  0.08394676,  0.08468733, ...,  0.13319936,\n",
       "          0.01509266, -0.15529563],\n",
       "        [ 0.01728809,  0.08394676,  0.08468733, ...,  0.13319936,\n",
       "          0.01509266, -0.15529563],\n",
       "        [ 0.0172881 ,  0.08394676,  0.08468734, ...,  0.13319936,\n",
       "          0.01509266, -0.15529564],\n",
       "        [ 0.0172881 ,  0.08394676,  0.08468734, ...,  0.13319936,\n",
       "          0.01509266, -0.15529564]], dtype=float32)>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_0[0], output_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1cb8372f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 256), dtype=float32, numpy=\n",
       "array([[2.559998, 2.559998, 2.559998, ..., 2.559998, 2.559998, 2.559998],\n",
       "       [2.559998, 2.559998, 2.559998, ..., 2.559998, 2.559998, 2.559998],\n",
       "       [2.559998, 2.559998, 2.559998, ..., 2.559998, 2.559998, 2.559998],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77812a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 1), dtype=float32, numpy=\n",
       "array([[[0.6619955],\n",
       "        [0.6619955],\n",
       "        [0.6619955],\n",
       "        [0.6619955],\n",
       "        [0.6619955]],\n",
       "\n",
       "       [[0.6619955],\n",
       "        [0.6619955],\n",
       "        [0.6619955],\n",
       "        [0.6619955],\n",
       "        [0.6619955]]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=32, value_dim=32)\n",
    "\n",
    "batch_size = 2\n",
    "x = np.ones([batch_size, 5, 1], dtype='float32')\n",
    "mask = np.array([[0, 0, 0, 1, 1], [1, 0, 0, 0, 1]], dtype='float32')\n",
    "mask = tf.tile(mask, [1, 1, ])\n",
    "\n",
    "layer(x, x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99100972",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b29f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def split_heads( x, batch_size, depth, name='qkv'):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"    \n",
    "    x = tf.reshape(x, (batch_size, -1, num_heads, depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3], name=name)\n",
    "    \n",
    "batch_size = 2\n",
    "x = np.ones([batch_size, 5, 1], dtype='float32')\n",
    "mask = np.array([[0, 0, 0, 1, 1], [1, 0, 0, 0, 1]], dtype='float32')[..., None]\n",
    "\n",
    "num_heads = 2\n",
    "head_dim  = 5\n",
    "d_model = num_heads * head_dim\n",
    "\n",
    "initializer = tf.keras.initializers.Constant(-.1)\n",
    "wq = tf.keras.layers.Dense(d_model, kernel_initializer=initializer, use_bias=False, name='WQ')\n",
    "wk = tf.keras.layers.Dense(d_model, kernel_initializer=initializer, use_bias=False, name='WK')\n",
    "wv = tf.keras.layers.Dense(d_model, kernel_initializer=initializer, use_bias=False, name='WV')\n",
    "dense = tf.keras.layers.Dense(d_model,kernel_initializer=initializer, use_bias=False, name='MixerDense')\n",
    "   \n",
    "q = wq(x)  # (batch_size, seq_len, d_model)\n",
    "k = wk(x)  # (batch_size, seq_len, d_model)\n",
    "v = wv(x)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "q = split_heads(q, batch_size, depth=head_dim, name='Q')  # (batch_size, num_heads, seq_len_q, depth)\n",
    "k = split_heads(k, batch_size, depth=head_dim, name='K')  # (batch_size, num_heads, seq_len_k, depth)\n",
    "v = split_heads(v, batch_size, depth=head_dim, name='V')  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "# scale matmul_qk\n",
    "dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "steps = tf.shape(scaled_attention_logits)[2]\n",
    "mask_rshp = tf.tile(mask, [1,1,steps])\n",
    "mask_rshp += tf.transpose(mask_rshp, [0,2,1])\n",
    "mask_rshp = tf.minimum(1., mask_rshp)\n",
    "mask_rshp = tf.expand_dims(mask_rshp, 1)\n",
    "scaled_attention_logits += (mask_rshp*-1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "086cd950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 5, 5), dtype=float32, numpy=\n",
       "array([[[[ 2.236068e-02,  2.236068e-02,  2.236068e-02, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [ 2.236068e-02,  2.236068e-02,  2.236068e-02, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [ 2.236068e-02,  2.236068e-02,  2.236068e-02, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09]],\n",
       "\n",
       "        [[ 2.236068e-02,  2.236068e-02,  2.236068e-02, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [ 2.236068e-02,  2.236068e-02,  2.236068e-02, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [ 2.236068e-02,  2.236068e-02,  2.236068e-02, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09]]],\n",
       "\n",
       "\n",
       "       [[[-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09,  2.236068e-02,  2.236068e-02,  2.236068e-02,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09,  2.236068e-02,  2.236068e-02,  2.236068e-02,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09,  2.236068e-02,  2.236068e-02,  2.236068e-02,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09]],\n",
       "\n",
       "        [[-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09,  2.236068e-02,  2.236068e-02,  2.236068e-02,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09,  2.236068e-02,  2.236068e-02,  2.236068e-02,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09,  2.236068e-02,  2.236068e-02,  2.236068e-02,\n",
       "          -1.000000e+09],\n",
       "         [-1.000000e+09, -1.000000e+09, -1.000000e+09, -1.000000e+09,\n",
       "          -1.000000e+09]]]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_attention_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ed1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
