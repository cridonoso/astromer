{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b263b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cridonoso/Documents/astromer-code\n"
     ]
    }
   ],
   "source": [
    "cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5009934d",
   "metadata": {},
   "source": [
    "# Using ASTROMER as layer's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb7fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 15:21:12.783877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-02 15:21:12.783896: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, LSTM, LayerNormalization\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "from presentation.experiments.clf.classifiers import build_mlp_att, build_lstm_att\n",
    "from core.data import load_dataset, inference_pipeline, pretraining_pipeline\n",
    "from core.astromer import ASTROMER\n",
    "from core.training.scheduler import CustomSchedule\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7fe5d",
   "metadata": {},
   "source": [
    "First we load ASTROMER pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc3d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 15:08:15.075368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-02 15:08:15.075409: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-02 15:08:15.075426: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (appa): /proc/driver/nvidia/version does not exist\n",
      "2022-04-02 15:08:15.075812: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "astromer = ASTROMER()\n",
    "astromer.load_weights('./runs/macho/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9345a",
   "metadata": {},
   "source": [
    "First we load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49494d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "max_obs    = 200\n",
    "datapath   = './data/records/alcock/fold_0/alcock/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03a291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cep_0</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cep_1</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC</td>\n",
       "      <td>6724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LPV</td>\n",
       "      <td>2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RRab</td>\n",
       "      <td>7297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RRc</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  size\n",
       "0  Cep_0  1082\n",
       "1  Cep_1   583\n",
       "2     EC  6724\n",
       "3    LPV  2946\n",
       "4   RRab  7297\n",
       "5    RRc  1662"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = pd.read_csv('{}/objects.csv'.format(datapath))\n",
    "n_classes = catalog.shape[0]\n",
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee957e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 15:21:21.259668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-02 15:21:21.259726: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-02 15:21:21.259740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (appa): /proc/driver/nvidia/version does not exist\n",
      "2022-04-02 15:21:21.259950: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "traindata = load_dataset(os.path.join(datapath, 'train'), repeat=1, shuffle=True)\n",
    "valdata   = load_dataset(os.path.join(datapath, 'val'), repeat=1)\n",
    "testdata  = load_dataset(os.path.join(datapath, 'test'), repeat=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a4eea",
   "metadata": {},
   "source": [
    "To evaluate use `pretraining_pipeline()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e30a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pretraining mode. Random 200-len windows\n"
     ]
    }
   ],
   "source": [
    "test_batches = pretraining_pipeline(testdata, batch_size=batch_size, max_obs=max_obs, \n",
    "                                    msk_frac=0.5, rnd_frac=0.2, same_frac= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16783d3",
   "metadata": {},
   "source": [
    "Before evaluating ASTROMER we need to compile the model. The `.compile()` function automatically loads the custom losses used during pre-training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cce0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "astromer.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c627330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 0.1686 - r2: 0.6605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1841157078742981, 0.685067892074585]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astromer.evaluate(test_batches.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81ed33",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5be8b8",
   "metadata": {},
   "source": [
    "When using `inference_pipeline()` the output is the classification labels instead of the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71cc080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inference mode. Cutting 200-len windows\n",
      "[INFO] Inference mode. Cutting 200-len windows\n"
     ]
    }
   ],
   "source": [
    "train_batches = inference_pipeline(traindata,\n",
    "                                   batch_size=batch_size,\n",
    "                                   max_obs=max_obs,\n",
    "                                   n_classes=n_classes,\n",
    "                                   shuffle=True)\n",
    "val_batches   = inference_pipeline(valdata,\n",
    "                                   batch_size=batch_size,\n",
    "                                   max_obs=max_obs,\n",
    "                                   n_classes=n_classes,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01a00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70f71e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected begin and size arguments to be 1-D tensors of size 0, but got shapes [1] and [1] instead.\n\t [[{{function_node __inference_get_masked_387}}{{node get_masked/Slice_1}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y  \u001b[38;5;129;01min\u001b[39;00m train_batches:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:836\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    835\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:819\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 819\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:2923\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2921\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   2922\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2923\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   2925\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7185\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7186\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected begin and size arguments to be 1-D tensors of size 0, but got shapes [1] and [1] instead.\n\t [[{{function_node __inference_get_masked_387}}{{node get_masked/Slice_1}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for x, y  in train_batches:\n",
    "    print(y)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785c2b3",
   "metadata": {},
   "source": [
    "Now we use the encoder layer from the pretrained ASTROMER instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9fcb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "astromer = ASTROMER()\n",
    "astromer.load_weights('./runs/macho/')\n",
    "encoder = astromer.get_layer('encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d96c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie  = Input(shape=(max_obs, 1), batch_size=None, name='input')\n",
    "times  = Input(shape=(max_obs, 1), batch_size=None, name='times')\n",
    "mask   = Input(shape=(max_obs, 1), batch_size=None, name='mask')\n",
    "placeholder = {'input':serie, 'mask_in':mask, 'times':times}\n",
    "\n",
    "mask_rnn = tf.cast(1.-placeholder['mask_in'][...,0], dtype=tf.bool)\n",
    "\n",
    "x = encoder(placeholder, training=False)\n",
    "x = LSTM(256, dropout=.3, return_sequences=True)(x, mask=mask_rnn)\n",
    "x = LayerNormalization()(x)\n",
    "x = LSTM(256, dropout=.3)(x, mask=mask_rnn)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dense(n_classes)(x)\n",
    "\n",
    "classifier = Model(inputs=placeholder, outputs=x, name=\"LSTMATT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fa955da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTMATT\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " mask (InputLayer)              [(None, 200, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 200)         0           ['mask[0][0]']                   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " input (InputLayer)             [(None, 200, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " times (InputLayer)             [(None, 200, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLambda  (None, 200)         0           ['tf.__operators__.getitem_4[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " encoder (Encoder)              (None, None, 256)    660736      ['input[0][0]',                  \n",
      "                                                                  'mask[0][0]',                   \n",
      "                                                                  'times[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.cast_4 (TFOpLambda)         (None, 200)          0           ['tf.math.subtract_4[0][0]']     \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  (None, None, 256)    525312      ['encoder[1][0]',                \n",
      "                                                                  'tf.cast_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, None, 256)   512         ['lstm_8[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  (None, 256)          525312      ['layer_normalization_36[0][0]', \n",
      "                                                                  'tf.cast_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 256)         512         ['lstm_9[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 6)            1542        ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,713,926\n",
      "Trainable params: 1,713,926\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8daef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "classifier.compile(optimizer='adam',\n",
    "                   loss=CategoricalCrossentropy(from_logits=True),\n",
    "                   metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fec9fa",
   "metadata": {},
   "source": [
    "we use early stopping callback on our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d96ce407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "estop = EarlyStopping(monitor='val_loss',\n",
    "                      min_delta=0,\n",
    "                      patience=40,\n",
    "                      verbose=0,\n",
    "                      mode='auto',\n",
    "                      baseline=None,\n",
    "                      restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d892c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nExpected begin and size arguments to be 1-D tensors of size 0, but got shapes [1] and [1] instead.\n\t [[{{node get_masked/Slice_1}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_68834]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mestop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf2/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nExpected begin and size arguments to be 1-D tensors of size 0, but got shapes [1] and [1] instead.\n\t [[{{node get_masked/Slice_1}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_68834]"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(train_batches,\n",
    "                         epochs=10000,\n",
    "                         callbacks=[estop],\n",
    "                         validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46b958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ba10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
