{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/dmoreno2016\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 10:25:53.860279: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-23 10:25:55.249474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_q: (8, 8)\n",
      "w_k: (8, 8)\n",
      "e_x: (5, 8)\n",
      "bq: (8,)\n",
      "bk: (8,)\n"
     ]
    }
   ],
   "source": [
    "def split_heads(x, num_heads, depth, name='qkv'):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    print(x.shape)\n",
    "    x = tf.reshape(x, (-1, num_heads, depth))\n",
    "    print(x.shape)\n",
    "    return tf.transpose(x, perm=[1, 0, 2], name=name)\n",
    "\n",
    "d_model = 8\n",
    "num_head = 4\n",
    "largo = 5\n",
    "\n",
    "depth = d_model // num_head\n",
    "\n",
    "\n",
    "w_q = tf.constant([[1,4,6,3,2,6,2,1],\n",
    "                   [2,5,1,2,6,8,6,9],\n",
    "                   [3,3,2,1,3,6,3,8],\n",
    "                   [2,4,1,6,8,2,6,9],\n",
    "                   [3,5,8,3,8,0,4,3],                   \n",
    "                   [5,7,8,2,3,5,4,3],\n",
    "                   [4,3,1,4,3,0,5,2],\n",
    "                   [5,5,5,5,4,9,3,4]]) \n",
    "\n",
    "w_k = tf.constant([[7,5,4,2,1,0,9,2],\n",
    "                   [5,7,8,2,3,5,4,3],\n",
    "                   [4,3,1,4,3,0,5,2],\n",
    "                   [5,5,5,5,4,9,3,4],\n",
    "                   [4,3,6,8,5,6,5,6],                   \n",
    "                   [3,3,2,1,3,6,3,8],\n",
    "                   [2,4,1,6,8,2,6,9],\n",
    "                   [3,5,8,3,8,0,4,3]]) \n",
    "\n",
    "e_x = tf.constant([[7,2,3,2,1,5,7,3],\n",
    "                   [3,5,4,2,1,5,7,2],\n",
    "                   [2,1,4,6,2,7,9,3],\n",
    "                   [2,4,1,5,7,4,6,8],\n",
    "                   [1,4,7,8,5,3,6,9]]) # 2 x 3\n",
    "\n",
    "\n",
    "bq = tf.constant([3,2,5,2,5,7,8,5])\n",
    "bk = tf.constant([2,1,7,2,4,3,1,2])\n",
    "\n",
    "print('w_q: {}'.format(w_q.shape))\n",
    "print('w_k: {}'.format(w_k.shape))\n",
    "print('e_x: {}'.format(e_x.shape))\n",
    "print('bq: {}'.format(bq.shape))\n",
    "print('bk: {}'.format(bk.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8)\n",
      "(5, 4, 2)\n",
      "(5, 8)\n",
      "(5, 4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5, 5), dtype=int32, numpy=\n",
       "array([[[29540, 28231, 30408, 35630, 41174],\n",
       "        [29150, 27844, 29994, 35138, 40610],\n",
       "        [35135, 33507, 36105, 42271, 48871],\n",
       "        [38995, 37249, 40125, 47007, 54327],\n",
       "        [42940, 40976, 44148, 51700, 59764]],\n",
       "\n",
       "       [[24485, 24514, 28452, 40485, 44136],\n",
       "        [20761, 20776, 24268, 34223, 37380],\n",
       "        [27034, 27041, 31788, 44427, 48618],\n",
       "        [32822, 32844, 38392, 54086, 59088],\n",
       "        [33620, 33614, 39752, 55090, 60396]],\n",
       "\n",
       "       [[26267, 28352, 37890, 42694, 46633],\n",
       "        [27230, 29270, 39036, 44056, 48184],\n",
       "        [30359, 32234, 42722, 48450, 53199],\n",
       "        [38875, 41260, 54674, 62014, 68101],\n",
       "        [45465, 48450, 64334, 72854, 79901]],\n",
       "\n",
       "       [[38405, 35576, 42518, 43182, 46345],\n",
       "        [44233, 41174, 49471, 50066, 53574],\n",
       "        [50538, 46950, 56289, 57048, 61119],\n",
       "        [54531, 50690, 60813, 61606, 65978],\n",
       "        [69332, 64916, 78494, 79104, 84346]]], dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.matmul(e_x, w_q) + bq\n",
    "k = tf.matmul(e_x, w_k) + bk\n",
    "\n",
    "q = split_heads(q, num_head, depth)\n",
    "k = split_heads(k, num_head, depth)\n",
    "\n",
    "result_1 = tf.matmul(q, k, transpose_b=True)\n",
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       "array([[2],\n",
       "       [1],\n",
       "       [7]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(bk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[20, 47, 50],\n",
       "       [25, 49, 31]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5299, 6353],\n",
       "       [4922, 5902]], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.matmul(e_x, w_q)\n",
    "k = tf.matmul(e_x, w_k)\n",
    "\n",
    "qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "cte_1 = tf.matmul(q, tf.expand_dims(bk, axis=1))\n",
    "cte_2 = tf.matmul(k, tf.expand_dims(bq, axis=1))\n",
    "\n",
    "bb = tf.matmul(tf.expand_dims(bk, axis=0), tf.expand_dims(bq, axis=1))\n",
    "\n",
    "qk + cte_1 + cte_2 + bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[3, 2, 5]], dtype=int32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(bq, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[31, 49, 31],\n",
       "       [38, 61, 38]], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 1, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8)\n",
      "(5, 4, 2)\n",
      "(5, 8)\n",
      "(5, 4, 2)\n",
      "(1, 8)\n",
      "(1, 4, 2)\n",
      "(8, 1)\n",
      "(1, 4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5, 5), dtype=int32, numpy=\n",
       "array([[[29540, 28231, 30408, 35630, 41174],\n",
       "        [29150, 27844, 29994, 35138, 40610],\n",
       "        [35135, 33507, 36105, 42271, 48871],\n",
       "        [38995, 37249, 40125, 47007, 54327],\n",
       "        [42940, 40976, 44148, 51700, 59764]],\n",
       "\n",
       "       [[24485, 24514, 28452, 40485, 44136],\n",
       "        [20761, 20776, 24268, 34223, 37380],\n",
       "        [27034, 27041, 31788, 44427, 48618],\n",
       "        [32822, 32844, 38392, 54086, 59088],\n",
       "        [33620, 33614, 39752, 55090, 60396]],\n",
       "\n",
       "       [[26267, 28352, 37890, 42694, 46633],\n",
       "        [27230, 29270, 39036, 44056, 48184],\n",
       "        [30359, 32234, 42722, 48450, 53199],\n",
       "        [38875, 41260, 54674, 62014, 68101],\n",
       "        [45465, 48450, 64334, 72854, 79901]],\n",
       "\n",
       "       [[38405, 35576, 42518, 43182, 46345],\n",
       "        [44233, 41174, 49471, 50066, 53574],\n",
       "        [50538, 46950, 56289, 57048, 61119],\n",
       "        [54531, 50690, 60813, 61606, 65978],\n",
       "        [69332, 64916, 78494, 79104, 84346]]], dtype=int32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.matmul(e_x, w_q)\n",
    "k = tf.matmul(e_x, w_k)\n",
    "q = split_heads(q, num_head, depth)\n",
    "k = split_heads(k, num_head, depth)\n",
    "\n",
    "qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "bias_q = split_heads(tf.expand_dims(bq, axis=1), num_head, depth)\n",
    "bias_k = split_heads(tf.expand_dims(bk, axis=1), num_head, depth)\n",
    "\n",
    "cte_1 = tf.matmul(q, bias_k, transpose_b=True)\n",
    "cte_2 = tf.matmul(bias_q, k, transpose_b=True)\n",
    "bb = tf.matmul(bias_k, bias_q, transpose_b=True)\n",
    "\n",
    "result_2_corrected = qk + cte_1 + cte_2 + bb\n",
    "result_2_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5299, 6433],\n",
       "       [4842, 5902]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FORMA CORRECTA DE HACERLO SIN LA OTRA DIMENSION DEL SPLIT HEAD\n",
    "\n",
    "q = tf.matmul(e_x, w_q)\n",
    "k = tf.matmul(e_x, w_k)\n",
    "qk = tf.matmul(q, k, transpose_b=True)\n",
    "cte_1 = tf.matmul(q, tf.expand_dims(bk, axis=1))\n",
    "cte_2 = tf.matmul(tf.expand_dims(bq, axis=0), k, transpose_b=True)\n",
    "bb = tf.matmul(tf.expand_dims(bk, axis=0), tf.expand_dims(bq, axis=1))\n",
    "result_2_corrected = qk + cte_1 + cte_2 + bb\n",
    "result_2_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 54, 104,  90],\n",
       "       [ 46,  96,  79]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul((e_x + pe_t), w_q) + bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = tf.matmul(e_x, w_q)\n",
    "b = tf.matmul(pe_t, w_q)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[3, 6, 8],\n",
       "       [4, 7, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
