{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/dmoreno2016/ASTROMER/astromer_pe_main/astromer\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 05:06:18.119681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-06 05:06:19.458329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from src.data.record import deserialize\n",
    "from src.data.zero import to_windows\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path_dataset):\n",
    "    rec_paths = []\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        if folder.endswith('.csv'):\n",
    "            continue\n",
    "        for x in os.listdir(os.path.join(path_dataset, folder)):\n",
    "            rec_paths.append(os.path.join(path_dataset, folder, x))\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(rec_paths)    \n",
    "    dataset = dataset.map(deserialize)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_windows(dataset, window_size, sampling):\n",
    "    \n",
    "    dataset = to_windows(dataset,\n",
    "                        window_size=window_size,\n",
    "                        sampling=sampling)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 05:06:24.715316: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Macho unlabeled\n",
    "dataset_macho_unl = get_dataset(path_dataset='./data/records/macho_clean/train')\n",
    "\n",
    "# Macho labeled\n",
    "dataset_macho_lab = get_dataset(path_dataset='./data/records/alcock/fold_0/alcock_50/train')\n",
    "\n",
    "# Atlas\n",
    "dataset_atlas = get_dataset(path_dataset='./data/records/atlas/fold_0/atlas_50/train')\n",
    "\n",
    "# Ogle\n",
    "dataset_ogle = get_dataset(path_dataset='./data/records/ogle/fold_0/ogle_50/train')\n",
    "\n",
    "# Kepler\n",
    "dataset_kepler = get_dataset(path_dataset='./data/records/kepler/fold_0/kepler_50/train')\n",
    "dataset_kepler_alcock = get_dataset(path_dataset='./data/records/kepler_alcock_linear/fold_0/kepler_alcock_linear_50/train')\n",
    "dataset_kepler_atlas = get_dataset(path_dataset='./data/records/kepler_atlas_linear/fold_0/kepler_atlas_linear_50/train')\n",
    "dataset_kepler_ogle = get_dataset(path_dataset='./data/records/kepler_ogle_linear/fold_0/kepler_ogle_linear_50/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE WINDOWS\n",
    "window_size = 200\n",
    "sampling = False\n",
    "\n",
    "# Macho unlabeled\n",
    "dataset_macho_unl = get_windows(dataset_macho_unl, window_size=window_size, sampling=sampling)\n",
    "\n",
    "# Macho labeled\n",
    "dataset_macho_lab = get_windows(dataset_macho_lab, window_size=window_size, sampling=sampling)\n",
    "\n",
    "# Atlas\n",
    "dataset_atlas = get_windows(dataset_atlas, window_size=window_size, sampling=sampling)\n",
    "\n",
    "# Ogle\n",
    "dataset_ogle = get_windows(dataset_ogle, window_size=window_size, sampling=sampling)\n",
    "\n",
    "# Kepler\n",
    "dataset_kepler = get_windows(dataset_kepler, window_size=window_size, sampling=sampling)\n",
    "dataset_kepler_alcock = get_windows(dataset_kepler_alcock, window_size=window_size, sampling=sampling)\n",
    "dataset_kepler_atlas = get_windows(dataset_kepler_atlas, window_size=window_size, sampling=sampling)\n",
    "dataset_kepler_ogle = get_windows(dataset_kepler_ogle, window_size=window_size, sampling=sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days_by_windows(dataset):\n",
    "    days_by_windows = []\n",
    "    for i, lc_info in enumerate(dataset):\n",
    "        lc_data = lc_info['input']\n",
    "        try:\n",
    "            days_by_windows.append(lc_data[-1][0] - lc_data[0][0].numpy())\n",
    "        except:\n",
    "            print(lc_data.shape)\n",
    "\n",
    "        if i > 50000:\n",
    "            break\n",
    "\n",
    "    return days_by_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 05:11:15.529465: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index -1 of dimension 0 out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "macho_unl_days_windows = get_days_by_windows(dataset_macho_unl)\n",
    "macho_lab_days_windows = get_days_by_windows(dataset_macho_lab)\n",
    "atlas_days_windows = get_days_by_windows(dataset_atlas)\n",
    "ogle_days_windows = get_days_by_windows(dataset_ogle)\n",
    "kepler_days_windows = get_days_by_windows(dataset_kepler)\n",
    "kepler_alcock_days_windows = get_days_by_windows(dataset_kepler_alcock)\n",
    "kepler_atlas_days_windows = get_days_by_windows(dataset_kepler_atlas)\n",
    "kepler_ogle_days_windows = get_days_by_windows(dataset_kepler_ogle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(days_by_windows, name_dataset):\n",
    "    print('{}'.format(name_dataset.upper()))\n",
    "    print('- Median: {:.2f}'.format(np.median(days_by_windows)))\n",
    "    print('- Mean: {:.2f}'.format(np.mean(days_by_windows)))\n",
    "    print('- Std: {:.2f}\\n'.format(np.std(days_by_windows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days saved in each generated window:\n",
      "\n",
      "MACHO UNLABELED\n",
      "- Median: 658.14\n",
      "- Mean: 724.77\n",
      "- Std: 555.84\n",
      "\n",
      "MACHO LABELED\n",
      "- Median: 678.42\n",
      "- Mean: 801.60\n",
      "- Std: 483.85\n",
      "\n",
      "ATLAS\n",
      "- Median: 577.70\n",
      "- Mean: 599.85\n",
      "- Std: 87.95\n",
      "\n",
      "OGLE\n",
      "- Median: 775.92\n",
      "- Mean: 752.82\n",
      "- Std: 508.14\n",
      "\n",
      "KEPLER\n",
      "- Median: 4.11\n",
      "- Mean: 4.92\n",
      "- Std: 7.96\n",
      "\n",
      "KEPLER-ALCOCK\n",
      "- Median: 801.27\n",
      "- Mean: 815.16\n",
      "- Std: 136.71\n",
      "\n",
      "KEPLER-ATLAS\n",
      "- Median: 893.68\n",
      "- Mean: 909.47\n",
      "- Std: 235.76\n",
      "\n",
      "KEPLER-OGLE\n",
      "- Median: 708.06\n",
      "- Mean: 727.16\n",
      "- Std: 181.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of days saved in each generated window:\\n')\n",
    "print_stats(macho_unl_days_windows, 'Macho Unlabeled')\n",
    "print_stats(macho_lab_days_windows, 'Macho Labeled')\n",
    "print_stats(atlas_days_windows, 'Atlas')\n",
    "print_stats(ogle_days_windows, 'Ogle')\n",
    "print_stats(kepler_days_windows, 'Kepler')\n",
    "print_stats(kepler_alcock_days_windows, 'Kepler-Alcock')\n",
    "print_stats(kepler_atlas_days_windows, 'Kepler-Atlas')\n",
    "print_stats(kepler_ogle_days_windows, 'Kepler-Ogle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHO labeled: 0.9701078534126282\n",
      "ATLAS: 1.139237642288208\n",
      "OGLE: 0.8482018709182739\n",
      "KEPLER: 160.15493774414062\n",
      "KEPLER-ALCOCK: 0.821365475654602\n",
      "KEPLER-ATLAS : 0.7364314794540405\n",
      "KEPLER-OGLE: 0.9294870495796204\n"
     ]
    }
   ],
   "source": [
    "print('MACHO labeled: {}'.format(np.median(macho_unl_days_windows) / np.median(macho_lab_days_windows)))\n",
    "print('ATLAS: {}'.format(np.median(macho_unl_days_windows) / np.median(atlas_days_windows)))\n",
    "print('OGLE: {}'.format(np.median(macho_unl_days_windows) / np.median(ogle_days_windows)))\n",
    "print('KEPLER: {}'.format(np.median(macho_unl_days_windows) / np.median(kepler_days_windows)))\n",
    "print('KEPLER-ALCOCK: {}'.format(np.median(macho_unl_days_windows) / np.median(kepler_alcock_days_windows)))\n",
    "print('KEPLER-ATLAS : {}'.format(np.median(macho_unl_days_windows) / np.median(kepler_atlas_days_windows)))\n",
    "print('KEPLER-OGLE: {}'.format(np.median(macho_unl_days_windows) / np.median(kepler_ogle_days_windows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHO labeled: 0.90\n",
      "ATLAS: 1.21\n",
      "OGLE: 0.96\n",
      "KEPLER: 147.35\n",
      "KEPLER-ALCOCK: 0.89\n",
      "KEPLER-ATLAS : 0.80\n",
      "KEPLER-OGLE: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('MACHO labeled: {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(macho_lab_days_windows)))\n",
    "print('ATLAS: {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(atlas_days_windows)))\n",
    "print('OGLE: {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(ogle_days_windows)))\n",
    "print('KEPLER: {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(kepler_days_windows)))\n",
    "print('KEPLER-ALCOCK: {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(kepler_alcock_days_windows)))\n",
    "print('KEPLER-ATLAS : {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(kepler_atlas_days_windows)))\n",
    "print('KEPLER-OGLE: {:.2f}'.format(np.mean(macho_unl_days_windows) / np.mean(kepler_ogle_days_windows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 01:13:58.734749: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using masking...\n",
      "Using masking...\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "\n",
    "Testing the pretrained model in other datasets \n",
    "\n",
    "'''\n",
    "\n",
    "from src.models.astromer_1 import get_ASTROMER, test_step\n",
    "from src.data import load_data\n",
    "from src.data.zero import pretraining_pipeline\n",
    "\n",
    "import toml\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_metrics(**kwargs):\n",
    "\tmerged = {}\n",
    "\tfor key, value in kwargs.items():\n",
    "\t\tfor subkey, subvalue in value.items():\n",
    "\t\t\tmerged['{}_{}'.format(key, subkey)] = subvalue\n",
    "\treturn merged\n",
    "\n",
    "\n",
    "def average_logs(logs):\n",
    "\tN = len(logs)\n",
    "\taverage_dict = {}\n",
    "\tfor key in logs[0].keys():\n",
    "\t\tsum_log = sum(log[key] for log in logs)\n",
    "\t\taverage_dict[key] = float(sum_log/N)\n",
    "\treturn average_dict\n",
    "\n",
    "###########################################################\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "#ds_names = ['alcock', 'ogle', 'atlas']\n",
    "#ds_names = ['kepler', 'kepler_alcock_linear', 'kepler_atlas_linear', 'kepler_ogle_linear']\n",
    "#ds_names = ['alcock', 'ogle', 'atlas', 'kepler', 'kepler_alcock_linear', 'kepler_atlas_linear', 'kepler_ogle_linear']\n",
    "ds_names = ['kepler']\n",
    "\n",
    "folds = [0, 1, 2]\n",
    "spc_list = [50]\n",
    "#spc_list = ['all']\n",
    "\n",
    "ROOT = './presentation/experiments/astromer_1_pe'\n",
    "pt_folder = 'results/pretraining/P02R01/pretrained_weights'\n",
    "\n",
    "test_step_fn = test_step\n",
    "\n",
    "with open('{}/{}/config.toml'.format(ROOT, pt_folder), mode=\"r\") as fp:\n",
    "    config = toml.load(fp)\n",
    "\n",
    "with open('{}/{}/pe_config.toml'.format(ROOT, pt_folder), mode=\"r\") as fp:\n",
    "    pe_config = toml.load(fp)\n",
    "\n",
    "astromer = get_ASTROMER(num_layers=config['num_layers'],\n",
    "                        num_heads=config['num_heads'],\n",
    "                        head_dim=config['head_dim'],\n",
    "                        mixer_size=config['mixer'],\n",
    "                        dropout=config['dropout'],\n",
    "                        pe_type=config['pe_type'],\n",
    "                        pe_config=pe_config,\n",
    "                        window_size=config['window_size'],\n",
    "                        encoder_mode=config['encoder_mode'],\n",
    "                        average_layers=config['avg_layers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "astromer.get_layer('encoder').data_name = 'marti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marti'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astromer.get_layer('encoder').data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "astromer.get_layer('encoder').data_name= 'perra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perra'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astromer.get_layer('encoder').data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
