{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 01:56:07.664429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 01:56:08.537270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import toml\n",
    "import os\n",
    "\n",
    "from src.models.astromer_1 import get_ASTROMER\n",
    "from src.data.record import deserialize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset):\n",
    "    list_data_lcs = []\n",
    "\n",
    "    for lc_info in dataset:\n",
    "        np_lc = lc_info['input'].numpy()\n",
    "        np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "        data = {'lcid': lc_info['lcid'].numpy(), \n",
    "                'lc_data': [np_lc],\n",
    "                'label': lc_info['label'].numpy()}  \n",
    "\n",
    "        list_data_lcs.append(pd.DataFrame(data))\n",
    "\n",
    "        if np_lc.shape[0] < 200:\n",
    "            print(lc_info['lcid'].numpy())\n",
    "\n",
    "    list_data_lcs = pd.concat(list_data_lcs)\n",
    "    return list_data_lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = './data/records/alcock/fold_0/alcock_20/train'\n",
    "\n",
    "batch_size = 16\n",
    "probed = 0.4\n",
    "random_same = 0.2 \n",
    "window_size = 200 \n",
    "nsp_prob = .5\n",
    "repeat = 1 \n",
    "sampling = False\n",
    "shuffle = False\n",
    "njobs = None\n",
    "num_cls = None\n",
    "test_mode = False\n",
    "off_nsp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 01:56:09.733367: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "rec_paths = []\n",
    "for folder in os.listdir(path_dataset):\n",
    "    if folder.endswith('.csv'):\n",
    "        continue\n",
    "    for x in os.listdir(os.path.join(path_dataset, folder)):\n",
    "        rec_paths.append(os.path.join(path_dataset, folder, x))\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(rec_paths)    \n",
    "dataset = dataset.map(deserialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat(repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ParallelMapDataset element_spec={'lcid': TensorSpec(shape=(), dtype=tf.string, name=None), 'length': TensorSpec(shape=(), dtype=tf.int32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int32, name=None), 'input': TensorSpec(shape=(None, None), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza correctamente el sampling \n",
    "def sample_lc(sample, max_obs, binary=True):\n",
    "\t'''\n",
    "\tSample a random window of \"max_obs\" observations from the input sequence\n",
    "\t'''\n",
    "\tif binary:\n",
    "\t\tinput_dict = deserialize(sample)\n",
    "\telse:\n",
    "\t\tinput_dict = sample\n",
    "\n",
    "\tserie_len = tf.shape(input_dict['input'])[0]\n",
    "\n",
    "\tpivot = 0\n",
    "\tif tf.greater(serie_len, max_obs):\n",
    "\t\tpivot = tf.random.uniform([],\n",
    "\t\t\t\t\t\t\t\t  minval=0,\n",
    "\t\t\t\t\t\t\t\t  maxval=serie_len-max_obs+1,\n",
    "\t\t\t\t\t\t\t\t  dtype=tf.int32)\n",
    "\n",
    "\t\tinput_dict['input'] = tf.slice(input_dict['input'], [pivot,0], [max_obs, -1]) # input_dict['input'][pivot:max_obs, :-1]\n",
    "\telse:\n",
    "\t\tinput_dict['input'] = tf.slice(input_dict['input'], [0,0], [serie_len, -1])\n",
    "\n",
    "\treturn input_dict\n",
    "\n",
    "samples_dataset = dataset.map(lambda x: sample_lc(x,\n",
    "                                          max_obs=window_size,\n",
    "                                          binary=False),\n",
    "                                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "samples_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lc_info in dataset:\n",
    "    np_lc = lc_info['input'].numpy()\n",
    "    np_lc = np_lc[np_lc[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_lc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([200, 200, 200, 200], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_window(sequence, length, pivot, max_obs):\n",
    "\tif length-pivot > max_obs:\n",
    "\t\tsliced = tf.slice(sequence, [pivot, 0], [max_obs, -1])\n",
    "\telse:\n",
    "\t\tsliced = tf.slice(sequence, [pivot, 0], [-1, -1])\n",
    "\t\t\n",
    "\treturn sliced\n",
    "\n",
    "max_obs = 200\n",
    "pivots = tf.tile([max_obs], [tf.cast(np_lc.shape[0]/max_obs, tf.int32)])\n",
    "pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(sequence, length, pivot, split_size):\n",
    "    if length - pivot > split_size:\n",
    "        sliced = tf.slice(sequence, [pivot, 0], [split_size, -1])\n",
    "    else:\n",
    "        sliced = tf.slice(sequence, [pivot, 0], [-1, -1])\n",
    "        \n",
    "    return sliced\n",
    "\n",
    "pivots = tf.cumsum(split_sizes) # Calcula los pivotes basados en los tamaños de división\n",
    "\n",
    "splits = tf.map_fn(lambda x: get_window(np_lc, np_lc.shape[0], x, split_sizes[x]), tf.range(len(split_sizes)),\n",
    "                    infer_shape=False,\n",
    "                    fn_output_signature=(tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 200, 3), dtype=float32, numpy=\n",
       "array([[[ 4.9162766e+04, -6.8810000e+00,  2.5000000e-02],\n",
       "        [ 4.9163379e+04, -6.8230000e+00,  1.2000000e-02],\n",
       "        [ 4.9164379e+04, -6.8839998e+00,  1.5000000e-02],\n",
       "        ...,\n",
       "        [ 4.9538746e+04, -6.8470001e+00,  2.2000000e-02],\n",
       "        [ 4.9540730e+04, -6.8790002e+00,  1.6000001e-02],\n",
       "        [ 4.9541805e+04, -6.8699999e+00,  8.0000004e-03]],\n",
       "\n",
       "       [[ 4.9162766e+04, -6.8810000e+00,  2.5000000e-02],\n",
       "        [ 4.9163379e+04, -6.8230000e+00,  1.2000000e-02],\n",
       "        [ 4.9164379e+04, -6.8839998e+00,  1.5000000e-02],\n",
       "        ...,\n",
       "        [ 4.9538746e+04, -6.8470001e+00,  2.2000000e-02],\n",
       "        [ 4.9540730e+04, -6.8790002e+00,  1.6000001e-02],\n",
       "        [ 4.9541805e+04, -6.8699999e+00,  8.0000004e-03]],\n",
       "\n",
       "       [[ 4.9162766e+04, -6.8810000e+00,  2.5000000e-02],\n",
       "        [ 4.9163379e+04, -6.8230000e+00,  1.2000000e-02],\n",
       "        [ 4.9164379e+04, -6.8839998e+00,  1.5000000e-02],\n",
       "        ...,\n",
       "        [ 4.9538746e+04, -6.8470001e+00,  2.2000000e-02],\n",
       "        [ 4.9540730e+04, -6.8790002e+00,  1.6000001e-02],\n",
       "        [ 4.9541805e+04, -6.8699999e+00,  8.0000004e-03]],\n",
       "\n",
       "       [[ 4.9162766e+04, -6.8810000e+00,  2.5000000e-02],\n",
       "        [ 4.9163379e+04, -6.8230000e+00,  1.2000000e-02],\n",
       "        [ 4.9164379e+04, -6.8839998e+00,  1.5000000e-02],\n",
       "        ...,\n",
       "        [ 4.9538746e+04, -6.8470001e+00,  2.2000000e-02],\n",
       "        [ 4.9540730e+04, -6.8790002e+00,  1.6000001e-02],\n",
       "        [ 4.9541805e+04, -6.8699999e+00,  8.0000004e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_window(sequence, length, pivot, max_obs):\n",
    "    def fn_true():\n",
    "        return tf.slice(sequence, [pivot, 0], [max_obs, -1])\n",
    "\n",
    "    def fn_false():\n",
    "        return tf.slice(sequence, [pivot, 0], [-1, -1])\n",
    "\n",
    "    return tf.cond(length - pivot > max_obs, fn_true, fn_false)\n",
    "\n",
    "max_obs = 200\n",
    "pivots = tf.tile([max_obs], [tf.cast(np_lc.shape[0] // max_obs, tf.int32)])\n",
    "\n",
    "splits = tf.map_fn(lambda x: get_window(np_lc, np_lc.shape[0], x, max_obs), pivots,\n",
    "                    infer_shape=False,\n",
    "                    fn_output_signature=(tf.float32))\n",
    "\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9162766e+04, -6.8810000e+00,  2.5000000e-02],\n",
       "       [ 4.9163379e+04, -6.8230000e+00,  1.2000000e-02],\n",
       "       [ 4.9164379e+04, -6.8839998e+00,  1.5000000e-02],\n",
       "       [ 4.9169820e+04, -6.8130002e+00,  1.5000000e-02],\n",
       "       [ 4.9172375e+04, -6.8880000e+00,  2.0000000e-02],\n",
       "       [ 4.9178773e+04, -6.8490000e+00,  4.1999999e-02],\n",
       "       [ 4.9179730e+04, -6.8189998e+00,  2.0000000e-02],\n",
       "       [ 4.9180699e+04, -6.8660002e+00,  1.7999999e-02],\n",
       "       [ 4.9181684e+04, -6.8779998e+00,  2.0000000e-02],\n",
       "       [ 4.9182785e+04, -6.9460001e+00,  1.5000000e-02],\n",
       "       [ 4.9183691e+04, -6.8480000e+00,  3.0999999e-02],\n",
       "       [ 4.9184664e+04, -6.8880000e+00,  2.2000000e-02],\n",
       "       [ 4.9185383e+04, -6.8730001e+00,  1.4000000e-02],\n",
       "       [ 4.9188668e+04, -6.9089999e+00,  1.7000001e-02],\n",
       "       [ 4.9189676e+04, -6.9260001e+00,  2.0000000e-02],\n",
       "       [ 4.9194691e+04, -6.8490000e+00,  1.7000001e-02],\n",
       "       [ 4.9195641e+04, -6.8670001e+00,  1.6000001e-02],\n",
       "       [ 4.9196676e+04, -6.9390001e+00,  2.7000001e-02],\n",
       "       [ 4.9199707e+04, -6.9050002e+00,  1.5000000e-02],\n",
       "       [ 4.9201637e+04, -6.8899999e+00,  5.4000001e-02],\n",
       "       [ 4.9203660e+04, -6.9320002e+00,  1.8999999e-02],\n",
       "       [ 4.9204656e+04, -6.8850002e+00,  2.0000000e-02],\n",
       "       [ 4.9208645e+04, -6.9120002e+00,  2.4000000e-02],\n",
       "       [ 4.9209625e+04, -6.8750000e+00,  1.8999999e-02],\n",
       "       [ 4.9210645e+04, -6.9580002e+00,  2.5000000e-02],\n",
       "       [ 4.9211676e+04, -6.8249998e+00,  1.2000000e-02],\n",
       "       [ 4.9212789e+04, -6.9130001e+00,  5.2000001e-02],\n",
       "       [ 4.9214781e+04, -6.8260002e+00,  3.9999999e-02],\n",
       "       [ 4.9215680e+04, -6.8579998e+00,  1.8999999e-02],\n",
       "       [ 4.9216605e+04, -6.8730001e+00,  3.0999999e-02],\n",
       "       [ 4.9217613e+04, -6.8690000e+00,  8.9999996e-03],\n",
       "       [ 4.9218602e+04, -6.8020000e+00,  1.2000000e-02],\n",
       "       [ 4.9219621e+04, -6.9039998e+00,  4.4000000e-02],\n",
       "       [ 4.9220719e+04, -6.9080000e+00,  2.1000000e-02],\n",
       "       [ 4.9221598e+04, -6.8429999e+00,  2.2000000e-02],\n",
       "       [ 4.9222586e+04, -6.8270001e+00,  1.3000000e-02],\n",
       "       [ 4.9223586e+04, -6.8769999e+00,  2.2000000e-02],\n",
       "       [ 4.9224574e+04, -6.8660002e+00,  1.6000001e-02],\n",
       "       [ 4.9225793e+04, -6.8940001e+00,  2.0000000e-02],\n",
       "       [ 4.9233566e+04, -6.8249998e+00,  3.0999999e-02],\n",
       "       [ 4.9252516e+04, -6.9060001e+00,  1.2000000e-02],\n",
       "       [ 4.9254629e+04, -6.8439999e+00,  9.9999998e-03],\n",
       "       [ 4.9255535e+04, -6.8920002e+00,  1.6000001e-02],\n",
       "       [ 4.9256559e+04, -6.8870001e+00,  9.9999998e-03],\n",
       "       [ 4.9256570e+04, -6.8400002e+00,  8.0000004e-03],\n",
       "       [ 4.9257578e+04, -6.7770000e+00,  8.9999996e-03],\n",
       "       [ 4.9258730e+04, -6.8200002e+00,  1.1000000e-02],\n",
       "       [ 4.9260531e+04, -6.8280001e+00,  1.7000001e-02],\n",
       "       [ 4.9264719e+04, -6.9270000e+00,  2.9999999e-02],\n",
       "       [ 4.9265508e+04, -6.8249998e+00,  1.2000000e-02],\n",
       "       [ 4.9266578e+04, -6.8280001e+00,  9.9999998e-03],\n",
       "       [ 4.9267609e+04, -6.9089999e+00,  1.3000000e-02],\n",
       "       [ 4.9267633e+04, -6.9070001e+00,  1.3000000e-02],\n",
       "       [ 4.9268551e+04, -6.8379998e+00,  1.3000000e-02],\n",
       "       [ 4.9269598e+04, -6.8559999e+00,  4.8000000e-02],\n",
       "       [ 4.9270574e+04, -6.9000001e+00,  1.8999999e-02],\n",
       "       [ 4.9272594e+04, -6.8480000e+00,  9.9999998e-03],\n",
       "       [ 4.9273492e+04, -6.8340001e+00,  8.9999996e-03],\n",
       "       [ 4.9274516e+04, -6.8880000e+00,  1.2000000e-02],\n",
       "       [ 4.9276754e+04, -6.8160000e+00,  8.0000004e-03],\n",
       "       [ 4.9277633e+04, -6.8670001e+00,  8.9999996e-03],\n",
       "       [ 4.9279762e+04, -6.9200001e+00,  1.7999999e-02],\n",
       "       [ 4.9280680e+04, -6.8200002e+00,  1.8999999e-02],\n",
       "       [ 4.9282531e+04, -6.8150001e+00,  1.1000000e-02],\n",
       "       [ 4.9283457e+04, -6.8340001e+00,  9.9999998e-03],\n",
       "       [ 4.9285676e+04, -6.9120002e+00,  2.4000000e-02],\n",
       "       [ 4.9286469e+04, -6.8520002e+00,  1.6000001e-02],\n",
       "       [ 4.9287547e+04, -6.8769999e+00,  2.6000001e-02],\n",
       "       [ 4.9289551e+04, -6.8569999e+00,  1.7000001e-02],\n",
       "       [ 4.9291484e+04, -6.9150000e+00,  1.7999999e-02],\n",
       "       [ 4.9302590e+04, -6.8740001e+00,  1.1000000e-02],\n",
       "       [ 4.9303441e+04, -6.8360000e+00,  1.7999999e-02],\n",
       "       [ 4.9307520e+04, -6.8360000e+00,  1.1000000e-02],\n",
       "       [ 4.9309480e+04, -6.8670001e+00,  8.0000004e-03],\n",
       "       [ 4.9311531e+04, -6.8639998e+00,  1.5000000e-02],\n",
       "       [ 4.9311738e+04, -6.9439998e+00,  2.2000000e-02],\n",
       "       [ 4.9312543e+04, -6.8530002e+00,  1.2000000e-02],\n",
       "       [ 4.9312734e+04, -6.8390002e+00,  1.1000000e-02],\n",
       "       [ 4.9313508e+04, -6.9310002e+00,  1.4000000e-02],\n",
       "       [ 4.9314480e+04, -6.8670001e+00,  2.7000001e-02],\n",
       "       [ 4.9315496e+04, -6.8790002e+00,  1.3000000e-02],\n",
       "       [ 4.9317496e+04, -6.8709998e+00,  8.9999996e-03],\n",
       "       [ 4.9317738e+04, -6.8639998e+00,  4.1999999e-02],\n",
       "       [ 4.9318629e+04, -6.8670001e+00,  3.5999998e-02],\n",
       "       [ 4.9371742e+04, -6.9029999e+00,  4.6000000e-02],\n",
       "       [ 4.9372484e+04, -6.8119998e+00,  8.9999996e-03],\n",
       "       [ 4.9374629e+04, -6.8429999e+00,  2.4000000e-02],\n",
       "       [ 4.9374652e+04, -6.8940001e+00,  1.4000000e-02],\n",
       "       [ 4.9375492e+04, -6.8179998e+00,  1.1000000e-02],\n",
       "       [ 4.9376516e+04, -6.8540001e+00,  9.9999998e-03],\n",
       "       [ 4.9377559e+04, -6.8670001e+00,  1.4000000e-02],\n",
       "       [ 4.9378469e+04, -6.8779998e+00,  2.3000000e-02],\n",
       "       [ 4.9380586e+04, -6.8639998e+00,  1.7999999e-02],\n",
       "       [ 4.9381555e+04, -6.9150000e+00,  1.8999999e-02],\n",
       "       [ 4.9384703e+04, -6.8750000e+00,  1.7000001e-02],\n",
       "       [ 4.9386492e+04, -6.8750000e+00,  1.1000000e-02],\n",
       "       [ 4.9388613e+04, -6.8930001e+00,  1.4000000e-02],\n",
       "       [ 4.9390477e+04, -6.8889999e+00,  1.4000000e-02],\n",
       "       [ 4.9392750e+04, -6.9039998e+00,  1.7999999e-02],\n",
       "       [ 4.9396605e+04, -6.9340000e+00,  2.5000000e-02],\n",
       "       [ 4.9398461e+04, -6.8490000e+00,  7.0000002e-03],\n",
       "       [ 4.9399465e+04, -6.9770002e+00,  1.5000000e-02],\n",
       "       [ 4.9399770e+04, -6.9010000e+00,  1.8999999e-02],\n",
       "       [ 4.9400500e+04, -6.8850002e+00,  2.4000000e-02],\n",
       "       [ 4.9400699e+04, -6.9250002e+00,  2.1000000e-02],\n",
       "       [ 4.9404664e+04, -6.9060001e+00,  9.9999998e-03],\n",
       "       [ 4.9405598e+04, -6.8610001e+00,  1.1000000e-02],\n",
       "       [ 4.9406656e+04, -6.9080000e+00,  1.6000001e-02],\n",
       "       [ 4.9409582e+04, -6.8629999e+00,  1.4000000e-02],\n",
       "       [ 4.9412328e+04, -6.8950000e+00,  1.4000000e-02],\n",
       "       [ 4.9413461e+04, -6.9050002e+00,  1.1000000e-02],\n",
       "       [ 4.9413750e+04, -6.8820000e+00,  2.1000000e-02],\n",
       "       [ 4.9414488e+04, -6.8350000e+00,  2.6000001e-02],\n",
       "       [ 4.9415457e+04, -6.8160000e+00,  7.0000002e-03],\n",
       "       [ 4.9416449e+04, -6.8909998e+00,  9.9999998e-03],\n",
       "       [ 4.9417457e+04, -6.9380002e+00,  1.3000000e-02],\n",
       "       [ 4.9423461e+04, -6.9330001e+00,  1.7999999e-02],\n",
       "       [ 4.9424449e+04, -6.9410000e+00,  1.6000001e-02],\n",
       "       [ 4.9425594e+04, -6.9520001e+00,  1.1000000e-02],\n",
       "       [ 4.9426453e+04, -6.8779998e+00,  1.1000000e-02],\n",
       "       [ 4.9428445e+04, -6.8959999e+00,  1.5000000e-02],\n",
       "       [ 4.9429559e+04, -6.7729998e+00,  3.5000000e-02],\n",
       "       [ 4.9432441e+04, -6.8709998e+00,  1.4000000e-02],\n",
       "       [ 4.9434555e+04, -6.8600001e+00,  1.4000000e-02],\n",
       "       [ 4.9436508e+04, -6.8690000e+00,  1.5000000e-02],\n",
       "       [ 4.9438547e+04, -6.8940001e+00,  1.5000000e-02],\n",
       "       [ 4.9444621e+04, -6.8899999e+00,  2.4000000e-02],\n",
       "       [ 4.9447594e+04, -6.8590002e+00,  3.0999999e-02],\n",
       "       [ 4.9447617e+04, -6.8569999e+00,  1.1000000e-02],\n",
       "       [ 4.9449531e+04, -6.9439998e+00,  1.7999999e-02],\n",
       "       [ 4.9450492e+04, -6.8569999e+00,  1.1000000e-02],\n",
       "       [ 4.9451500e+04, -6.8750000e+00,  1.2000000e-02],\n",
       "       [ 4.9452539e+04, -6.8909998e+00,  1.6000001e-02],\n",
       "       [ 4.9455484e+04, -6.9080000e+00,  1.7999999e-02],\n",
       "       [ 4.9456617e+04, -6.8740001e+00,  1.6000001e-02],\n",
       "       [ 4.9457477e+04, -6.8330002e+00,  9.9999998e-03],\n",
       "       [ 4.9458438e+04, -6.8400002e+00,  8.9999996e-03],\n",
       "       [ 4.9460465e+04, -6.9480000e+00,  1.2000000e-02],\n",
       "       [ 4.9461484e+04, -6.8210001e+00,  1.1000000e-02],\n",
       "       [ 4.9462461e+04, -6.8470001e+00,  1.3000000e-02],\n",
       "       [ 4.9462500e+04, -6.8600001e+00,  1.2000000e-02],\n",
       "       [ 4.9463520e+04, -6.8709998e+00,  9.9999998e-03],\n",
       "       [ 4.9464465e+04, -6.8350000e+00,  2.1000000e-02],\n",
       "       [ 4.9465473e+04, -6.8220000e+00,  1.1000000e-02],\n",
       "       [ 4.9466469e+04, -6.8369999e+00,  1.1000000e-02],\n",
       "       [ 4.9467512e+04, -6.9590001e+00,  3.9999999e-02],\n",
       "       [ 4.9469570e+04, -6.8730001e+00,  3.0999999e-02],\n",
       "       [ 4.9470594e+04, -6.9299998e+00,  5.9999999e-02],\n",
       "       [ 4.9472523e+04, -6.8759999e+00,  1.7000001e-02],\n",
       "       [ 4.9473543e+04, -6.8750000e+00,  1.1000000e-02],\n",
       "       [ 4.9477461e+04, -6.9020000e+00,  9.9999998e-03],\n",
       "       [ 4.9479406e+04, -6.8779998e+00,  1.6000001e-02],\n",
       "       [ 4.9479441e+04, -6.7800002e+00,  2.5000000e-02],\n",
       "       [ 4.9479465e+04, -6.8790002e+00,  1.6000001e-02],\n",
       "       [ 4.9481512e+04, -6.8720002e+00,  1.1000000e-02],\n",
       "       [ 4.9483496e+04, -6.8730001e+00,  1.4000000e-02],\n",
       "       [ 4.9484387e+04, -6.8810000e+00,  8.9999996e-03],\n",
       "       [ 4.9485453e+04, -6.9499998e+00,  1.3000000e-02],\n",
       "       [ 4.9486445e+04, -6.8709998e+00,  2.7000001e-02],\n",
       "       [ 4.9487480e+04, -6.8520002e+00,  9.9999998e-03],\n",
       "       [ 4.9488465e+04, -6.9150000e+00,  1.5000000e-02],\n",
       "       [ 4.9489430e+04, -6.8850002e+00,  2.6000001e-02],\n",
       "       [ 4.9491824e+04, -6.8979998e+00,  2.7000001e-02],\n",
       "       [ 4.9492473e+04, -6.9070001e+00,  2.1000000e-02],\n",
       "       [ 4.9493816e+04, -6.8680000e+00,  3.7000000e-02],\n",
       "       [ 4.9494828e+04, -6.8270001e+00,  2.6000001e-02],\n",
       "       [ 4.9496430e+04, -6.8309999e+00,  3.3000000e-02],\n",
       "       [ 4.9496832e+04, -6.8639998e+00,  3.3000000e-02],\n",
       "       [ 4.9498457e+04, -6.8200002e+00,  4.6999998e-02],\n",
       "       [ 4.9500422e+04, -6.8709998e+00,  5.2999999e-02],\n",
       "       [ 4.9505477e+04, -6.8509998e+00,  1.2000000e-02],\n",
       "       [ 4.9509438e+04, -6.8449998e+00,  1.2000000e-02],\n",
       "       [ 4.9511449e+04, -6.8490000e+00,  2.0000000e-02],\n",
       "       [ 4.9511793e+04, -6.8499999e+00,  3.5999998e-02],\n",
       "       [ 4.9512422e+04, -6.8979998e+00,  1.7999999e-02],\n",
       "       [ 4.9512785e+04, -6.9039998e+00,  2.6000001e-02],\n",
       "       [ 4.9513430e+04, -6.9260001e+00,  1.6000001e-02],\n",
       "       [ 4.9513828e+04, -6.8249998e+00,  1.3000000e-02],\n",
       "       [ 4.9514410e+04, -6.8290000e+00,  1.4000000e-02],\n",
       "       [ 4.9516422e+04, -6.8569999e+00,  2.5000000e-02],\n",
       "       [ 4.9517746e+04, -6.8410001e+00,  2.8999999e-02],\n",
       "       [ 4.9518781e+04, -6.8260002e+00,  4.8000000e-02],\n",
       "       [ 4.9519457e+04, -6.8930001e+00,  1.7999999e-02],\n",
       "       [ 4.9520766e+04, -6.8260002e+00,  4.3000001e-02],\n",
       "       [ 4.9522801e+04, -6.8810000e+00,  2.2000000e-02],\n",
       "       [ 4.9525805e+04, -6.8550000e+00,  2.2000000e-02],\n",
       "       [ 4.9526395e+04, -6.8379998e+00,  2.8999999e-02],\n",
       "       [ 4.9530438e+04, -6.8520002e+00,  2.1000000e-02],\n",
       "       [ 4.9530703e+04, -6.8420000e+00,  2.8999999e-02],\n",
       "       [ 4.9530836e+04, -6.9210000e+00,  1.7999999e-02],\n",
       "       [ 4.9531754e+04, -6.8579998e+00,  1.8999999e-02],\n",
       "       [ 4.9532406e+04, -6.8200002e+00,  9.9999998e-03],\n",
       "       [ 4.9532828e+04, -6.8150001e+00,  8.9999996e-03],\n",
       "       [ 4.9533414e+04, -6.8610001e+00,  1.7999999e-02],\n",
       "       [ 4.9534703e+04, -6.8540001e+00,  3.9999999e-02],\n",
       "       [ 4.9536410e+04, -6.9200001e+00,  3.5000000e-02],\n",
       "       [ 4.9537691e+04, -6.8790002e+00,  3.7000000e-02],\n",
       "       [ 4.9538746e+04, -6.8470001e+00,  2.2000000e-02],\n",
       "       [ 4.9540730e+04, -6.8790002e+00,  1.6000001e-02],\n",
       "       [ 4.9541805e+04, -6.8699999e+00,  8.0000004e-03]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[2].numpy() == np_lc[200:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "966-400 > 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([  0, 200, 200, 200, 200], dtype=int32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivots = tf.concat([[0], pivots], 0)\n",
    "pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([  0, 200, 400, 600, 800], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivots = tf.math.cumsum(pivots)\n",
    "pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_4524/1436799668.py\", line 1, in None  *\n        lambda x: get_window(np_lc, np_lc.shape[0], x, max_obs)\n    File \"/tmp/ipykernel_4524/535930636.py\", line 9, in get_window  *\n        sliced = tf.slice(sequence, [start, 0], [end - start, -1])\n\n    InvalidArgumentError: {{function_node __wrapped__Slice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected size[0] in [0, 166], but got 200 [Op:Slice]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing copy.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m splits \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmap_fn(\u001b[39mlambda\u001b[39;49;00m x: get_window(np_lc, np_lc\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], x, max_obs), pivots,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \t\t\t\t\t\t\t\t\t\tinfer_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \t\t\t\t\t\t\t\t\t\tfn_output_signature\u001b[39m=\u001b[39;49m(tf\u001b[39m.\u001b[39;49mfloat32))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m splits\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:648\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    641\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    642\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    643\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m\n\u001b[1;32m    647\u001b[0m             (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 648\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    570\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    571\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[1;32m    575\u001b[0m           instructions)\n\u001b[0;32m--> 576\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/ops/map_fn.py:640\u001b[0m, in \u001b[0;36mmap_fn_v2\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[39mif\u001b[39;00m fn_output_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m   fn_output_signature \u001b[39m=\u001b[39m dtype\n\u001b[0;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m map_fn(\n\u001b[1;32m    641\u001b[0m     fn\u001b[39m=\u001b[39;49mfn,\n\u001b[1;32m    642\u001b[0m     elems\u001b[39m=\u001b[39;49melems,\n\u001b[1;32m    643\u001b[0m     fn_output_signature\u001b[39m=\u001b[39;49mfn_output_signature,\n\u001b[1;32m    644\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m    645\u001b[0m     back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m    646\u001b[0m     swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m    647\u001b[0m     infer_shape\u001b[39m=\u001b[39;49minfer_shape,\n\u001b[1;32m    648\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    570\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    571\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[1;32m    575\u001b[0m           instructions)\n\u001b[0;32m--> 576\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/ops/map_fn.py:498\u001b[0m, in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    493\u001b[0m   tas \u001b[39m=\u001b[39m [\n\u001b[1;32m    494\u001b[0m       ta\u001b[39m.\u001b[39mwrite(i, value) \u001b[39mfor\u001b[39;00m (ta, value) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tas, result_value_batchable)\n\u001b[1;32m    495\u001b[0m   ]\n\u001b[1;32m    496\u001b[0m   \u001b[39mreturn\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, tas)\n\u001b[0;32m--> 498\u001b[0m _, r_a \u001b[39m=\u001b[39m while_loop\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m    499\u001b[0m     \u001b[39mlambda\u001b[39;49;00m i, _: i \u001b[39m<\u001b[39;49m n,\n\u001b[1;32m    500\u001b[0m     compute, (i, result_batchable_ta),\n\u001b[1;32m    501\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m    502\u001b[0m     back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m    503\u001b[0m     swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m    504\u001b[0m     maximum_iterations\u001b[39m=\u001b[39;49mn)\n\u001b[1;32m    505\u001b[0m result_batchable \u001b[39m=\u001b[39m [r\u001b[39m.\u001b[39mstack() \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m r_a]\n\u001b[1;32m    507\u001b[0m \u001b[39m# Update each output tensor w/ static shape info about the outer dimension.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/ops/while_loop.py:499\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m    496\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m    497\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[1;32m    498\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[0;32m--> 499\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[1;32m    500\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    501\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/ops/while_loop.py:490\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m    487\u001b[0m     loop_vars \u001b[39m=\u001b[39m (counter, loop_vars)\n\u001b[1;32m    488\u001b[0m     cond \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    489\u001b[0m         math_ops\u001b[39m.\u001b[39mlogical_and(i \u001b[39m<\u001b[39m maximum_iterations, orig_cond(\u001b[39m*\u001b[39mlv)))\n\u001b[0;32m--> 490\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, orig_body(\u001b[39m*\u001b[39;49mlv))\n\u001b[1;32m    491\u001b[0m   try_to_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/ops/map_fn.py:488\u001b[0m, in \u001b[0;36mmap_fn.<locals>.compute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    486\u001b[0m ag_ctx \u001b[39m=\u001b[39m autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    487\u001b[0m autographed_fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(fn, ag_ctx)\n\u001b[0;32m--> 488\u001b[0m result_value \u001b[39m=\u001b[39m autographed_fn(elems_value)\n\u001b[1;32m    489\u001b[0m nest\u001b[39m.\u001b[39massert_same_structure(fn_output_signature \u001b[39mor\u001b[39;00m elems, result_value)\n\u001b[1;32m    490\u001b[0m result_value_flat \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(result_value)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_4524/1436799668.py\", line 1, in None  *\n        lambda x: get_window(np_lc, np_lc.shape[0], x, max_obs)\n    File \"/tmp/ipykernel_4524/535930636.py\", line 9, in get_window  *\n        sliced = tf.slice(sequence, [start, 0], [end - start, -1])\n\n    InvalidArgumentError: {{function_node __wrapped__Slice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected size[0] in [0, 166], but got 200 [Op:Slice]\n"
     ]
    }
   ],
   "source": [
    "splits = tf.map_fn(lambda x: get_window(np_lc, np_lc.shape[0], x, max_obs), pivots,\n",
    "\t\t\t\t\t\t\t\t\t\tinfer_shape=False,\n",
    "\t\t\t\t\t\t\t\t\t\tfn_output_signature=(tf.float32))\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_lc[0:200] == splits[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(sequence, length, pivot, max_obs):\n",
    "\tpivot = tf.minimum(length-max_obs, pivot)\n",
    "\tpivot = tf.maximum(0, pivot)\n",
    "\tend = tf.minimum(length, max_obs)\n",
    "\n",
    "\tsliced = tf.slice(sequence, [pivot, 0], [end, -1])\n",
    "\treturn sliced\n",
    "\n",
    "def get_windows(sample, max_obs, binary=True):\n",
    "\tif binary:\n",
    "\t\tinput_dict = deserialize(sample)\n",
    "\telse:\n",
    "\t\tinput_dict = sample\n",
    "\n",
    "\tsequence = input_dict['input']\n",
    "\trest = input_dict['length']%(max_obs)\n",
    "\n",
    "\tpivots = tf.tile([max_obs], [tf.cast(input_dict['length']/max_obs, tf.int32)]) # toma la cantidad de ventanas que se pueden formar dentro de la curvas de luz\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   # puede haber trozos de curvas de luz menor al max_obs que no considerara\n",
    "\tpivots = tf.concat([[0], pivots], 0)\n",
    "\tpivots = tf.math.cumsum(pivots)\n",
    "\n",
    "\tsplits = tf.map_fn(lambda x: get_window(sequence,\n",
    "\t\t\t\t\t\t\t\t\t\t\tinput_dict['length'],\n",
    "\t\t\t\t\t\t\t\t\t\t\tx,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmax_obs),  pivots,\n",
    "\t\t\t\t\t\t\t\t\t\t\tinfer_shape=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\tfn_output_signature=(tf.float32))\n",
    "\n",
    "\tinput_dict['label']  = tf.tile([input_dict['label']], [len(splits)])\n",
    "\tinput_dict['lcid']   = tf.tile([input_dict['lcid']], [len(splits)])\n",
    "\tinput_dict['length'] = tf.tile([input_dict['length']], [len(splits)])\n",
    "\tinput_dict['input']  = splits\n",
    "\n",
    "\treturn input_dict\n",
    "\n",
    "all_dataset = dataset.map(lambda x: get_windows(x,\n",
    "                                            max_obs=window_size,\n",
    "                                            binary=False),\n",
    "                        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "all_dataset = all_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing get_sampling and get_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"b'23.3665.599'\"\n",
      "b\"b'53.3115.350'\"\n",
      "b\"b'9.5486.943'\"\n",
      "b\"b'10.3560.4'\"\n",
      "b\"b'17.2586.233'\"\n",
      "b\"b'24.3585.23'\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcid</th>\n",
       "      <th>lc_data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[49961.613, -4.848, 0.063], [49966.715, -5.01...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'10.3430.1344'\"</td>\n",
       "      <td>[[49001.53, -4.481, 0.057], [49003.59, -4.546,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'18.2598.715'\"</td>\n",
       "      <td>[[49065.574, -4.85, 0.052], [49067.527, -5.029...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'10.3800.1073'\"</td>\n",
       "      <td>[[49818.473, -4.98, 0.045], [49829.46, -4.818,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'11.9109.1427'\"</td>\n",
       "      <td>[[49135.367, -4.919, 0.054], [49144.37, -4.889...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'47.2134.31'\"</td>\n",
       "      <td>[[49257.67, -7.959, 0.003], [49260.61, -7.858,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'80.7079.1118'\"</td>\n",
       "      <td>[[49311.72, -4.978, 0.085], [49312.516, -4.972...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'12.10922.199'\"</td>\n",
       "      <td>[[49223.637, -5.937, 0.047], [49224.605, -5.93...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'11.8632.36'\"</td>\n",
       "      <td>[[49699.695, -8.239, 0.021], [49700.527, -8.21...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[49866.4, -6.834, 0.009], [49872.457, -6.889,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  lcid                                            lc_data  \\\n",
       "0     b\"b'3.7081.943'\"  [[49961.613, -4.848, 0.063], [49966.715, -5.01...   \n",
       "0   b\"b'10.3430.1344'\"  [[49001.53, -4.481, 0.057], [49003.59, -4.546,...   \n",
       "0    b\"b'18.2598.715'\"  [[49065.574, -4.85, 0.052], [49067.527, -5.029...   \n",
       "0   b\"b'10.3800.1073'\"  [[49818.473, -4.98, 0.045], [49829.46, -4.818,...   \n",
       "0   b\"b'11.9109.1427'\"  [[49135.367, -4.919, 0.054], [49144.37, -4.889...   \n",
       "..                 ...                                                ...   \n",
       "0     b\"b'47.2134.31'\"  [[49257.67, -7.959, 0.003], [49260.61, -7.858,...   \n",
       "0   b\"b'80.7079.1118'\"  [[49311.72, -4.978, 0.085], [49312.516, -4.972...   \n",
       "0   b\"b'12.10922.199'\"  [[49223.637, -5.937, 0.047], [49224.605, -5.93...   \n",
       "0     b\"b'11.8632.36'\"  [[49699.695, -8.239, 0.021], [49700.527, -8.21...   \n",
       "0      b\"b'6.7054.88'\"  [[49866.4, -6.834, 0.009], [49872.457, -6.889,...   \n",
       "\n",
       "    label  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "..    ...  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sampling = get_data(samples_dataset)\n",
    "dataset_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"b'23.3665.599'\"\n",
      "b\"b'53.3115.350'\"\n",
      "b\"b'9.5486.943'\"\n",
      "b\"b'10.3560.4'\"\n",
      "b\"b'17.2586.233'\"\n",
      "b\"b'24.3585.23'\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcid</th>\n",
       "      <th>lc_data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[48917.543, -5.061, 0.038], [48918.76, -5.039...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[49461.51, -4.964, 0.059], [49462.477, -4.862...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[50212.438, -5.266, 0.057], [50216.434, -4.90...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[50335.71, -4.931, 0.041], [50349.68, -5.015,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'10.3430.1344'\"</td>\n",
       "      <td>[[48825.76, -4.808, 0.095], [48826.727, -4.876...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[48823.67, -6.931, 0.038], [48824.68, -6.889,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[49162.766, -6.881, 0.025], [49163.38, -6.823...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[49545.395, -6.862, 0.023], [49546.68, -6.87,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[50007.668, -6.871, 0.016], [50013.55, -6.939...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[50435.594, -6.841, 0.008], [50437.547, -6.83...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  lcid                                            lc_data  \\\n",
       "0     b\"b'3.7081.943'\"  [[48917.543, -5.061, 0.038], [48918.76, -5.039...   \n",
       "0     b\"b'3.7081.943'\"  [[49461.51, -4.964, 0.059], [49462.477, -4.862...   \n",
       "0     b\"b'3.7081.943'\"  [[50212.438, -5.266, 0.057], [50216.434, -4.90...   \n",
       "0     b\"b'3.7081.943'\"  [[50335.71, -4.931, 0.041], [50349.68, -5.015,...   \n",
       "0   b\"b'10.3430.1344'\"  [[48825.76, -4.808, 0.095], [48826.727, -4.876...   \n",
       "..                 ...                                                ...   \n",
       "0      b\"b'6.7054.88'\"  [[48823.67, -6.931, 0.038], [48824.68, -6.889,...   \n",
       "0      b\"b'6.7054.88'\"  [[49162.766, -6.881, 0.025], [49163.38, -6.823...   \n",
       "0      b\"b'6.7054.88'\"  [[49545.395, -6.862, 0.023], [49546.68, -6.87,...   \n",
       "0      b\"b'6.7054.88'\"  [[50007.668, -6.871, 0.016], [50013.55, -6.939...   \n",
       "0      b\"b'6.7054.88'\"  [[50435.594, -6.841, 0.008], [50437.547, -6.83...   \n",
       "\n",
       "    label  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "..    ...  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "\n",
       "[398 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_windows = get_data(all_dataset)\n",
    "dataset_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguiremos con sampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = all_dataset.map(lambda x: {'input' :x['input'],\n",
    "                                       'original' :x['input'],\n",
    "                                       'lcid'  :x['lcid'],\n",
    "                                       'length':x['length'],\n",
    "                                       'mask'  :tf.ones(tf.shape(x['input'])[0]),\n",
    "                                       'label' : x['label']},\n",
    "                                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "sizes = {\n",
    "\t\t'input': (window_size, None),\n",
    "\t\t'original': (window_size, None),\n",
    "\t\t'lcid': (),\n",
    "\t\t'length': (),\n",
    "\t\t'mask': (window_size),\n",
    "\t\t'label': ()\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(tensor, axis=0, return_mean=False):\n",
    "    \"\"\"\n",
    "    Standardize a tensor subtracting the mean\n",
    "\n",
    "    Args:\n",
    "        tensor (1-dim tensorflow tensor): values\n",
    "        axis (int): axis on which we calculate the mean\n",
    "        return_mean (bool): output the mean of the tensor\n",
    "                            turning on the original scale\n",
    "    Returns:\n",
    "        tensor (1-dim tensorflow tensor): standardize tensor\n",
    "    \"\"\"\n",
    "\n",
    "    mean_value = tf.reduce_mean(tensor['input'], axis, name='mean_value')\n",
    "    tensor['input'] = tensor['input'] - tf.expand_dims(mean_value, axis)\n",
    "\n",
    "    mean_value = tf.reduce_mean(tensor['original'], axis, name='mean_value')\n",
    "    tensor['original'] = tensor['original'] - tf.expand_dims(mean_value, axis)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_std = dataset_1.map(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"b'23.3665.599'\"\n",
      "b\"b'53.3115.350'\"\n",
      "b\"b'9.5486.943'\"\n",
      "b\"b'10.3560.4'\"\n",
      "b\"b'17.2586.233'\"\n",
      "b\"b'24.3585.23'\"\n"
     ]
    }
   ],
   "source": [
    "for lc_info in dataset_std:\n",
    "    np_lc = lc_info['input'].numpy()\n",
    "    np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "    if np_lc.shape[0] < 200:\n",
    "        print(lc_info['lcid'].numpy())\n",
    "        id_temporal = lc_info['lcid'].numpy()\n",
    "        lc_temporal_info = copy.deepcopy(lc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_temporal_info['input'].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(178,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_temporal_info['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PaddedBatchDataset element_spec={'input': TensorSpec(shape=(None, 200, None), dtype=tf.float32, name=None), 'original': TensorSpec(shape=(None, 200, None), dtype=tf.float32, name=None), 'lcid': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'length': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'mask': TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_padded = dataset_std.padded_batch(batch_size, padded_shapes=sizes)\n",
    "dataset_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de batch 0\n",
      "Numero de batch 1\n",
      "Numero de batch 2\n",
      "Numero de batch 3\n",
      "Numero de batch 4\n",
      "Numero de batch 5\n",
      "Numero de batch 6\n",
      "Numero de batch 7\n",
      "Numero de batch 8\n",
      "Numero de batch 9\n",
      "Numero de batch 10\n",
      "Numero de batch 11\n",
      "Numero de batch 12\n",
      "Numero de batch 13\n",
      "Numero de batch 14\n",
      "Numero de batch 15\n",
      "Numero de batch 16\n",
      "Numero de batch 17\n",
      "Numero de batch 18\n",
      "Numero de batch 19\n",
      "Numero de batch 20\n",
      "Numero de batch 21\n",
      "Numero de batch 22\n",
      "Encontramos la SNID\n",
      "Numero de batch 23\n",
      "Numero de batch 24\n"
     ]
    }
   ],
   "source": [
    "for batch, lc_info_batches in enumerate(dataset_padded):\n",
    "    print('Numero de batch {}'.format(batch))\n",
    "    \n",
    "    for snid, np_lc, mask_pad in zip(lc_info_batches['lcid'].numpy(), lc_info_batches['input'], lc_info_batches['mask']):\n",
    "        #np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "        if snid == id_temporal:\n",
    "            print('Encontramos la SNID')\n",
    "            lc_temporal_padded = copy.deepcopy(np_lc)\n",
    "            mask_padded = copy.deepcopy(mask_pad)\n",
    "            lc_info_with_pad = copy.deepcopy(lc_info_batches)\n",
    "    \n",
    "        #print(lc_info['lcid'].numpy())\n",
    "       # id_temporal = lc_info['lcid'].numpy()  \n",
    "       # lc_temporal = copy.deepcopy(np_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'original', 'lcid', 'length', 'mask', 'label'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 3)\n",
      "tf.Tensor(\n",
      "[[-1.44449609e+03 -8.21390152e-02  4.49437648e-05]\n",
      " [-1.43655078e+03 -8.71391296e-02  1.04494346e-03]\n",
      " [-1.42655469e+03 -1.24138832e-01 -9.55056399e-04]\n",
      " [-1.42550781e+03 -1.01139069e-01 -9.55056399e-04]\n",
      " [-1.42455469e+03 -1.04139328e-01  2.04494363e-03]\n",
      " [-1.34866016e+03 -6.81390762e-02 -1.95505633e-03]\n",
      " [-1.34072266e+03 -4.41389084e-02 -9.55056399e-04]\n",
      " [-1.33964453e+03 -2.01396942e-02 -1.95505633e-03]\n",
      " [-1.33874609e+03 -2.41394043e-02 -9.55056399e-04]\n",
      " [-1.33673047e+03 -7.13920593e-03 -1.95505633e-03]\n",
      " [-1.32967578e+03 -3.71389389e-02 -9.55056399e-04]\n",
      " [-1.25262891e+03  2.38609314e-02  4.49437648e-05]\n",
      " [-1.23079688e+03  1.01861000e-01 -1.95505633e-03]\n",
      " [-1.22463281e+03  9.18607712e-02 -9.55056399e-04]\n",
      " [-1.19973047e+03  1.25861168e-01  4.49437648e-05]\n",
      " [-1.18769141e+03  1.81860924e-01  1.04494346e-03]\n",
      " [-1.17279688e+03  2.70860672e-01  4.49437648e-05]\n",
      " [-1.16774609e+03  2.48860359e-01  2.60449424e-02]\n",
      " [-1.15981250e+03  3.43860626e-01  7.04494352e-03]\n",
      " [-1.15581250e+03  3.64860535e-01  1.04494346e-03]\n",
      " [-1.14283984e+03  3.74860764e-01 -9.55056399e-04]\n",
      " [-1.13287500e+03  3.55860710e-01  1.04494346e-03]\n",
      " [-9.97640625e+02  5.58605194e-02  5.04494319e-03]\n",
      " [-8.95578125e+02 -6.81390762e-02  4.49437648e-05]\n",
      " [-8.92742188e+02 -5.61389923e-02  1.04494346e-03]\n",
      " [-8.92683594e+02 -7.21387863e-02 -9.55056399e-04]\n",
      " [-8.89605469e+02 -9.91392136e-02  3.04494379e-03]\n",
      " [-8.69703125e+02 -2.82138824e-01 -1.95505633e-03]\n",
      " [-8.52695312e+02 -1.40139580e-01 -9.55056399e-04]\n",
      " [-8.41656250e+02 -4.31394577e-02 -9.55056399e-04]\n",
      " [-8.16742188e+02 -2.28138924e-01 -9.55056399e-04]\n",
      " [-7.90785156e+02 -1.61139488e-01 -9.55056399e-04]\n",
      " [-7.78820312e+02 -1.40139580e-01  1.40449423e-02]\n",
      " [-5.44597656e+02 -6.61392212e-02  4.49437648e-05]\n",
      " [-5.37664062e+02 -8.91389847e-02 -9.55056399e-04]\n",
      " [-5.29578125e+02 -9.81388092e-02  2.04494363e-03]\n",
      " [-5.26597656e+02 -9.81388092e-02 -9.55056399e-04]\n",
      " [-5.20585938e+02 -7.11393356e-02  1.04494346e-03]\n",
      " [-5.18750000e+02 -6.21395111e-02 -1.95505633e-03]\n",
      " [-5.16671875e+02 -5.11388779e-02  4.49437648e-05]\n",
      " [-5.12816406e+02 -4.21390533e-02 -1.95505633e-03]\n",
      " [-5.07757812e+02 -4.11396027e-02 -9.55056399e-04]\n",
      " [-5.02636719e+02 -5.71393967e-02  1.04494346e-03]\n",
      " [-4.99625000e+02 -4.91390228e-02  4.49437648e-05]\n",
      " [-4.80769531e+02 -1.44139290e-01 -9.55056399e-04]\n",
      " [-4.78750000e+02 -1.61139488e-01 -9.55056399e-04]\n",
      " [-4.77734375e+02 -1.69138908e-01 -9.55056399e-04]\n",
      " [-4.72734375e+02 -1.67139053e-01 -9.55056399e-04]\n",
      " [-4.65804688e+02 -1.27139091e-01  1.04494346e-03]\n",
      " [-4.62800781e+02 -1.27139091e-01 -1.95505633e-03]\n",
      " [-4.60796875e+02 -1.16139412e-01 -9.55056399e-04]\n",
      " [-4.49792969e+02 -8.61396790e-02 -9.55056399e-04]\n",
      " [-4.40808594e+02 -1.05138779e-01 -9.55056399e-04]\n",
      " [-4.35871094e+02 -1.17138863e-01 -1.95505633e-03]\n",
      " [-4.24808594e+02 -1.32139206e-01  4.49437648e-05]\n",
      " [-3.94929688e+02 -8.41388702e-02 -9.55056399e-04]\n",
      " [-2.22617188e+02  1.13861084e-01 -9.55056399e-04]\n",
      " [-1.79667969e+02  2.11860657e-01 -9.55056399e-04]\n",
      " [-1.75597656e+02  2.21860886e-01  1.04494346e-03]\n",
      " [-1.60613281e+02  1.94860458e-01 -9.55056399e-04]\n",
      " [-1.59593750e+02  1.86861038e-01 -9.55056399e-04]\n",
      " [-1.58574219e+02  1.73860550e-01 -9.55056399e-04]\n",
      " [-1.49667969e+02  1.42860413e-01  2.04494363e-03]\n",
      " [-1.44667969e+02  9.08603668e-02  1.04494346e-03]\n",
      " [-1.42687500e+02  1.06861115e-01  1.04494346e-03]\n",
      " [-1.41578125e+02  7.38611221e-02  1.04494346e-03]\n",
      " [-1.40617188e+02  7.68604279e-02  1.04494346e-03]\n",
      " [-1.36648438e+02  4.38604355e-02 -9.55056399e-04]\n",
      " [-1.34753906e+02  6.58607483e-02 -9.55056399e-04]\n",
      " [-1.13761719e+02 -1.41391754e-02 -1.95505633e-03]\n",
      " [-9.48085938e+01 -8.21390152e-02  4.49437648e-05]\n",
      " [-8.18867188e+01 -7.61394501e-02 -9.55056399e-04]\n",
      " [-7.48906250e+01 -7.31391907e-02 -9.55056399e-04]\n",
      " [-7.09062500e+01 -6.11391068e-02  4.04494395e-03]\n",
      " [-7.08593750e+01 -9.51395035e-02 -9.55056399e-04]\n",
      " [-6.68867188e+01 -1.21139526e-01 -1.95505633e-03]\n",
      " [-5.48593750e+01 -1.21139526e-01  4.49437648e-05]\n",
      " [-5.08476562e+01 -1.23139381e-01 -9.55056399e-04]\n",
      " [-4.79296875e+01 -1.12138748e-01 -1.95505633e-03]\n",
      " [-4.38828125e+01 -1.07139587e-01 -9.55056399e-04]\n",
      " [-3.99296875e+01 -9.01393890e-02 -9.55056399e-04]\n",
      " [-3.49257812e+01 -8.71391296e-02 -9.55056399e-04]\n",
      " [-2.89140625e+01 -1.02139473e-01 -1.95505633e-03]\n",
      " [-2.58945312e+01 -1.04139328e-01 -1.95505633e-03]\n",
      " [-2.38789062e+01 -1.34139061e-01  4.49437648e-05]\n",
      " [-2.19375000e+01 -1.19139671e-01 -9.55056399e-04]\n",
      " [ 8.24062500e+01  9.86099243e-03  1.04494346e-03]\n",
      " [ 8.43789062e+01  1.86061859e-03  3.04494379e-03]\n",
      " [ 1.00343750e+02 -3.11393738e-02 -9.55056399e-04]\n",
      " [ 1.63339844e+02  8.08610916e-02 -9.55056399e-04]\n",
      " [ 1.64375000e+02  8.18605423e-02 -1.95505633e-03]\n",
      " [ 1.68367188e+02  8.78610611e-02 -9.55056399e-04]\n",
      " [ 1.72285156e+02  8.68606567e-02  4.49437648e-05]\n",
      " [ 1.76304688e+02  1.12860680e-01 -9.55056399e-04]\n",
      " [ 1.77222656e+02  1.14860535e-01 -1.95505633e-03]\n",
      " [ 1.81300781e+02  1.16860390e-01 -1.95505633e-03]\n",
      " [ 1.84375000e+02  1.10860825e-01 -1.95505633e-03]\n",
      " [ 1.87257812e+02  1.30860329e-01 -9.55056399e-04]\n",
      " [ 1.88296875e+02  1.26860619e-01 -1.95505633e-03]\n",
      " [ 1.93320312e+02  1.63860321e-01 -9.55056399e-04]\n",
      " [ 1.94324219e+02  1.71860695e-01  1.04494346e-03]\n",
      " [ 1.99332031e+02  1.74860954e-01 -9.55056399e-04]\n",
      " [ 2.00363281e+02  1.85860634e-01 -9.55056399e-04]\n",
      " [ 2.02207031e+02  1.82860374e-01  1.04494346e-03]\n",
      " [ 2.10300781e+02  2.37860680e-01 -1.95505633e-03]\n",
      " [ 2.18300781e+02  2.67860413e-01 -9.55056399e-04]\n",
      " [ 2.25390625e+02  2.31861115e-01 -9.55056399e-04]\n",
      " [ 2.30167969e+02  1.84861183e-01 -9.55056399e-04]\n",
      " [ 2.39253906e+02  8.68606567e-02 -1.95505633e-03]\n",
      " [ 2.50281250e+02  1.68609619e-02 -1.95505633e-03]\n",
      " [ 2.53261719e+02 -1.71394348e-02  4.49437648e-05]\n",
      " [ 2.58203125e+02  1.08604431e-02  1.04494346e-03]\n",
      " [ 2.61312500e+02  4.86087799e-03  1.04494346e-03]\n",
      " [ 2.65222656e+02 -1.61390305e-02 -9.55056399e-04]\n",
      " [ 2.67300781e+02  7.86113739e-03  4.49437648e-05]\n",
      " [ 2.73210938e+02  3.08609009e-02  1.04494346e-03]\n",
      " [ 2.79148438e+02  1.28612518e-02 -9.55056399e-04]\n",
      " [ 2.86156250e+02  1.68609619e-02 -9.55056399e-04]\n",
      " [ 2.95160156e+02 -1.51395798e-02 -9.55056399e-04]\n",
      " [ 2.99109375e+02 -3.31392288e-02  4.49437648e-05]\n",
      " [ 3.05132812e+02 -7.71389008e-02  4.49437648e-05]\n",
      " [ 3.09199219e+02 -1.10138893e-01  2.00449433e-02]\n",
      " [ 3.13156250e+02 -1.24138832e-01 -1.95505633e-03]\n",
      " [ 3.27156250e+02 -1.31138802e-01 -9.55056399e-04]\n",
      " [ 3.47066406e+02 -6.71396255e-02  6.04494335e-03]\n",
      " [ 3.66042969e+02 -1.27139091e-01  4.49437648e-05]\n",
      " [ 4.68343750e+02 -1.48139000e-01  4.49437648e-05]\n",
      " [ 4.99398438e+02 -2.20139503e-01 -9.55056399e-04]\n",
      " [ 5.50402344e+02 -4.51393127e-02 -9.55056399e-04]\n",
      " [ 5.62296875e+02  4.18605804e-02  4.49437648e-05]\n",
      " [ 5.66339844e+02  2.28605270e-02 -9.55056399e-04]\n",
      " [ 5.68386719e+02  5.38606644e-02  1.04494346e-03]\n",
      " [ 5.73164062e+02  6.28604889e-02 -1.95505633e-03]\n",
      " [ 5.76269531e+02  5.88607788e-02 -1.95505633e-03]\n",
      " [ 5.80343750e+02  2.98604965e-02  3.04494379e-03]\n",
      " [ 5.94355469e+02  7.98606873e-02 -9.55056399e-04]\n",
      " [ 5.96382812e+02  6.68611526e-02  4.49437648e-05]\n",
      " [ 5.98308594e+02  6.78606033e-02  1.04494346e-03]\n",
      " [ 6.00378906e+02  7.68604279e-02 -9.55056399e-04]\n",
      " [ 6.06222656e+02  1.01861000e-01 -9.55056399e-04]\n",
      " [ 6.10269531e+02  1.22860909e-01  5.04494319e-03]\n",
      " [ 6.13164062e+02  1.32861137e-01 -9.55056399e-04]\n",
      " [ 6.15300781e+02  1.28860474e-01 -9.55056399e-04]\n",
      " [ 6.40125000e+02  1.36860847e-01 -1.95505633e-03]\n",
      " [ 6.53246094e+02  7.68604279e-02  4.49437648e-05]\n",
      " [ 6.73042969e+02  1.96860313e-01  4.49437648e-05]\n",
      " [ 6.84054688e+02  2.97861099e-01 -9.55056399e-04]\n",
      " [ 6.93085938e+02  3.26860428e-01 -9.55056399e-04]\n",
      " [ 7.06089844e+02  4.54860687e-01  9.04494338e-03]\n",
      " [ 7.14074219e+02  4.14860725e-01 -9.55056399e-04]\n",
      " [ 8.91363281e+02 -2.32139587e-01  4.49437648e-05]\n",
      " [ 9.03199219e+02 -2.61138916e-01 -1.95505633e-03]\n",
      " [ 9.08246094e+02 -2.63138771e-01 -1.95505633e-03]\n",
      " [ 9.12300781e+02 -2.64139175e-01 -9.55056399e-04]\n",
      " [ 9.19394531e+02 -2.58139610e-01  4.49437648e-05]\n",
      " [ 9.25351562e+02 -2.95139313e-01  1.04494346e-03]\n",
      " [ 9.56277344e+02 -1.26139641e-01  1.04494346e-03]\n",
      " [ 9.60187500e+02 -8.51392746e-02 -9.55056399e-04]\n",
      " [ 9.72199219e+02 -3.21388245e-02 -9.55056399e-04]\n",
      " [ 9.78218750e+02 -5.61389923e-02 -1.95505633e-03]\n",
      " [ 9.81207031e+02 -7.61394501e-02 -1.95505633e-03]\n",
      " [ 9.83171875e+02 -6.61392212e-02 -1.95505633e-03]\n",
      " [ 9.92226562e+02 -5.61389923e-02 -9.55056399e-04]\n",
      " [ 1.00814062e+03 -8.41388702e-02 -1.95505633e-03]\n",
      " [ 1.01114844e+03 -8.51392746e-02 -1.95505633e-03]\n",
      " [ 1.01721484e+03 -8.31394196e-02 -9.55056399e-04]\n",
      " [ 1.01822266e+03 -1.05138779e-01 -9.55056399e-04]\n",
      " [ 1.02414453e+03 -1.15139008e-01 -1.95505633e-03]\n",
      " [ 1.03115234e+03 -1.25139236e-01 -9.55056399e-04]\n",
      " [ 1.03415625e+03 -1.06139183e-01 -9.55056399e-04]\n",
      " [ 1.03714453e+03 -1.14139557e-01  4.49437648e-05]\n",
      " [ 1.04013281e+03 -9.31396484e-02 -1.95505633e-03]\n",
      " [ 1.04508203e+03 -7.71389008e-02  1.04494346e-03]\n",
      " [ 1.04913672e+03 -6.31389618e-02 -9.55056399e-04]\n",
      " [ 1.05809766e+03  1.28612518e-02  4.49437648e-05]\n",
      " [ 1.07108594e+03  8.58612061e-02  4.04494395e-03]\n",
      " [ 1.25832812e+03  1.68609619e-02 -1.95505633e-03]\n",
      " [ 1.27332812e+03 -2.03139305e-01 -9.55056399e-04]], shape=(178, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(lc_temporal_info['input'].shape)\n",
    "print(lc_temporal_info['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "tf.Tensor(\n",
      "[[-1.44449609e+03 -8.21390152e-02  4.49437648e-05]\n",
      " [-1.43655078e+03 -8.71391296e-02  1.04494346e-03]\n",
      " [-1.42655469e+03 -1.24138832e-01 -9.55056399e-04]\n",
      " [-1.42550781e+03 -1.01139069e-01 -9.55056399e-04]\n",
      " [-1.42455469e+03 -1.04139328e-01  2.04494363e-03]\n",
      " [-1.34866016e+03 -6.81390762e-02 -1.95505633e-03]\n",
      " [-1.34072266e+03 -4.41389084e-02 -9.55056399e-04]\n",
      " [-1.33964453e+03 -2.01396942e-02 -1.95505633e-03]\n",
      " [-1.33874609e+03 -2.41394043e-02 -9.55056399e-04]\n",
      " [-1.33673047e+03 -7.13920593e-03 -1.95505633e-03]\n",
      " [-1.32967578e+03 -3.71389389e-02 -9.55056399e-04]\n",
      " [-1.25262891e+03  2.38609314e-02  4.49437648e-05]\n",
      " [-1.23079688e+03  1.01861000e-01 -1.95505633e-03]\n",
      " [-1.22463281e+03  9.18607712e-02 -9.55056399e-04]\n",
      " [-1.19973047e+03  1.25861168e-01  4.49437648e-05]\n",
      " [-1.18769141e+03  1.81860924e-01  1.04494346e-03]\n",
      " [-1.17279688e+03  2.70860672e-01  4.49437648e-05]\n",
      " [-1.16774609e+03  2.48860359e-01  2.60449424e-02]\n",
      " [-1.15981250e+03  3.43860626e-01  7.04494352e-03]\n",
      " [-1.15581250e+03  3.64860535e-01  1.04494346e-03]\n",
      " [-1.14283984e+03  3.74860764e-01 -9.55056399e-04]\n",
      " [-1.13287500e+03  3.55860710e-01  1.04494346e-03]\n",
      " [-9.97640625e+02  5.58605194e-02  5.04494319e-03]\n",
      " [-8.95578125e+02 -6.81390762e-02  4.49437648e-05]\n",
      " [-8.92742188e+02 -5.61389923e-02  1.04494346e-03]\n",
      " [-8.92683594e+02 -7.21387863e-02 -9.55056399e-04]\n",
      " [-8.89605469e+02 -9.91392136e-02  3.04494379e-03]\n",
      " [-8.69703125e+02 -2.82138824e-01 -1.95505633e-03]\n",
      " [-8.52695312e+02 -1.40139580e-01 -9.55056399e-04]\n",
      " [-8.41656250e+02 -4.31394577e-02 -9.55056399e-04]\n",
      " [-8.16742188e+02 -2.28138924e-01 -9.55056399e-04]\n",
      " [-7.90785156e+02 -1.61139488e-01 -9.55056399e-04]\n",
      " [-7.78820312e+02 -1.40139580e-01  1.40449423e-02]\n",
      " [-5.44597656e+02 -6.61392212e-02  4.49437648e-05]\n",
      " [-5.37664062e+02 -8.91389847e-02 -9.55056399e-04]\n",
      " [-5.29578125e+02 -9.81388092e-02  2.04494363e-03]\n",
      " [-5.26597656e+02 -9.81388092e-02 -9.55056399e-04]\n",
      " [-5.20585938e+02 -7.11393356e-02  1.04494346e-03]\n",
      " [-5.18750000e+02 -6.21395111e-02 -1.95505633e-03]\n",
      " [-5.16671875e+02 -5.11388779e-02  4.49437648e-05]\n",
      " [-5.12816406e+02 -4.21390533e-02 -1.95505633e-03]\n",
      " [-5.07757812e+02 -4.11396027e-02 -9.55056399e-04]\n",
      " [-5.02636719e+02 -5.71393967e-02  1.04494346e-03]\n",
      " [-4.99625000e+02 -4.91390228e-02  4.49437648e-05]\n",
      " [-4.80769531e+02 -1.44139290e-01 -9.55056399e-04]\n",
      " [-4.78750000e+02 -1.61139488e-01 -9.55056399e-04]\n",
      " [-4.77734375e+02 -1.69138908e-01 -9.55056399e-04]\n",
      " [-4.72734375e+02 -1.67139053e-01 -9.55056399e-04]\n",
      " [-4.65804688e+02 -1.27139091e-01  1.04494346e-03]\n",
      " [-4.62800781e+02 -1.27139091e-01 -1.95505633e-03]\n",
      " [-4.60796875e+02 -1.16139412e-01 -9.55056399e-04]\n",
      " [-4.49792969e+02 -8.61396790e-02 -9.55056399e-04]\n",
      " [-4.40808594e+02 -1.05138779e-01 -9.55056399e-04]\n",
      " [-4.35871094e+02 -1.17138863e-01 -1.95505633e-03]\n",
      " [-4.24808594e+02 -1.32139206e-01  4.49437648e-05]\n",
      " [-3.94929688e+02 -8.41388702e-02 -9.55056399e-04]\n",
      " [-2.22617188e+02  1.13861084e-01 -9.55056399e-04]\n",
      " [-1.79667969e+02  2.11860657e-01 -9.55056399e-04]\n",
      " [-1.75597656e+02  2.21860886e-01  1.04494346e-03]\n",
      " [-1.60613281e+02  1.94860458e-01 -9.55056399e-04]\n",
      " [-1.59593750e+02  1.86861038e-01 -9.55056399e-04]\n",
      " [-1.58574219e+02  1.73860550e-01 -9.55056399e-04]\n",
      " [-1.49667969e+02  1.42860413e-01  2.04494363e-03]\n",
      " [-1.44667969e+02  9.08603668e-02  1.04494346e-03]\n",
      " [-1.42687500e+02  1.06861115e-01  1.04494346e-03]\n",
      " [-1.41578125e+02  7.38611221e-02  1.04494346e-03]\n",
      " [-1.40617188e+02  7.68604279e-02  1.04494346e-03]\n",
      " [-1.36648438e+02  4.38604355e-02 -9.55056399e-04]\n",
      " [-1.34753906e+02  6.58607483e-02 -9.55056399e-04]\n",
      " [-1.13761719e+02 -1.41391754e-02 -1.95505633e-03]\n",
      " [-9.48085938e+01 -8.21390152e-02  4.49437648e-05]\n",
      " [-8.18867188e+01 -7.61394501e-02 -9.55056399e-04]\n",
      " [-7.48906250e+01 -7.31391907e-02 -9.55056399e-04]\n",
      " [-7.09062500e+01 -6.11391068e-02  4.04494395e-03]\n",
      " [-7.08593750e+01 -9.51395035e-02 -9.55056399e-04]\n",
      " [-6.68867188e+01 -1.21139526e-01 -1.95505633e-03]\n",
      " [-5.48593750e+01 -1.21139526e-01  4.49437648e-05]\n",
      " [-5.08476562e+01 -1.23139381e-01 -9.55056399e-04]\n",
      " [-4.79296875e+01 -1.12138748e-01 -1.95505633e-03]\n",
      " [-4.38828125e+01 -1.07139587e-01 -9.55056399e-04]\n",
      " [-3.99296875e+01 -9.01393890e-02 -9.55056399e-04]\n",
      " [-3.49257812e+01 -8.71391296e-02 -9.55056399e-04]\n",
      " [-2.89140625e+01 -1.02139473e-01 -1.95505633e-03]\n",
      " [-2.58945312e+01 -1.04139328e-01 -1.95505633e-03]\n",
      " [-2.38789062e+01 -1.34139061e-01  4.49437648e-05]\n",
      " [-2.19375000e+01 -1.19139671e-01 -9.55056399e-04]\n",
      " [ 8.24062500e+01  9.86099243e-03  1.04494346e-03]\n",
      " [ 8.43789062e+01  1.86061859e-03  3.04494379e-03]\n",
      " [ 1.00343750e+02 -3.11393738e-02 -9.55056399e-04]\n",
      " [ 1.63339844e+02  8.08610916e-02 -9.55056399e-04]\n",
      " [ 1.64375000e+02  8.18605423e-02 -1.95505633e-03]\n",
      " [ 1.68367188e+02  8.78610611e-02 -9.55056399e-04]\n",
      " [ 1.72285156e+02  8.68606567e-02  4.49437648e-05]\n",
      " [ 1.76304688e+02  1.12860680e-01 -9.55056399e-04]\n",
      " [ 1.77222656e+02  1.14860535e-01 -1.95505633e-03]\n",
      " [ 1.81300781e+02  1.16860390e-01 -1.95505633e-03]\n",
      " [ 1.84375000e+02  1.10860825e-01 -1.95505633e-03]\n",
      " [ 1.87257812e+02  1.30860329e-01 -9.55056399e-04]\n",
      " [ 1.88296875e+02  1.26860619e-01 -1.95505633e-03]\n",
      " [ 1.93320312e+02  1.63860321e-01 -9.55056399e-04]\n",
      " [ 1.94324219e+02  1.71860695e-01  1.04494346e-03]\n",
      " [ 1.99332031e+02  1.74860954e-01 -9.55056399e-04]\n",
      " [ 2.00363281e+02  1.85860634e-01 -9.55056399e-04]\n",
      " [ 2.02207031e+02  1.82860374e-01  1.04494346e-03]\n",
      " [ 2.10300781e+02  2.37860680e-01 -1.95505633e-03]\n",
      " [ 2.18300781e+02  2.67860413e-01 -9.55056399e-04]\n",
      " [ 2.25390625e+02  2.31861115e-01 -9.55056399e-04]\n",
      " [ 2.30167969e+02  1.84861183e-01 -9.55056399e-04]\n",
      " [ 2.39253906e+02  8.68606567e-02 -1.95505633e-03]\n",
      " [ 2.50281250e+02  1.68609619e-02 -1.95505633e-03]\n",
      " [ 2.53261719e+02 -1.71394348e-02  4.49437648e-05]\n",
      " [ 2.58203125e+02  1.08604431e-02  1.04494346e-03]\n",
      " [ 2.61312500e+02  4.86087799e-03  1.04494346e-03]\n",
      " [ 2.65222656e+02 -1.61390305e-02 -9.55056399e-04]\n",
      " [ 2.67300781e+02  7.86113739e-03  4.49437648e-05]\n",
      " [ 2.73210938e+02  3.08609009e-02  1.04494346e-03]\n",
      " [ 2.79148438e+02  1.28612518e-02 -9.55056399e-04]\n",
      " [ 2.86156250e+02  1.68609619e-02 -9.55056399e-04]\n",
      " [ 2.95160156e+02 -1.51395798e-02 -9.55056399e-04]\n",
      " [ 2.99109375e+02 -3.31392288e-02  4.49437648e-05]\n",
      " [ 3.05132812e+02 -7.71389008e-02  4.49437648e-05]\n",
      " [ 3.09199219e+02 -1.10138893e-01  2.00449433e-02]\n",
      " [ 3.13156250e+02 -1.24138832e-01 -1.95505633e-03]\n",
      " [ 3.27156250e+02 -1.31138802e-01 -9.55056399e-04]\n",
      " [ 3.47066406e+02 -6.71396255e-02  6.04494335e-03]\n",
      " [ 3.66042969e+02 -1.27139091e-01  4.49437648e-05]\n",
      " [ 4.68343750e+02 -1.48139000e-01  4.49437648e-05]\n",
      " [ 4.99398438e+02 -2.20139503e-01 -9.55056399e-04]\n",
      " [ 5.50402344e+02 -4.51393127e-02 -9.55056399e-04]\n",
      " [ 5.62296875e+02  4.18605804e-02  4.49437648e-05]\n",
      " [ 5.66339844e+02  2.28605270e-02 -9.55056399e-04]\n",
      " [ 5.68386719e+02  5.38606644e-02  1.04494346e-03]\n",
      " [ 5.73164062e+02  6.28604889e-02 -1.95505633e-03]\n",
      " [ 5.76269531e+02  5.88607788e-02 -1.95505633e-03]\n",
      " [ 5.80343750e+02  2.98604965e-02  3.04494379e-03]\n",
      " [ 5.94355469e+02  7.98606873e-02 -9.55056399e-04]\n",
      " [ 5.96382812e+02  6.68611526e-02  4.49437648e-05]\n",
      " [ 5.98308594e+02  6.78606033e-02  1.04494346e-03]\n",
      " [ 6.00378906e+02  7.68604279e-02 -9.55056399e-04]\n",
      " [ 6.06222656e+02  1.01861000e-01 -9.55056399e-04]\n",
      " [ 6.10269531e+02  1.22860909e-01  5.04494319e-03]\n",
      " [ 6.13164062e+02  1.32861137e-01 -9.55056399e-04]\n",
      " [ 6.15300781e+02  1.28860474e-01 -9.55056399e-04]\n",
      " [ 6.40125000e+02  1.36860847e-01 -1.95505633e-03]\n",
      " [ 6.53246094e+02  7.68604279e-02  4.49437648e-05]\n",
      " [ 6.73042969e+02  1.96860313e-01  4.49437648e-05]\n",
      " [ 6.84054688e+02  2.97861099e-01 -9.55056399e-04]\n",
      " [ 6.93085938e+02  3.26860428e-01 -9.55056399e-04]\n",
      " [ 7.06089844e+02  4.54860687e-01  9.04494338e-03]\n",
      " [ 7.14074219e+02  4.14860725e-01 -9.55056399e-04]\n",
      " [ 8.91363281e+02 -2.32139587e-01  4.49437648e-05]\n",
      " [ 9.03199219e+02 -2.61138916e-01 -1.95505633e-03]\n",
      " [ 9.08246094e+02 -2.63138771e-01 -1.95505633e-03]\n",
      " [ 9.12300781e+02 -2.64139175e-01 -9.55056399e-04]\n",
      " [ 9.19394531e+02 -2.58139610e-01  4.49437648e-05]\n",
      " [ 9.25351562e+02 -2.95139313e-01  1.04494346e-03]\n",
      " [ 9.56277344e+02 -1.26139641e-01  1.04494346e-03]\n",
      " [ 9.60187500e+02 -8.51392746e-02 -9.55056399e-04]\n",
      " [ 9.72199219e+02 -3.21388245e-02 -9.55056399e-04]\n",
      " [ 9.78218750e+02 -5.61389923e-02 -1.95505633e-03]\n",
      " [ 9.81207031e+02 -7.61394501e-02 -1.95505633e-03]\n",
      " [ 9.83171875e+02 -6.61392212e-02 -1.95505633e-03]\n",
      " [ 9.92226562e+02 -5.61389923e-02 -9.55056399e-04]\n",
      " [ 1.00814062e+03 -8.41388702e-02 -1.95505633e-03]\n",
      " [ 1.01114844e+03 -8.51392746e-02 -1.95505633e-03]\n",
      " [ 1.01721484e+03 -8.31394196e-02 -9.55056399e-04]\n",
      " [ 1.01822266e+03 -1.05138779e-01 -9.55056399e-04]\n",
      " [ 1.02414453e+03 -1.15139008e-01 -1.95505633e-03]\n",
      " [ 1.03115234e+03 -1.25139236e-01 -9.55056399e-04]\n",
      " [ 1.03415625e+03 -1.06139183e-01 -9.55056399e-04]\n",
      " [ 1.03714453e+03 -1.14139557e-01  4.49437648e-05]\n",
      " [ 1.04013281e+03 -9.31396484e-02 -1.95505633e-03]\n",
      " [ 1.04508203e+03 -7.71389008e-02  1.04494346e-03]\n",
      " [ 1.04913672e+03 -6.31389618e-02 -9.55056399e-04]\n",
      " [ 1.05809766e+03  1.28612518e-02  4.49437648e-05]\n",
      " [ 1.07108594e+03  8.58612061e-02  4.04494395e-03]\n",
      " [ 1.25832812e+03  1.68609619e-02 -1.95505633e-03]\n",
      " [ 1.27332812e+03 -2.03139305e-01 -9.55056399e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]], shape=(200, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(lc_temporal_padded.shape)\n",
    "print(lc_temporal_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASKING\n",
    "\n",
    "def get_probed(input_dict, probed, njobs):\n",
    "\n",
    "    input_shape = tf.shape(input_dict['input'])\n",
    "\n",
    "    if probed == 1.:\n",
    "        probed_mask = tf.ones([input_shape[0], input_shape[1]]) * input_dict['mask']\n",
    "        input_dict['probed_mask']  = probed_mask\n",
    "        input_dict['att_mask'] = 1. - probed_mask\n",
    "        return input_dict\n",
    "\n",
    "    nprobed = tf.multiply(tf.cast(input_shape[1], tf.float32), probed)\n",
    "    nprobed = tf.cast(nprobed, tf.int32)\n",
    "    random_integers = tf.range(input_shape[1], dtype=tf.int32)\n",
    "    indices = tf.map_fn(lambda x: tf.random.shuffle(random_integers), \n",
    "                                      tf.range(input_shape[0]),\n",
    "                                      parallel_iterations=njobs)\n",
    "    indices = tf.slice(indices, [0, 0], [-1, nprobed])\n",
    "    random_mask = tf.one_hot(indices, input_shape[1])\n",
    "    random_mask = tf.reduce_sum(random_mask, 1)\n",
    "\n",
    "    input_dict['probed_mask'] = random_mask * input_dict['mask']\n",
    "    att_mask = (1 - input_dict['mask']) + random_mask \n",
    "    att_mask = tf.minimum(att_mask, 1)\n",
    "    input_dict['att_mask'] = att_mask\n",
    "\n",
    "    return input_dict\n",
    "\n",
    "dataset_probed = dataset_padded.map(lambda x: get_probed(x, probed=probed, njobs=njobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=200>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = tf.shape(lc_info_batches['input'])\n",
    "input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprobed = tf.multiply(tf.cast(input_shape[1], tf.float32), probed)\n",
    "nprobed = tf.cast(nprobed, tf.int32)\n",
    "nprobed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_integers = tf.range(input_shape[1], dtype=tf.int32)\n",
    "random_integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=int32, numpy=\n",
       "array([[ 75, 130,  81, ..., 194, 144, 125],\n",
       "       [ 29,  93,  40, ...,  46, 146,   8],\n",
       "       [152,  10,  72, ...,  28,  23,  97],\n",
       "       ...,\n",
       "       [ 31,   2,  18, ..., 152,  69, 174],\n",
       "       [116,  21,  69, ...,  81,  59,  29],\n",
       "       [198,  54,  68, ..., 165,   5, 164]], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.map_fn(lambda x: tf.random.shuffle(random_integers),\n",
    "                                        tf.range(input_shape[0]),\n",
    "                                        parallel_iterations=njobs)\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(indices[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 80), dtype=int32, numpy=\n",
       "array([[ 75, 130,  81, ...,  47,  90,  23],\n",
       "       [ 29,  93,  40, ..., 133,  57, 107],\n",
       "       [152,  10,  72, ...,  95,  30, 102],\n",
       "       ...,\n",
       "       [ 31,   2,  18, ..., 155,  40,  84],\n",
       "       [116,  21,  69, ...,  12,  57,  93],\n",
       "       [198,  54,  68, ..., 107, 139, 192]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.slice(indices, [0, 0], [-1, nprobed])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 80, 200), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_mask = tf.one_hot(indices, input_shape[1])\n",
    "random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 los valores probed (80)\n",
    "# 0 los valores no probed (120)\n",
    "\n",
    "random_mask = tf.reduce_sum(random_mask, 1)\n",
    "random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'original', 'lcid', 'length', 'mask', 'label'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['probed_mask'] = random_mask * lc_info_batches['mask']\n",
    "lc_info_batches['probed_mask'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n"
     ]
    }
   ],
   "source": [
    "## Comprobacion\n",
    "for lc_probed_mask in lc_info_batches['probed_mask']:\n",
    "    print(np.sum(lc_probed_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 200), dtype=float32, numpy=\n",
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_with_pad['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(200, shape=(), dtype=int32)\n",
      "tf.Tensor(80, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199], shape=(200,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 23 198  98 ... 159 175 186]\n",
      " [ 74  52  24 ...  26 147   4]\n",
      " [ 92   8   2 ... 163 134  54]\n",
      " ...\n",
      " [181 133  69 ...  15 161  78]\n",
      " [ 55  82  95 ...  50 124  62]\n",
      " [ 38  99  27 ...  57  88  77]], shape=(16, 200), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 23 198  98 ...  57 191 140]\n",
      " [ 74  52  24 ...  58  43 194]\n",
      " [ 92   8   2 ... 183  81 185]\n",
      " ...\n",
      " [181 133  69 ... 191 102 164]\n",
      " [ 55  82  95 ...  27  75 100]\n",
      " [ 38  99  27 ... 181 198 113]], shape=(16, 80), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]], shape=(16, 200), dtype=float32)\n",
      "********************\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "67.0\n",
      "80.0\n",
      "80.0\n"
     ]
    }
   ],
   "source": [
    "## Comprobacion\n",
    "def check_probed(lc_batch):\n",
    "\n",
    "    input_shape = tf.shape(lc_batch['input'])\n",
    "    print(input_shape[1])\n",
    "\n",
    "    nprobed = tf.multiply(tf.cast(input_shape[1], tf.float32), probed)\n",
    "    nprobed = tf.cast(nprobed, tf.int32)\n",
    "    print(nprobed)\n",
    "\n",
    "    random_integers = tf.range(input_shape[1], dtype=tf.int32)\n",
    "    print(random_integers)\n",
    "\n",
    "    indices = tf.map_fn(lambda x: tf.random.shuffle(random_integers),\n",
    "                                            tf.range(input_shape[0]),\n",
    "                                            parallel_iterations=njobs)\n",
    "\n",
    "    print(indices)\n",
    "\n",
    "    indices = tf.slice(indices, [0, 0], [-1, nprobed])\n",
    "    print(indices)\n",
    "\n",
    "    random_mask = tf.one_hot(indices, input_shape[1])\n",
    "    random_mask = tf.reduce_sum(random_mask, 1)\n",
    "    print(random_mask)\n",
    "    print('*'*20)\n",
    "\n",
    "    lc_batch['probed_mask'] = random_mask * lc_batch['mask']\n",
    "    for lc_probed_mask in lc_info_with_pad['probed_mask']:\n",
    "        print(np.sum(lc_probed_mask))\n",
    "        \n",
    "\n",
    "check_probed(lc_info_with_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(200, shape=(), dtype=int32)\n",
      "tf.Tensor(80, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199], shape=(200,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[129  93 135 ... 177  88 194]\n",
      " [184 116 144 ...  44 176 149]\n",
      " [137  78  73 ...  84 194  40]\n",
      " ...\n",
      " [131  92  76 ... 193 100  12]\n",
      " [148 185  31 ...  26 143 198]\n",
      " [ 81  13 132 ...  11  15  92]], shape=(16, 200), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[129  93 135 ... 199  89 145]\n",
      " [184 116 144 ... 163 137 180]\n",
      " [137  78  73 ...  99  45 192]\n",
      " ...\n",
      " [131  92  76 ...  84  13  26]\n",
      " [148 185  31 ...  13 111 120]\n",
      " [ 81  13 132 ... 126  73 134]], shape=(16, 80), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 1. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]], shape=(16, 200), dtype=float32)\n",
      "********************\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "69.0\n",
      "80.0\n",
      "80.0\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 2. 2. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]], shape=(16, 200), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 1. 1. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]], shape=(16, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Comprobacion\n",
    "def check_probed_mask_pad(lc_batch):\n",
    "\n",
    "    input_shape = tf.shape(lc_batch['input'])\n",
    "    print(input_shape[1])\n",
    "\n",
    "    nprobed = tf.multiply(tf.cast(input_shape[1], tf.float32), probed)\n",
    "    nprobed = tf.cast(nprobed, tf.int32)\n",
    "    print(nprobed)\n",
    "\n",
    "    random_integers = tf.range(input_shape[1], dtype=tf.int32)\n",
    "    print(random_integers)\n",
    "\n",
    "    indices = tf.map_fn(lambda x: tf.random.shuffle(random_integers),\n",
    "                                            tf.range(input_shape[0]),\n",
    "                                            parallel_iterations=njobs)\n",
    "\n",
    "    print(indices)\n",
    "\n",
    "    indices = tf.slice(indices, [0, 0], [-1, nprobed])\n",
    "    print(indices)\n",
    "\n",
    "    random_mask = tf.one_hot(indices, input_shape[1])\n",
    "    random_mask = tf.reduce_sum(random_mask, 1)\n",
    "    print(random_mask)\n",
    "    print('*'*20)\n",
    "\n",
    "    lc_batch['probed_mask'] = random_mask * lc_batch['mask']\n",
    "    for lc_probed_mask in lc_info_with_pad['probed_mask']:\n",
    "        print(np.sum(lc_probed_mask))\n",
    "\n",
    "    att_mask = (1 - lc_batch['mask']) + random_mask \n",
    "    \n",
    "    return att_mask\n",
    "        \n",
    "att_mask_padded = check_probed_mask_pad(lc_info_with_pad)\n",
    "print(att_mask_padded)\n",
    "att_mask_padded = tf.minimum(att_mask_padded, 1)\n",
    "print(att_mask_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_mask = (1 - lc_info_batches['mask']) + random_mask \n",
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['probed_mask'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################### Corrobora Innecesarioamente lo mismo\n",
    "att_mask == lc_info_batches['probed_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lc_info_batches['probed_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrobora Innecesarioamente lo mismo\n",
    "att_mask == tf.minimum(att_mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Innecesarioamente lo mismo\n",
    "att_mask = tf.minimum(att_mask, 1)\n",
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['att_mask'] = att_mask\n",
    "lc_info_batches['att_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pre_mask, n_elements):\n",
    "    indices = tf.where(pre_mask)\n",
    "    indices = tf.random.shuffle(indices)\n",
    "    indices = tf.slice(indices, [0, 0], [n_elements, -1])\n",
    "\n",
    "    mask = tf.one_hot(indices, tf.shape(pre_mask)[0], dtype=tf.int32)\n",
    "    mask = tf.reduce_sum(mask, 0)\n",
    "    mask = tf.reshape(mask, [tf.shape(pre_mask)[0]])\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_random(input_dict, random_frac, njobs):\n",
    "    \"\"\" Add random observations to each sequence\n",
    "        \n",
    "    Args:\n",
    "        random_frac (number): Fraction of probed (in decimal) to be replaced with random values\n",
    "    \"\"\" \n",
    "    input_shape = tf.shape(input_dict['input'])\n",
    "    input_dict['input_pre_nsp'] = input_dict['input'] \n",
    "\n",
    "    # ====== RANDOM MASK =====\n",
    "    n_probed = tf.reduce_sum(input_dict['probed_mask'], 1)\n",
    "    n_random = tf.math.ceil(n_probed * random_frac)\n",
    "    n_random = tf.cast(n_random, tf.int32)\n",
    "    random_mask = tf.map_fn(lambda x: create_mask(x[0], x[1]),\n",
    "                                (input_dict['probed_mask'], n_random),\n",
    "                                parallel_iterations=njobs,\n",
    "                                fn_output_signature=tf.int32)\n",
    "\n",
    "    # ====== SAME MASK =====\n",
    "    rest = tf.cast(input_dict['probed_mask'], tf.int32) * (1-random_mask)\n",
    "    n_rest = tf.reduce_sum(rest, 1)\n",
    "    n_same = tf.math.ceil(tf.cast(n_rest, tf.float32) * random_frac)\n",
    "    n_same = tf.cast(n_same, tf.int32)\n",
    "\n",
    "    same_mask = tf.map_fn(lambda x: create_mask(x[0], x[1]), \n",
    "                                  (rest, n_same),\n",
    "                                  parallel_iterations=njobs,\n",
    "                                  fn_output_signature=tf.int32)\n",
    "\n",
    "    # ===== REPLACEMENT ==== \n",
    "    random_replacement = tf.random.shuffle(tf.transpose(input_dict['input'], [1, 0, 2]))\n",
    "    random_replacement = tf.transpose(random_replacement, [1, 0, 2])\n",
    "    random_replacement = random_replacement * tf.cast(tf.expand_dims(random_mask, -1), tf.float32) * [0., 1., 1.]\n",
    "\n",
    "    # Mask refering to observations that do not change\n",
    "    keep_mask = tf.expand_dims(1 - random_mask, -1)\n",
    "    keep_mask = tf.tile(keep_mask, [1, 1, input_shape[-1]-1])\n",
    "    keep_mask = tf.concat([tf.zeros([input_shape[0], input_shape[1], 1], dtype=tf.int32), keep_mask], 2)\n",
    "    keep_mask = tf.abs([1, 0, 0] - keep_mask)\n",
    "\n",
    "    # Part of the input we mantain\n",
    "    keep_input = input_dict['input'] * tf.cast(keep_mask, tf.float32)\n",
    "\n",
    "    # Replacing original input with the randomized one\n",
    "    input_dict['input']  = random_replacement + keep_input\n",
    "\n",
    "    # Attention mask is 1 when masked. \n",
    "    # Random mask is 1 for masked observations selected to be randomized\n",
    "    # then,\n",
    "    att_mask    = tf.cast(input_dict['att_mask'], tf.bool)\n",
    "    random_mask = tf.cast(random_mask, tf.bool)\n",
    "    same_mask   = tf.cast(same_mask, tf.bool)\n",
    "\n",
    "    att_mask = tf.math.logical_xor(att_mask, random_mask)\n",
    "    att_mask = tf.math.logical_xor(att_mask, same_mask)\n",
    "\n",
    "    input_dict['att_mask'] = tf.cast(att_mask, tf.float32)\n",
    "\n",
    "    return input_dict\n",
    "\n",
    "dataset_random_mask = dataset_probed.map(lambda x: add_random(x, random_frac=random_same, njobs=njobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_frac=random_same\n",
    "random_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tf.shape(lc_info_batches['input'])\n",
    "lc_info_batches['input_pre_nsp'] = lc_info_batches['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['probed_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
       "array([80., 80., 80., 80., 80., 80., 80., 80., 80., 80., 80., 80., 80.,\n",
       "       80.], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== RANDOM MASK =====\n",
    "n_probed = tf.reduce_sum(lc_info_batches['probed_mask'], 1)\n",
    "n_probed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=int32, numpy=\n",
       "array([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_random = tf.math.ceil(n_probed * random_frac)\n",
    "n_random = tf.cast(n_random, tf.int32)\n",
    "n_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_mask(pre_mask, n_elements):\n",
    "    print(pre_mask.shape)\n",
    "    print(n_elements)\n",
    "    indices = tf.where(pre_mask)\n",
    "    indices = tf.random.shuffle(indices)\n",
    "    indices = tf.slice(indices, [0, 0], [n_elements, -1])\n",
    "\n",
    "    mask = tf.one_hot(indices, tf.shape(pre_mask)[0], dtype=tf.int32)\n",
    "    mask = tf.reduce_sum(mask, 0)\n",
    "    mask = tf.reshape(mask, [tf.shape(pre_mask)[0]])\n",
    "    \n",
    "    return mask\n",
    "\n",
    "random_mask = tf.map_fn(lambda x: create_mask(x[0], x[1]),\n",
    "                            (lc_info_batches['probed_mask'], n_random),\n",
    "                            parallel_iterations=njobs,\n",
    "                            fn_output_signature=tf.int32)\n",
    "\n",
    "random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_mask = lc_info_batches['probed_mask'][0]\n",
    "n_elements = n_random[0]\n",
    "pre_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=16>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(80, 1), dtype=int64, numpy=\n",
       "array([[  4],\n",
       "       [  5],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [  8],\n",
       "       [  9],\n",
       "       [ 10],\n",
       "       [ 14],\n",
       "       [ 18],\n",
       "       [ 23],\n",
       "       [ 24],\n",
       "       [ 26],\n",
       "       [ 27],\n",
       "       [ 29],\n",
       "       [ 31],\n",
       "       [ 33],\n",
       "       [ 40],\n",
       "       [ 41],\n",
       "       [ 43],\n",
       "       [ 47],\n",
       "       [ 48],\n",
       "       [ 49],\n",
       "       [ 50],\n",
       "       [ 54],\n",
       "       [ 56],\n",
       "       [ 59],\n",
       "       [ 60],\n",
       "       [ 62],\n",
       "       [ 63],\n",
       "       [ 66],\n",
       "       [ 68],\n",
       "       [ 74],\n",
       "       [ 75],\n",
       "       [ 76],\n",
       "       [ 77],\n",
       "       [ 81],\n",
       "       [ 82],\n",
       "       [ 84],\n",
       "       [ 86],\n",
       "       [ 87],\n",
       "       [ 89],\n",
       "       [ 90],\n",
       "       [ 93],\n",
       "       [ 94],\n",
       "       [ 96],\n",
       "       [ 98],\n",
       "       [103],\n",
       "       [104],\n",
       "       [111],\n",
       "       [112],\n",
       "       [113],\n",
       "       [114],\n",
       "       [115],\n",
       "       [116],\n",
       "       [130],\n",
       "       [131],\n",
       "       [133],\n",
       "       [135],\n",
       "       [137],\n",
       "       [139],\n",
       "       [141],\n",
       "       [150],\n",
       "       [152],\n",
       "       [157],\n",
       "       [158],\n",
       "       [160],\n",
       "       [164],\n",
       "       [167],\n",
       "       [170],\n",
       "       [174],\n",
       "       [179],\n",
       "       [182],\n",
       "       [183],\n",
       "       [186],\n",
       "       [188],\n",
       "       [190],\n",
       "       [193],\n",
       "       [195],\n",
       "       [198],\n",
       "       [199]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.where(pre_mask)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(80, 1), dtype=int64, numpy=\n",
       "array([[ 82],\n",
       "       [ 48],\n",
       "       [ 23],\n",
       "       [ 54],\n",
       "       [ 96],\n",
       "       [158],\n",
       "       [ 66],\n",
       "       [131],\n",
       "       [193],\n",
       "       [ 75],\n",
       "       [ 43],\n",
       "       [ 81],\n",
       "       [150],\n",
       "       [182],\n",
       "       [ 59],\n",
       "       [ 74],\n",
       "       [186],\n",
       "       [103],\n",
       "       [  7],\n",
       "       [ 93],\n",
       "       [ 68],\n",
       "       [174],\n",
       "       [ 62],\n",
       "       [ 84],\n",
       "       [  9],\n",
       "       [  6],\n",
       "       [157],\n",
       "       [198],\n",
       "       [170],\n",
       "       [167],\n",
       "       [135],\n",
       "       [ 27],\n",
       "       [ 40],\n",
       "       [ 89],\n",
       "       [ 49],\n",
       "       [160],\n",
       "       [115],\n",
       "       [195],\n",
       "       [141],\n",
       "       [152],\n",
       "       [ 29],\n",
       "       [199],\n",
       "       [ 56],\n",
       "       [ 87],\n",
       "       [179],\n",
       "       [188],\n",
       "       [111],\n",
       "       [114],\n",
       "       [  8],\n",
       "       [133],\n",
       "       [190],\n",
       "       [ 98],\n",
       "       [ 33],\n",
       "       [  5],\n",
       "       [130],\n",
       "       [ 18],\n",
       "       [ 41],\n",
       "       [ 14],\n",
       "       [ 26],\n",
       "       [113],\n",
       "       [ 77],\n",
       "       [164],\n",
       "       [ 76],\n",
       "       [183],\n",
       "       [116],\n",
       "       [112],\n",
       "       [ 47],\n",
       "       [104],\n",
       "       [  4],\n",
       "       [ 50],\n",
       "       [ 86],\n",
       "       [137],\n",
       "       [ 10],\n",
       "       [ 63],\n",
       "       [139],\n",
       "       [ 60],\n",
       "       [ 31],\n",
       "       [ 90],\n",
       "       [ 24],\n",
       "       [ 94]])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.random.shuffle(indices)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=int64, numpy=\n",
       "array([[ 82],\n",
       "       [ 48],\n",
       "       [ 23],\n",
       "       [ 54],\n",
       "       [ 96],\n",
       "       [158],\n",
       "       [ 66],\n",
       "       [131],\n",
       "       [193],\n",
       "       [ 75],\n",
       "       [ 43],\n",
       "       [ 81],\n",
       "       [150],\n",
       "       [182],\n",
       "       [ 59],\n",
       "       [ 74]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.slice(indices, [0, 0], [n_elements, -1])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1, 200), dtype=int32, numpy=\n",
       "array([[[0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.one_hot(indices, tf.shape(pre_mask)[0], dtype=tf.int32)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.reduce_sum(mask, 0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.reshape(mask, [tf.shape(pre_mask)[0]])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== SAME MASK =====\n",
    "rest = tf.cast(lc_info_batches['probed_mask'], tf.int32) * (1-random_mask)\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=int32, numpy=\n",
       "array([64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rest = tf.reduce_sum(rest, 1)\n",
    "n_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
       "array([13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n",
       "       13.], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_same = tf.math.ceil(tf.cast(n_rest, tf.float32) * random_frac)\n",
    "n_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14,), dtype=int32, numpy=\n",
       "array([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_same = tf.cast(n_same, tf.int32)\n",
    "n_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "(200,)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_mask = tf.map_fn(lambda x: create_mask(x[0], x[1]), \n",
    "                                (rest, n_same),\n",
    "                                parallel_iterations=njobs,\n",
    "                                fn_output_signature=tf.int32)\n",
    "\n",
    "same_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=float32, numpy=\n",
       "array([[[-2.6617578e+02, -5.5631161e-02, -2.0884996e-02],\n",
       "        [-2.6527734e+02,  1.5836906e-01, -1.5884995e-02],\n",
       "        [-2.6414844e+02,  3.2368660e-02,  5.1150061e-03],\n",
       "        ...,\n",
       "        [ 2.7077344e+02, -3.7631035e-02, -1.8884996e-02],\n",
       "        [ 2.7179297e+02, -2.0631313e-02, -1.6884996e-02],\n",
       "        [ 2.7966406e+02,  1.8636894e-01, -1.9884996e-02]],\n",
       "\n",
       "       [[-3.5253906e+02, -1.5975475e-02, -4.3549910e-03],\n",
       "        [-3.4756641e+02, -1.4797544e-01,  3.5645012e-02],\n",
       "        [-3.4554297e+02,  1.2502480e-01,  2.6450083e-03],\n",
       "        ...,\n",
       "        [ 2.9165625e+02,  5.8024883e-02, -1.5354991e-02],\n",
       "        [ 2.9549219e+02, -2.5975227e-02, -1.6354991e-02],\n",
       "        [ 2.9651172e+02, -5.5975437e-02, -3.3549927e-03]],\n",
       "\n",
       "       [[-4.9218359e+02, -7.2044373e-02,  1.6059995e-02],\n",
       "        [-4.8922266e+02, -8.2044125e-02, -1.9400045e-03],\n",
       "        [-4.8826953e+02,  2.9955864e-02, -9.9400058e-03],\n",
       "        ...,\n",
       "        [ 5.8973438e+02,  3.3956051e-02,  4.3059994e-02],\n",
       "        [ 6.0473828e+02,  3.9956093e-02,  2.0599924e-03],\n",
       "        [ 6.1676953e+02, -6.5043926e-02,  7.0599951e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.9699219e+02,  5.3181648e-03,  4.2449962e-03],\n",
       "        [-1.9570703e+02, -2.6817322e-03,  1.2449957e-03],\n",
       "        [-1.9371094e+02,  5.6318283e-02,  4.1244995e-02],\n",
       "        ...,\n",
       "        [ 2.5629688e+02, -3.6816597e-03, -4.7550034e-03],\n",
       "        [ 2.6321094e+02, -3.2681942e-02, -8.7550040e-03],\n",
       "        [ 2.6419922e+02, -6.2681675e-02, -1.0755003e-02]],\n",
       "\n",
       "       [[-2.7599609e+02,  2.9764175e-03, -5.4999255e-04],\n",
       "        [-2.7011328e+02, -6.5023899e-02, -2.5499929e-03],\n",
       "        [-2.6395312e+02,  9.1976166e-02,  6.4500067e-03],\n",
       "        ...,\n",
       "        [ 2.6190625e+02, -1.1023998e-02,  3.0450005e-02],\n",
       "        [ 2.6482031e+02,  2.7976036e-02,  3.2450005e-02],\n",
       "        [ 2.6891016e+02,  1.3976097e-02, -2.5499929e-03]],\n",
       "\n",
       "       [[-5.0294141e+02,  1.6838074e-02, -8.4150052e-03],\n",
       "        [-5.0098828e+02,  2.5838375e-02, -4.4150054e-03],\n",
       "        [-4.9994922e+02, -2.5161743e-02, -1.4150059e-03],\n",
       "        ...,\n",
       "        [ 5.7401172e+02, -1.3161659e-02, -7.4150059e-03],\n",
       "        [ 5.7515234e+02,  8.8381767e-03, -7.4150059e-03],\n",
       "        [ 5.7701562e+02, -7.6161861e-02,  1.0584995e-02]]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 14, 3), dtype=float32, numpy=\n",
       "array([[[-2.6617578e+02, -5.5631161e-02, -2.0884996e-02],\n",
       "        [-3.5253906e+02, -1.5975475e-02, -4.3549910e-03],\n",
       "        [-4.9218359e+02, -7.2044373e-02,  1.6059995e-02],\n",
       "        ...,\n",
       "        [-1.9699219e+02,  5.3181648e-03,  4.2449962e-03],\n",
       "        [-2.7599609e+02,  2.9764175e-03, -5.4999255e-04],\n",
       "        [-5.0294141e+02,  1.6838074e-02, -8.4150052e-03]],\n",
       "\n",
       "       [[-2.6527734e+02,  1.5836906e-01, -1.5884995e-02],\n",
       "        [-3.4756641e+02, -1.4797544e-01,  3.5645012e-02],\n",
       "        [-4.8922266e+02, -8.2044125e-02, -1.9400045e-03],\n",
       "        ...,\n",
       "        [-1.9570703e+02, -2.6817322e-03,  1.2449957e-03],\n",
       "        [-2.7011328e+02, -6.5023899e-02, -2.5499929e-03],\n",
       "        [-5.0098828e+02,  2.5838375e-02, -4.4150054e-03]],\n",
       "\n",
       "       [[-2.6414844e+02,  3.2368660e-02,  5.1150061e-03],\n",
       "        [-3.4554297e+02,  1.2502480e-01,  2.6450083e-03],\n",
       "        [-4.8826953e+02,  2.9955864e-02, -9.9400058e-03],\n",
       "        ...,\n",
       "        [-1.9371094e+02,  5.6318283e-02,  4.1244995e-02],\n",
       "        [-2.6395312e+02,  9.1976166e-02,  6.4500067e-03],\n",
       "        [-4.9994922e+02, -2.5161743e-02, -1.4150059e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.7077344e+02, -3.7631035e-02, -1.8884996e-02],\n",
       "        [ 2.9165625e+02,  5.8024883e-02, -1.5354991e-02],\n",
       "        [ 5.8973438e+02,  3.3956051e-02,  4.3059994e-02],\n",
       "        ...,\n",
       "        [ 2.5629688e+02, -3.6816597e-03, -4.7550034e-03],\n",
       "        [ 2.6190625e+02, -1.1023998e-02,  3.0450005e-02],\n",
       "        [ 5.7401172e+02, -1.3161659e-02, -7.4150059e-03]],\n",
       "\n",
       "       [[ 2.7179297e+02, -2.0631313e-02, -1.6884996e-02],\n",
       "        [ 2.9549219e+02, -2.5975227e-02, -1.6354991e-02],\n",
       "        [ 6.0473828e+02,  3.9956093e-02,  2.0599924e-03],\n",
       "        ...,\n",
       "        [ 2.6321094e+02, -3.2681942e-02, -8.7550040e-03],\n",
       "        [ 2.6482031e+02,  2.7976036e-02,  3.2450005e-02],\n",
       "        [ 5.7515234e+02,  8.8381767e-03, -7.4150059e-03]],\n",
       "\n",
       "       [[ 2.7966406e+02,  1.8636894e-01, -1.9884996e-02],\n",
       "        [ 2.9651172e+02, -5.5975437e-02, -3.3549927e-03],\n",
       "        [ 6.1676953e+02, -6.5043926e-02,  7.0599951e-03],\n",
       "        ...,\n",
       "        [ 2.6419922e+02, -6.2681675e-02, -1.0755003e-02],\n",
       "        [ 2.6891016e+02,  1.3976097e-02, -2.5499929e-03],\n",
       "        [ 5.7701562e+02, -7.6161861e-02,  1.0584995e-02]]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(lc_info_batches['input'], [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 14, 3), dtype=float32, numpy=\n",
       "array([[[ 2.16882812e+02, -1.26309395e-02, -1.48849953e-02],\n",
       "        [ 2.53449219e+02, -5.69753647e-02, -2.33549904e-02],\n",
       "        [ 4.98863281e+02, -6.30440712e-02, -1.39400065e-02],\n",
       "        ...,\n",
       "        [ 2.11246094e+02,  1.33180618e-02, -5.75500354e-03],\n",
       "        [ 1.77863281e+02,  6.97612762e-03, -9.54999309e-03],\n",
       "        [ 4.76171875e+02,  1.48838043e-01, -5.41500561e-03]],\n",
       "\n",
       "       [[ 9.68437500e+01,  4.36878204e-03,  3.81150059e-02],\n",
       "        [ 1.81531250e+02,  1.18024826e-01,  2.06450075e-02],\n",
       "        [ 3.24640625e+02, -2.50439644e-02, -1.49400067e-02],\n",
       "        ...,\n",
       "        [ 1.49000000e+02, -6.81877136e-04, -7.75500387e-03],\n",
       "        [ 1.26933594e+02, -3.02362442e-03, -5.49992546e-04],\n",
       "        [ 2.93144531e+02,  1.98383331e-02, -7.41500594e-03]],\n",
       "\n",
       "       [[-1.13171875e+02,  1.19369030e-01, -1.98849961e-02],\n",
       "        [-1.91464844e+02, -9.49754715e-02,  1.36450082e-02],\n",
       "        [-3.23375000e+02,  3.99560928e-02, -4.94000688e-03],\n",
       "        ...,\n",
       "        [-1.46734375e+02, -1.68180466e-03, -6.75500371e-03],\n",
       "        [-1.29945312e+02, -6.00237846e-02,  3.45000625e-03],\n",
       "        [-2.95851562e+02,  3.28383446e-02, -3.41500528e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.99101562e+01, -5.96313477e-02, -7.88499415e-03],\n",
       "        [ 1.70691406e+02,  2.30245590e-02,  1.46450102e-02],\n",
       "        [ 2.99699219e+02, -1.09044075e-01, -1.79400053e-02],\n",
       "        ...,\n",
       "        [ 1.33003906e+02, -8.16817284e-02,  9.24499705e-03],\n",
       "        [ 1.17988281e+02, -2.80237198e-02, -4.54999320e-03],\n",
       "        [ 2.57218750e+02,  3.08380127e-02, -1.41500589e-03]],\n",
       "\n",
       "       [[-7.22929688e+01, -2.66313553e-02, -1.88849960e-02],\n",
       "        [-7.04296875e+01, -4.09750938e-02, -1.13549903e-02],\n",
       "        [-1.91292969e+02,  2.95591354e-03, -3.94000672e-03],\n",
       "        ...,\n",
       "        [-1.11785156e+02,  3.33180428e-02, -6.75500371e-03],\n",
       "        [-6.31835938e+01, -4.40239906e-02,  4.50007617e-04],\n",
       "        [-1.91832031e+02,  8.83817673e-03, -6.41500577e-03]],\n",
       "\n",
       "       [[ 1.34941406e+02, -4.16312218e-02,  1.15003437e-04],\n",
       "        [ 2.17453125e+02, -9.97543335e-03, -2.33549904e-02],\n",
       "        [ 3.88625000e+02, -4.30440903e-02, -2.19400059e-02],\n",
       "        ...,\n",
       "        [ 1.96253906e+02, -1.56817436e-02,  1.42449960e-02],\n",
       "        [ 1.47878906e+02,  3.79762650e-02, -6.54999353e-03],\n",
       "        [ 3.65933594e+02, -3.91616821e-02, -4.15004790e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== REPLACEMENT ==== \n",
    "random_replacement = tf.random.shuffle(tf.transpose(lc_info_batches['input'], [1, 0, 2]))\n",
    "random_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=float32, numpy=\n",
       "array([[[ 2.16882812e+02, -1.26309395e-02, -1.48849953e-02],\n",
       "        [ 9.68437500e+01,  4.36878204e-03,  3.81150059e-02],\n",
       "        [-1.13171875e+02,  1.19369030e-01, -1.98849961e-02],\n",
       "        ...,\n",
       "        [ 8.99101562e+01, -5.96313477e-02, -7.88499415e-03],\n",
       "        [-7.22929688e+01, -2.66313553e-02, -1.88849960e-02],\n",
       "        [ 1.34941406e+02, -4.16312218e-02,  1.15003437e-04]],\n",
       "\n",
       "       [[ 2.53449219e+02, -5.69753647e-02, -2.33549904e-02],\n",
       "        [ 1.81531250e+02,  1.18024826e-01,  2.06450075e-02],\n",
       "        [-1.91464844e+02, -9.49754715e-02,  1.36450082e-02],\n",
       "        ...,\n",
       "        [ 1.70691406e+02,  2.30245590e-02,  1.46450102e-02],\n",
       "        [-7.04296875e+01, -4.09750938e-02, -1.13549903e-02],\n",
       "        [ 2.17453125e+02, -9.97543335e-03, -2.33549904e-02]],\n",
       "\n",
       "       [[ 4.98863281e+02, -6.30440712e-02, -1.39400065e-02],\n",
       "        [ 3.24640625e+02, -2.50439644e-02, -1.49400067e-02],\n",
       "        [-3.23375000e+02,  3.99560928e-02, -4.94000688e-03],\n",
       "        ...,\n",
       "        [ 2.99699219e+02, -1.09044075e-01, -1.79400053e-02],\n",
       "        [-1.91292969e+02,  2.95591354e-03, -3.94000672e-03],\n",
       "        [ 3.88625000e+02, -4.30440903e-02, -2.19400059e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.11246094e+02,  1.33180618e-02, -5.75500354e-03],\n",
       "        [ 1.49000000e+02, -6.81877136e-04, -7.75500387e-03],\n",
       "        [-1.46734375e+02, -1.68180466e-03, -6.75500371e-03],\n",
       "        ...,\n",
       "        [ 1.33003906e+02, -8.16817284e-02,  9.24499705e-03],\n",
       "        [-1.11785156e+02,  3.33180428e-02, -6.75500371e-03],\n",
       "        [ 1.96253906e+02, -1.56817436e-02,  1.42449960e-02]],\n",
       "\n",
       "       [[ 1.77863281e+02,  6.97612762e-03, -9.54999309e-03],\n",
       "        [ 1.26933594e+02, -3.02362442e-03, -5.49992546e-04],\n",
       "        [-1.29945312e+02, -6.00237846e-02,  3.45000625e-03],\n",
       "        ...,\n",
       "        [ 1.17988281e+02, -2.80237198e-02, -4.54999320e-03],\n",
       "        [-6.31835938e+01, -4.40239906e-02,  4.50007617e-04],\n",
       "        [ 1.47878906e+02,  3.79762650e-02, -6.54999353e-03]],\n",
       "\n",
       "       [[ 4.76171875e+02,  1.48838043e-01, -5.41500561e-03],\n",
       "        [ 2.93144531e+02,  1.98383331e-02, -7.41500594e-03],\n",
       "        [-2.95851562e+02,  3.28383446e-02, -3.41500528e-03],\n",
       "        ...,\n",
       "        [ 2.57218750e+02,  3.08380127e-02, -1.41500589e-03],\n",
       "        [-1.91832031e+02,  8.83817673e-03, -6.41500577e-03],\n",
       "        [ 3.65933594e+02, -3.91616821e-02, -4.15004790e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_replacement = tf.transpose(random_replacement, [1, 0, 2])\n",
    "random_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.expand_dims(random_mask, -1), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=float32, numpy=\n",
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.expand_dims(random_mask, -1), tf.float32) * [0., 1., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=float32, numpy=\n",
       "array([[[ 0.        , -0.        , -0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.        ,  0.        , -0.        ],\n",
       "        ...,\n",
       "        [ 0.        , -0.        , -0.        ],\n",
       "        [-0.        , -0.02663136, -0.018885  ],\n",
       "        [ 0.        , -0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        , -0.05697536, -0.02335499],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.        , -0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.        , -0.        , -0.        ],\n",
       "        [ 0.        , -0.        , -0.        ]],\n",
       "\n",
       "       [[ 0.        , -0.        , -0.        ],\n",
       "        [ 0.        , -0.        , -0.        ],\n",
       "        [-0.        ,  0.        , -0.        ],\n",
       "        ...,\n",
       "        [ 0.        , -0.10904408, -0.01794001],\n",
       "        [-0.        ,  0.        , -0.        ],\n",
       "        [ 0.        , -0.        , -0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        , -0.        ],\n",
       "        [ 0.        , -0.        , -0.        ],\n",
       "        [-0.        , -0.        , -0.        ],\n",
       "        ...,\n",
       "        [ 0.        , -0.        ,  0.        ],\n",
       "        [-0.        ,  0.        , -0.        ],\n",
       "        [ 0.        , -0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        , -0.        ],\n",
       "        [ 0.        , -0.        , -0.        ],\n",
       "        [-0.        , -0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        , -0.        , -0.        ],\n",
       "        [-0.        , -0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        , -0.        ],\n",
       "        [ 0.        ,  0.        , -0.        ],\n",
       "        [-0.        ,  0.03283834, -0.00341501],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        , -0.        ],\n",
       "        [-0.        ,  0.00883818, -0.00641501],\n",
       "        [ 0.        , -0.        , -0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_replacement = random_replacement * tf.cast(tf.expand_dims(random_mask, -1), tf.float32) * [0., 1., 1.]\n",
    "random_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((1 - random_mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]]], dtype=int32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask refering to observations that do not change\n",
    "keep_mask = tf.expand_dims(1 - random_mask, -1)\n",
    "keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape[-1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 2), dtype=int32, numpy=\n",
       "array([[[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_mask = tf.tile(keep_mask, [1, 1, input_shape[-1]-1])\n",
    "keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 1), dtype=int32, numpy=\n",
       "array([[[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]], dtype=int32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([input_shape[0], input_shape[1], 1], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=int32, numpy=\n",
       "array([[[0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        ...,\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 1]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        ...,\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1]],\n",
       "\n",
       "       [[0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        ...,\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1]],\n",
       "\n",
       "       [[0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        ...,\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1]],\n",
       "\n",
       "       [[0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_mask = tf.concat([tf.zeros([input_shape[0], input_shape[1], 1], dtype=tf.int32), keep_mask], 2)\n",
    "keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=int32, numpy=\n",
       "array([[[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       [[1, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_mask = tf.abs([1, 0, 0] - keep_mask)\n",
    "keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(keep_mask[0][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=float32, numpy=\n",
       "array([[[-2.6617578e+02, -5.5631161e-02, -2.0884996e-02],\n",
       "        [-2.6527734e+02,  1.5836906e-01, -1.5884995e-02],\n",
       "        [-2.6414844e+02,  3.2368660e-02,  5.1150061e-03],\n",
       "        ...,\n",
       "        [ 2.7077344e+02, -3.7631035e-02, -1.8884996e-02],\n",
       "        [ 2.7179297e+02, -0.0000000e+00, -0.0000000e+00],\n",
       "        [ 2.7966406e+02,  1.8636894e-01, -1.9884996e-02]],\n",
       "\n",
       "       [[-3.5253906e+02, -0.0000000e+00, -0.0000000e+00],\n",
       "        [-3.4756641e+02, -1.4797544e-01,  3.5645012e-02],\n",
       "        [-3.4554297e+02,  1.2502480e-01,  2.6450083e-03],\n",
       "        ...,\n",
       "        [ 2.9165625e+02,  5.8024883e-02, -1.5354991e-02],\n",
       "        [ 2.9549219e+02, -2.5975227e-02, -1.6354991e-02],\n",
       "        [ 2.9651172e+02, -5.5975437e-02, -3.3549927e-03]],\n",
       "\n",
       "       [[-4.9218359e+02, -7.2044373e-02,  1.6059995e-02],\n",
       "        [-4.8922266e+02, -8.2044125e-02, -1.9400045e-03],\n",
       "        [-4.8826953e+02,  2.9955864e-02, -9.9400058e-03],\n",
       "        ...,\n",
       "        [ 5.8973438e+02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.0473828e+02,  3.9956093e-02,  2.0599924e-03],\n",
       "        [ 6.1676953e+02, -6.5043926e-02,  7.0599951e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.9699219e+02,  5.3181648e-03,  4.2449962e-03],\n",
       "        [-1.9570703e+02, -2.6817322e-03,  1.2449957e-03],\n",
       "        [-1.9371094e+02,  5.6318283e-02,  4.1244995e-02],\n",
       "        ...,\n",
       "        [ 2.5629688e+02, -3.6816597e-03, -4.7550034e-03],\n",
       "        [ 2.6321094e+02, -3.2681942e-02, -8.7550040e-03],\n",
       "        [ 2.6419922e+02, -6.2681675e-02, -1.0755003e-02]],\n",
       "\n",
       "       [[-2.7599609e+02,  2.9764175e-03, -5.4999255e-04],\n",
       "        [-2.7011328e+02, -6.5023899e-02, -2.5499929e-03],\n",
       "        [-2.6395312e+02,  9.1976166e-02,  6.4500067e-03],\n",
       "        ...,\n",
       "        [ 2.6190625e+02, -1.1023998e-02,  3.0450005e-02],\n",
       "        [ 2.6482031e+02,  2.7976036e-02,  3.2450005e-02],\n",
       "        [ 2.6891016e+02,  1.3976097e-02, -2.5499929e-03]],\n",
       "\n",
       "       [[-5.0294141e+02,  1.6838074e-02, -8.4150052e-03],\n",
       "        [-5.0098828e+02,  2.5838375e-02, -4.4150054e-03],\n",
       "        [-4.9994922e+02, -0.0000000e+00, -0.0000000e+00],\n",
       "        ...,\n",
       "        [ 5.7401172e+02, -1.3161659e-02, -7.4150059e-03],\n",
       "        [ 5.7515234e+02,  0.0000000e+00, -0.0000000e+00],\n",
       "        [ 5.7701562e+02, -7.6161861e-02,  1.0584995e-02]]], dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of the input we mantain\n",
    "keep_input = lc_info_batches['input'] * tf.cast(keep_mask, tf.float32)\n",
    "keep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 3), dtype=float32, numpy=\n",
       "array([[[-2.66175781e+02, -5.56311607e-02, -2.08849963e-02],\n",
       "        [-2.65277344e+02,  1.58369064e-01, -1.58849955e-02],\n",
       "        [-2.64148438e+02,  3.23686600e-02,  5.11500612e-03],\n",
       "        ...,\n",
       "        [ 2.70773438e+02, -3.76310349e-02, -1.88849960e-02],\n",
       "        [ 2.71792969e+02, -2.66313553e-02, -1.88849960e-02],\n",
       "        [ 2.79664062e+02,  1.86368942e-01, -1.98849961e-02]],\n",
       "\n",
       "       [[-3.52539062e+02, -5.69753647e-02, -2.33549904e-02],\n",
       "        [-3.47566406e+02, -1.47975445e-01,  3.56450118e-02],\n",
       "        [-3.45542969e+02,  1.25024796e-01,  2.64500827e-03],\n",
       "        ...,\n",
       "        [ 2.91656250e+02,  5.80248833e-02, -1.53549910e-02],\n",
       "        [ 2.95492188e+02, -2.59752274e-02, -1.63549911e-02],\n",
       "        [ 2.96511719e+02, -5.59754372e-02, -3.35499272e-03]],\n",
       "\n",
       "       [[-4.92183594e+02, -7.20443726e-02,  1.60599947e-02],\n",
       "        [-4.89222656e+02, -8.20441246e-02, -1.94000453e-03],\n",
       "        [-4.88269531e+02,  2.99558640e-02, -9.94000584e-03],\n",
       "        ...,\n",
       "        [ 5.89734375e+02, -1.09044075e-01, -1.79400053e-02],\n",
       "        [ 6.04738281e+02,  3.99560928e-02,  2.05999240e-03],\n",
       "        [ 6.16769531e+02, -6.50439262e-02,  7.05999509e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.96992188e+02,  5.31816483e-03,  4.24499623e-03],\n",
       "        [-1.95707031e+02, -2.68173218e-03,  1.24499574e-03],\n",
       "        [-1.93710938e+02,  5.63182831e-02,  4.12449948e-02],\n",
       "        ...,\n",
       "        [ 2.56296875e+02, -3.68165970e-03, -4.75500338e-03],\n",
       "        [ 2.63210938e+02, -3.26819420e-02, -8.75500403e-03],\n",
       "        [ 2.64199219e+02, -6.26816750e-02, -1.07550034e-02]],\n",
       "\n",
       "       [[-2.75996094e+02,  2.97641754e-03, -5.49992546e-04],\n",
       "        [-2.70113281e+02, -6.50238991e-02, -2.54999287e-03],\n",
       "        [-2.63953125e+02,  9.19761658e-02,  6.45000674e-03],\n",
       "        ...,\n",
       "        [ 2.61906250e+02, -1.10239983e-02,  3.04500051e-02],\n",
       "        [ 2.64820312e+02,  2.79760361e-02,  3.24500054e-02],\n",
       "        [ 2.68910156e+02,  1.39760971e-02, -2.54999287e-03]],\n",
       "\n",
       "       [[-5.02941406e+02,  1.68380737e-02, -8.41500517e-03],\n",
       "        [-5.00988281e+02,  2.58383751e-02, -4.41500545e-03],\n",
       "        [-4.99949219e+02,  3.28383446e-02, -3.41500528e-03],\n",
       "        ...,\n",
       "        [ 5.74011719e+02, -1.31616592e-02, -7.41500594e-03],\n",
       "        [ 5.75152344e+02,  8.83817673e-03, -6.41500577e-03],\n",
       "        [ 5.77015625e+02, -7.61618614e-02,  1.05849952e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing original input with the randomized one\n",
    "lc_info_batches['input']  = random_replacement + keep_input\n",
    "lc_info_batches['input'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False,  True,  True],\n",
       "       [ True,  True, False, ..., False, False,  True],\n",
       "       [ True, False, False, ...,  True, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False,  True, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False,  True, ..., False,  True, False]])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention mask is 1 when masked. \n",
    "# Random mask is 1 for masked observations selected to be randomized\n",
    "# then,\n",
    "att_mask    = tf.cast(lc_info_batches['att_mask'], tf.bool)\n",
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False,  True, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False,  True, ..., False,  True, False]])>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_mask = tf.cast(random_mask, tf.bool)\n",
    "random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False,  True, ..., False,  True, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_mask   = tf.cast(same_mask, tf.bool)\n",
    "same_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False,  True,  True],\n",
       "       [ True,  True, False, ..., False, False,  True],\n",
       "       [ True, False, False, ...,  True, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False,  True, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False,  True, ..., False,  True, False]])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False,  True, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False,  True, ..., False,  True, False]])>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False, False,  True],\n",
       "       [False,  True, False, ..., False, False,  True],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False,  True, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False]])>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_mask = tf.math.logical_xor(att_mask, random_mask)\n",
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Innecesariamente lo mismo\n",
    "tf.cast(rest, tf.bool) == att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=bool, numpy=\n",
       "array([[False, False, False, ..., False, False,  True],\n",
       "       [False,  True, False, ..., False, False,  True],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False]])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_mask = tf.math.logical_xor(att_mask, same_mask)\n",
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'original', 'lcid', 'length', 'mask', 'label', 'probed_mask', 'att_mask', 'input_pre_nsp'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lc_info_batches['att_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_batches['att_mask'] = tf.cast(att_mask, tf.float32)\n",
    "lc_info_batches['att_mask'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lc_info_batches['att_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de batch 0\n",
      "Numero de batch 1\n",
      "Numero de batch 2\n",
      "Numero de batch 3\n",
      "Numero de batch 4\n",
      "Numero de batch 5\n",
      "Numero de batch 6\n",
      "Numero de batch 7\n",
      "Numero de batch 8\n",
      "Numero de batch 9\n",
      "Numero de batch 10\n",
      "Numero de batch 11\n",
      "Numero de batch 12\n",
      "Numero de batch 13\n",
      "Numero de batch 14\n",
      "Numero de batch 15\n",
      "Numero de batch 16\n",
      "Numero de batch 17\n",
      "Numero de batch 18\n",
      "Numero de batch 19\n",
      "Numero de batch 20\n",
      "Numero de batch 21\n",
      "Numero de batch 22\n",
      "Encontramos la SNID\n",
      "Numero de batch 23\n",
      "Numero de batch 24\n"
     ]
    }
   ],
   "source": [
    "for batch, lc_info_batches in enumerate(dataset_random_mask):\n",
    "    print('Numero de batch {}'.format(batch))\n",
    "    \n",
    "    for snid, np_lc, mask_pad in zip(lc_info_batches['lcid'].numpy(), lc_info_batches['input'], lc_info_batches['mask']):\n",
    "        #np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "        if snid == id_temporal:\n",
    "            print('Encontramos la SNID')\n",
    "            lc_temporal_padded = copy.deepcopy(np_lc)\n",
    "            mask_padded = copy.deepcopy(mask_pad)\n",
    "            lc_info_with_pad = copy.deepcopy(lc_info_batches)\n",
    "    \n",
    "        #print(lc_info['lcid'].numpy())\n",
    "       # id_temporal = lc_info['lcid'].numpy()  \n",
    "       # lc_temporal = copy.deepcopy(np_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lc_info_with_pad['att_mask'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lc_info_with_pad['att_mask'][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lc_info_with_pad['probed_mask'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       "array([0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_with_pad['att_mask'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       "array([1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_with_pad['probed_mask'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=bool, numpy=\n",
       "array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True, False,  True,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True, False,  True, False, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_info_with_pad['att_mask'][13] == lc_info_with_pad['probed_mask'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input_no_nsp(input_dict, num_cls=None, test_mode=False):\n",
    "    times = tf.slice(input_dict['input'], [0, 0, 0], [-1, -1, 1])  # input_dict['input'][0:-1, 0:-1, 0:1]\n",
    "    magnitudes = tf.slice(input_dict['input'], [0, 0, 1], [-1, -1, 1]) # input_dict['input'][0:-1, 0:-1, 1:1]\n",
    "    att_mask = tf.expand_dims(input_dict['att_mask'], axis=-1)\n",
    "\n",
    "    inputs = {\n",
    "        'magnitudes': magnitudes,\n",
    "        'times': times,\n",
    "        'att_mask': att_mask,\n",
    "    }\n",
    "    if test_mode:\n",
    "        print('[INFO] TESTING MODE')\n",
    "        inputs['original'] = input_dict['original']\n",
    "        inputs['mask'] = input_dict['mask']\n",
    "\n",
    "    if num_cls is not None:\n",
    "        outputs = tf.one_hot(input_dict['label'], num_cls)\n",
    "\n",
    "    else:\n",
    "        outputs = {\n",
    "            'magnitudes': tf.slice(input_dict['original'], [0, 0, 1], [-1, -1, 1]),\n",
    "            'probed_mask': tf.expand_dims(input_dict['probed_mask'], -1),\n",
    "        }\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "dataset_input = dataset_random_mask.map(lambda x: format_input_no_nsp(x, num_cls=num_cls, test_mode=test_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de batch 0\n",
      "({'magnitudes': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[-0.01758671],\n",
      "        [ 0.00441313],\n",
      "        [-0.02958679],\n",
      "        ...,\n",
      "        [-0.06358671],\n",
      "        [-0.0045867 ],\n",
      "        [ 0.22541332]],\n",
      "\n",
      "       [[ 0.0615387 ],\n",
      "        [ 0.16353893],\n",
      "        [ 0.00153875],\n",
      "        ...,\n",
      "        [-0.09246111],\n",
      "        [ 0.17153883],\n",
      "        [-0.19946098]],\n",
      "\n",
      "       [[-0.25677538],\n",
      "        [ 0.10322428],\n",
      "        [ 0.05122423],\n",
      "        ...,\n",
      "        [ 0.12222433],\n",
      "        [-0.13177538],\n",
      "        [ 0.09822464]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1143198 ],\n",
      "        [ 0.04568005],\n",
      "        [-0.14432001],\n",
      "        ...,\n",
      "        [ 0.09768009],\n",
      "        [ 0.23867989],\n",
      "        [-0.04631996]],\n",
      "\n",
      "       [[ 0.15093136],\n",
      "        [ 0.19893122],\n",
      "        [-0.02106857],\n",
      "        ...,\n",
      "        [ 0.05293131],\n",
      "        [-0.10606861],\n",
      "        [-0.1560688 ]],\n",
      "\n",
      "       [[-0.05855036],\n",
      "        [-0.13255024],\n",
      "        [ 0.16544962],\n",
      "        ...,\n",
      "        [ 0.11444998],\n",
      "        [-0.35855007],\n",
      "        [ 0.06544971]]], dtype=float32)>, 'times': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[-246.88672],\n",
      "        [-245.66797],\n",
      "        [-244.875  ],\n",
      "        ...,\n",
      "        [ 293.07812],\n",
      "        [ 294.08984],\n",
      "        [ 296.0547 ]],\n",
      "\n",
      "       [[-343.125  ],\n",
      "        [-342.16016],\n",
      "        [-341.10156],\n",
      "        ...,\n",
      "        [ 395.83594],\n",
      "        [ 396.84766],\n",
      "        [ 401.8164 ]],\n",
      "\n",
      "       [[-427.6875 ],\n",
      "        [-423.6914 ],\n",
      "        [-421.72266],\n",
      "        ...,\n",
      "        [ 620.27734],\n",
      "        [ 638.3047 ],\n",
      "        [ 642.33594]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-185.97266],\n",
      "        [-183.70312],\n",
      "        [-177.9961 ],\n",
      "        ...,\n",
      "        [ 214.04688],\n",
      "        [ 219.04688],\n",
      "        [ 221.0586 ]],\n",
      "\n",
      "       [[-354.90234],\n",
      "        [-353.8086 ],\n",
      "        [-352.8672 ],\n",
      "        ...,\n",
      "        [ 301.28906],\n",
      "        [ 307.13672],\n",
      "        [ 311.15625]],\n",
      "\n",
      "       [[-490.98438],\n",
      "        [-485.88672],\n",
      "        [-483.9336 ],\n",
      "        ...,\n",
      "        [ 788.3281 ],\n",
      "        [ 808.3008 ],\n",
      "        [ 817.2344 ]]], dtype=float32)>, 'att_mask': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]],\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]], dtype=float32)>}, {'magnitudes': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[-0.01758671],\n",
      "        [ 0.00441313],\n",
      "        [-0.02958679],\n",
      "        ...,\n",
      "        [-0.06358671],\n",
      "        [-0.0045867 ],\n",
      "        [ 0.22541332]],\n",
      "\n",
      "       [[ 0.0615387 ],\n",
      "        [ 0.16353893],\n",
      "        [ 0.00153875],\n",
      "        ...,\n",
      "        [-0.09246111],\n",
      "        [ 0.17153883],\n",
      "        [-0.19946098]],\n",
      "\n",
      "       [[-0.25677538],\n",
      "        [ 0.10322428],\n",
      "        [ 0.05122423],\n",
      "        ...,\n",
      "        [ 0.12222433],\n",
      "        [-0.13177538],\n",
      "        [ 0.09822464]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1143198 ],\n",
      "        [ 0.04568005],\n",
      "        [-0.14432001],\n",
      "        ...,\n",
      "        [ 0.09768009],\n",
      "        [ 0.23867989],\n",
      "        [-0.04631996]],\n",
      "\n",
      "       [[ 0.15093136],\n",
      "        [ 0.19893122],\n",
      "        [-0.02106857],\n",
      "        ...,\n",
      "        [ 0.05293131],\n",
      "        [-0.10606861],\n",
      "        [-0.1560688 ]],\n",
      "\n",
      "       [[-0.05855036],\n",
      "        [-0.13255024],\n",
      "        [ 0.16544962],\n",
      "        ...,\n",
      "        [ 0.11444998],\n",
      "        [-0.35855007],\n",
      "        [ 0.06544971]]], dtype=float32)>, 'probed_mask': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]],\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]], dtype=float32)>})\n"
     ]
    }
   ],
   "source": [
    "for batch, lc_info_batches in enumerate(dataset_input):\n",
    "    print('Numero de batch {}'.format(batch))\n",
    "    print(lc_info_batches)\n",
    "\n",
    "    break\n",
    "    \n",
    "    for snid, np_lc in zip(lc_info_batches['lcid'].numpy(), lc_info_batches['input']):\n",
    "        #np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "        if snid == id_temporal:\n",
    "            print('Encontramos la SNID')\n",
    "            lc_temporal_padded = copy.deepcopy(np_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['magnitudes', 'times', 'att_mask'])\n",
      "dict_keys(['magnitudes', 'probed_mask'])\n"
     ]
    }
   ],
   "source": [
    "dict_input_lc = lc_info_batches[0]\n",
    "dict_output_lc = lc_info_batches[1]\n",
    "\n",
    "print(dict_input_lc.keys())\n",
    "print(dict_output_lc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 1), dtype=bool, numpy=\n",
       "array([[False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False]])>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_input_lc['att_mask'][0] == dict_input_lc['att_mask'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_input_lc['att_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_input_lc['att_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 200, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(lc_info_batches['att_mask'], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=({'magnitudes': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None), 'times': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None), 'att_mask': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None)}, {'magnitudes': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None), 'probed_mask': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None)})>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHUFFLE_BUFFER = 10000\n",
    "dataset_input = dataset_input.shuffle(SHUFFLE_BUFFER)\n",
    "dataset_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=({'magnitudes': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None), 'times': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None), 'att_mask': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None)}, {'magnitudes': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None), 'probed_mask': TensorSpec(shape=(None, 200, 1), dtype=tf.float32, name=None)})>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input = dataset_input.prefetch(2)\n",
    "dataset_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de batch 0\n",
      "({'magnitudes': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[-0.03971672],\n",
      "        [ 0.08628321],\n",
      "        [-0.37771654],\n",
      "        ...,\n",
      "        [ 0.23528337],\n",
      "        [ 0.04128361],\n",
      "        [ 0.20028353]],\n",
      "\n",
      "       [[ 0.0513587 ],\n",
      "        [-0.01664162],\n",
      "        [-0.05264139],\n",
      "        ...,\n",
      "        [ 0.15635872],\n",
      "        [-0.1696415 ],\n",
      "        [-0.07564116]],\n",
      "\n",
      "       [[-0.27462006],\n",
      "        [ 0.2023797 ],\n",
      "        [ 0.20337963],\n",
      "        ...,\n",
      "        [ 0.13537979],\n",
      "        [ 0.14737988],\n",
      "        [ 0.13238001]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1050725 ],\n",
      "        [ 0.10392761],\n",
      "        [-0.11707258],\n",
      "        ...,\n",
      "        [ 0.10592747],\n",
      "        [-0.04107285],\n",
      "        [-0.06407261]],\n",
      "\n",
      "       [[ 0.20767021],\n",
      "        [ 0.11067057],\n",
      "        [ 0.06767035],\n",
      "        ...,\n",
      "        [-0.06532955],\n",
      "        [ 0.1866703 ],\n",
      "        [-0.12732935]],\n",
      "\n",
      "       [[-0.06105042],\n",
      "        [ 0.03894997],\n",
      "        [-0.20905018],\n",
      "        ...,\n",
      "        [-0.07805014],\n",
      "        [-0.04305029],\n",
      "        [-0.14605045]]], dtype=float32)>, 'times': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[-484.39062],\n",
      "        [-476.40234],\n",
      "        [-468.375  ],\n",
      "        ...,\n",
      "        [ 705.5078 ],\n",
      "        [ 714.41016],\n",
      "        [ 717.41797]],\n",
      "\n",
      "       [[-657.2656 ],\n",
      "        [-657.2578 ],\n",
      "        [-657.25   ],\n",
      "        ...,\n",
      "        [ 790.7539 ],\n",
      "        [ 802.79297],\n",
      "        [ 806.7617 ]],\n",
      "\n",
      "       [[-335.77734],\n",
      "        [-292.76953],\n",
      "        [-291.8125 ],\n",
      "        ...,\n",
      "        [ 334.9961 ],\n",
      "        [ 336.01953],\n",
      "        [ 336.98438]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-322.11328],\n",
      "        [-322.03125],\n",
      "        [-321.96094],\n",
      "        ...,\n",
      "        [ 365.16406],\n",
      "        [ 365.98828],\n",
      "        [ 366.16016]],\n",
      "\n",
      "       [[-421.0703 ],\n",
      "        [-407.07812],\n",
      "        [-406.91406],\n",
      "        ...,\n",
      "        [ 378.79297],\n",
      "        [ 379.03906],\n",
      "        [ 379.83594]],\n",
      "\n",
      "       [[-526.6133 ],\n",
      "        [-525.625  ],\n",
      "        [-523.6172 ],\n",
      "        ...,\n",
      "        [ 669.6914 ],\n",
      "        [ 672.6289 ],\n",
      "        [ 773.7461 ]]], dtype=float32)>, 'att_mask': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]], dtype=float32)>}, {'magnitudes': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[-0.03971672],\n",
      "        [ 0.08628321],\n",
      "        [-0.37771654],\n",
      "        ...,\n",
      "        [ 0.23528337],\n",
      "        [ 0.04128361],\n",
      "        [-0.11471653]],\n",
      "\n",
      "       [[ 0.0513587 ],\n",
      "        [-0.01664162],\n",
      "        [-0.05264139],\n",
      "        ...,\n",
      "        [ 0.15635872],\n",
      "        [-0.1696415 ],\n",
      "        [-0.07564116]],\n",
      "\n",
      "       [[-0.27462006],\n",
      "        [ 0.2023797 ],\n",
      "        [ 0.20337963],\n",
      "        ...,\n",
      "        [ 0.13537979],\n",
      "        [ 0.14737988],\n",
      "        [ 0.13238001]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1050725 ],\n",
      "        [ 0.10392761],\n",
      "        [ 0.26692724],\n",
      "        ...,\n",
      "        [ 0.0449276 ],\n",
      "        [-0.04107285],\n",
      "        [-0.00107241]],\n",
      "\n",
      "       [[ 0.20767021],\n",
      "        [ 0.11067057],\n",
      "        [ 0.06767035],\n",
      "        ...,\n",
      "        [-0.06532955],\n",
      "        [ 0.1866703 ],\n",
      "        [-0.12732935]],\n",
      "\n",
      "       [[-0.06105042],\n",
      "        [-0.17505026],\n",
      "        [-0.20905018],\n",
      "        ...,\n",
      "        [-0.07805014],\n",
      "        [-0.04305029],\n",
      "        [-0.01705027]]], dtype=float32)>, 'probed_mask': <tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
      "array([[[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]],\n",
      "\n",
      "       [[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]], dtype=float32)>})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb Cell 106\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumero de batch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(batch))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(lc_info_batches)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m snid, np_lc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(lc_info_batches[\u001b[39m'\u001b[39;49m\u001b[39mlcid\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mnumpy(), lc_info_batches[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m#np_lc = np_lc[np_lc[:,0].argsort()]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m snid \u001b[39m==\u001b[39m id_temporal:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeephub/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer/presentation/experiments/astromer_1_pe/notebooks/debug_preprocessing.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEncontramos la SNID\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for batch, lc_info_batches in enumerate(dataset_input):\n",
    "    print('Numero de batch {}'.format(batch))\n",
    "    print(lc_info_batches)\n",
    "    \n",
    "    for snid, np_lc in zip(lc_info_batches['lcid'].numpy(), lc_info_batches['input']):\n",
    "        #np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "        if snid == id_temporal:\n",
    "            print('Encontramos la SNID')\n",
    "            lc_temporal_padded = copy.deepcopy(np_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['magnitudes', 'times', 'att_mask'])\n",
      "dict_keys(['magnitudes', 'probed_mask'])\n"
     ]
    }
   ],
   "source": [
    "dict_input_lc = lc_info_batches[0]\n",
    "dict_output_lc = lc_info_batches[1]\n",
    "\n",
    "print(dict_input_lc.keys())\n",
    "print(dict_output_lc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
       "array([[[-0.03971672],\n",
       "        [ 0.08628321],\n",
       "        [-0.37771654],\n",
       "        ...,\n",
       "        [ 0.23528337],\n",
       "        [ 0.04128361],\n",
       "        [ 0.20028353]],\n",
       "\n",
       "       [[ 0.0513587 ],\n",
       "        [-0.01664162],\n",
       "        [-0.05264139],\n",
       "        ...,\n",
       "        [ 0.15635872],\n",
       "        [-0.1696415 ],\n",
       "        [-0.07564116]],\n",
       "\n",
       "       [[-0.27462006],\n",
       "        [ 0.2023797 ],\n",
       "        [ 0.20337963],\n",
       "        ...,\n",
       "        [ 0.13537979],\n",
       "        [ 0.14737988],\n",
       "        [ 0.13238001]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.1050725 ],\n",
       "        [ 0.10392761],\n",
       "        [-0.11707258],\n",
       "        ...,\n",
       "        [ 0.10592747],\n",
       "        [-0.04107285],\n",
       "        [-0.06407261]],\n",
       "\n",
       "       [[ 0.20767021],\n",
       "        [ 0.11067057],\n",
       "        [ 0.06767035],\n",
       "        ...,\n",
       "        [-0.06532955],\n",
       "        [ 0.1866703 ],\n",
       "        [-0.12732935]],\n",
       "\n",
       "       [[-0.06105042],\n",
       "        [ 0.03894997],\n",
       "        [-0.20905018],\n",
       "        ...,\n",
       "        [-0.07805014],\n",
       "        [-0.04305029],\n",
       "        [-0.14605045]]], dtype=float32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_input_lc['magnitudes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_input_lc['att_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_lcs = []\n",
    "\n",
    "for lc_info in dataset_1:\n",
    "    np_lc = lc_info['input'].numpy()\n",
    "    np_lc = np_lc[np_lc[:,0].argsort()]\n",
    "\n",
    "    for snid, lc_data, label in zip(lc_info['lcid'].numpy(), np_lc, lc_info['label'].numpy()):\n",
    "        data = {'lcid': snid, \n",
    "                'lc_data': [lc_data],\n",
    "                'label': label}  \n",
    "\n",
    "        list_data_lcs.append(pd.DataFrame(data))\n",
    "\n",
    "list_data_lcs = pd.concat(list_data_lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcid</th>\n",
       "      <th>lc_data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[[49461.51, -4.964, 0.059], [49462.477, -4.86...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[[49461.51, -4.964, 0.059], [49462.477, -4.86...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[[49461.51, -4.964, 0.059], [49462.477, -4.86...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'3.7081.943'\"</td>\n",
       "      <td>[[[49461.51, -4.964, 0.059], [49462.477, -4.86...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'10.3430.1344'\"</td>\n",
       "      <td>[[[49461.51, -4.964, 0.059], [49462.477, -4.86...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[[49819.547, -5.919, 0.035], [49824.52, -6.05...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[[49819.547, -5.919, 0.035], [49824.52, -6.05...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[[49819.547, -5.919, 0.035], [49824.52, -6.05...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[[49819.547, -5.919, 0.035], [49824.52, -6.05...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"b'6.7054.88'\"</td>\n",
       "      <td>[[[49819.547, -5.919, 0.035], [49824.52, -6.05...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  lcid                                            lc_data  \\\n",
       "0     b\"b'3.7081.943'\"  [[[49461.51, -4.964, 0.059], [49462.477, -4.86...   \n",
       "0     b\"b'3.7081.943'\"  [[[49461.51, -4.964, 0.059], [49462.477, -4.86...   \n",
       "0     b\"b'3.7081.943'\"  [[[49461.51, -4.964, 0.059], [49462.477, -4.86...   \n",
       "0     b\"b'3.7081.943'\"  [[[49461.51, -4.964, 0.059], [49462.477, -4.86...   \n",
       "0   b\"b'10.3430.1344'\"  [[[49461.51, -4.964, 0.059], [49462.477, -4.86...   \n",
       "..                 ...                                                ...   \n",
       "0      b\"b'6.7054.88'\"  [[[49819.547, -5.919, 0.035], [49824.52, -6.05...   \n",
       "0      b\"b'6.7054.88'\"  [[[49819.547, -5.919, 0.035], [49824.52, -6.05...   \n",
       "0      b\"b'6.7054.88'\"  [[[49819.547, -5.919, 0.035], [49824.52, -6.05...   \n",
       "0      b\"b'6.7054.88'\"  [[[49819.547, -5.919, 0.035], [49824.52, -6.05...   \n",
       "0      b\"b'6.7054.88'\"  [[[49819.547, -5.919, 0.035], [49824.52, -6.05...   \n",
       "\n",
       "    label  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "0       5  \n",
       "..    ...  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "\n",
       "[398 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9018617e+04, -4.3959999e+00,  1.0000000e-01],\n",
       "       [ 4.9059512e+04, -4.9980001e+00,  8.9000002e-02],\n",
       "       [ 4.9060492e+04, -5.0289998e+00,  8.6999997e-02],\n",
       "       [ 4.9061480e+04, -4.8569999e+00,  7.2999999e-02],\n",
       "       [ 4.9065648e+04, -5.0110002e+00,  9.6000001e-02],\n",
       "       [ 4.9068523e+04, -4.9050002e+00,  7.9000004e-02],\n",
       "       [ 4.9077484e+04, -5.2030001e+00,  9.0000004e-02],\n",
       "       [ 4.9094438e+04, -4.7940001e+00,  9.0000004e-02],\n",
       "       [ 4.9095438e+04, -4.9159999e+00,  9.4999999e-02],\n",
       "       [ 4.9096434e+04, -4.5700002e+00,  9.0000004e-02],\n",
       "       [ 4.9103434e+04, -5.1259999e+00,  7.4000001e-02],\n",
       "       [ 4.9120418e+04, -5.1310000e+00,  7.8000002e-02],\n",
       "       [ 4.9145398e+04, -6.1059999e+00, -4.5600000e+02],\n",
       "       [ 4.9283766e+04, -5.2230000e+00,  7.5999998e-02],\n",
       "       [ 4.9447633e+04, -4.8439999e+00,  9.7000003e-02],\n",
       "       [ 4.9458527e+04, -4.7319999e+00,  9.4999999e-02],\n",
       "       [ 4.9465496e+04, -4.7989998e+00,  1.0000000e-01],\n",
       "       [ 4.9518430e+04, -2.6750000e+00, -4.9830000e+03],\n",
       "       [ 4.9717684e+04, -4.8509998e+00,  7.9000004e-02],\n",
       "       [ 4.9759617e+04, -5.1669998e+00,  7.9000004e-02],\n",
       "       [ 4.9810586e+04, -4.8709998e+00,  9.7999997e-02],\n",
       "       [ 4.9872484e+04, -4.9910002e+00,  9.7000003e-02],\n",
       "       [ 4.9891410e+04, -4.8260002e+00,  9.4999999e-02],\n",
       "       [ 5.0107609e+04, -4.8369999e+00,  8.3999999e-02],\n",
       "       [ 5.0108609e+04, -4.6739998e+00,  9.7999997e-02],\n",
       "       [ 5.0123605e+04, -5.0270000e+00,  9.6000001e-02],\n",
       "       [ 5.0141516e+04, -5.0710001e+00,  6.6000000e-02],\n",
       "       [ 5.0151543e+04, -2.5030000e+00, -6.6530000e+03],\n",
       "       [ 5.0161602e+04, -5.7950001e+00,  6.6000000e-02],\n",
       "       [ 5.0219441e+04, -5.1079998e+00,  7.1999997e-02],\n",
       "       [ 5.0228508e+04, -4.9480000e+00,  9.8999999e-02],\n",
       "       [ 5.0461598e+04, -5.1040001e+00,  5.4000001e-02],\n",
       "       [ 5.0484703e+04, -4.6929998e+00,  9.6000001e-02],\n",
       "       [ 5.0507527e+04, -4.5500002e+00,  8.6999997e-02],\n",
       "       [ 5.0522562e+04, -4.8280001e+00,  8.6999997e-02],\n",
       "       [ 5.0523473e+04, -4.8810000e+00,  9.0999998e-02],\n",
       "       [ 5.0547578e+04, -4.9460001e+00,  9.7000003e-02],\n",
       "       [ 5.0550531e+04, -4.5560002e+00,  9.2000000e-02],\n",
       "       [ 5.0825516e+04, -3.5090001e+00, -3.7100000e+02],\n",
       "       [ 5.0834594e+04, -4.8140001e+00,  6.1999999e-02],\n",
       "       [ 5.0841551e+04, -4.2820001e+00,  9.0000004e-02],\n",
       "       [ 5.0842578e+04, -5.0879998e+00,  6.1000001e-02],\n",
       "       [ 5.0844508e+04, -4.9050002e+00,  8.1000000e-02],\n",
       "       [ 5.0875641e+04, -4.9870000e+00,  9.8999999e-02],\n",
       "       [ 5.1172562e+04, -5.1380000e+00,  5.5000000e-02],\n",
       "       [ 5.1175605e+04, -4.8299999e+00, -9.5800000e+02],\n",
       "       [ 5.1179582e+04, -5.1459999e+00, -2.4900000e+02],\n",
       "       [ 5.1181582e+04, -4.9180002e+00,  1.0000000e-01],\n",
       "       [ 5.1195695e+04, -5.1440001e+00,  7.1000002e-02],\n",
       "       [ 5.1223527e+04, -5.1820002e+00,  4.5000002e-02],\n",
       "       [ 5.1231562e+04, -5.3260002e+00,  5.7999998e-02],\n",
       "       [ 5.1275449e+04, -5.0009999e+00,  6.3000001e-02],\n",
       "       [ 5.1292480e+04, -4.9840002e+00,  6.4000003e-02],\n",
       "       [ 5.1300508e+04, -5.2240000e+00,  8.2000002e-02],\n",
       "       [ 5.1302379e+04, -5.1640000e+00,  7.4000001e-02],\n",
       "       [ 5.1319414e+04, -1.9990000e+00, -9.9000000e+01],\n",
       "       [ 5.1336383e+04, -5.1009998e+00,  5.9999999e-02],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_lcs[list_data_lcs.lcid == b\"b'9.5486.943'\"].lc_data.iloc[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9018617e+04, -4.3959999e+00,  1.0000000e-01],\n",
       "       [ 4.9059512e+04, -4.9980001e+00,  8.9000002e-02],\n",
       "       [ 4.9060492e+04, -5.0289998e+00,  8.6999997e-02],\n",
       "       [ 4.9061480e+04, -4.8569999e+00,  7.2999999e-02],\n",
       "       [ 4.9065648e+04, -5.0110002e+00,  9.6000001e-02],\n",
       "       [ 4.9068523e+04, -4.9050002e+00,  7.9000004e-02],\n",
       "       [ 4.9077484e+04, -5.2030001e+00,  9.0000004e-02],\n",
       "       [ 4.9094438e+04, -4.7940001e+00,  9.0000004e-02],\n",
       "       [ 4.9095438e+04, -4.9159999e+00,  9.4999999e-02],\n",
       "       [ 4.9096434e+04, -4.5700002e+00,  9.0000004e-02],\n",
       "       [ 4.9103434e+04, -5.1259999e+00,  7.4000001e-02],\n",
       "       [ 4.9120418e+04, -5.1310000e+00,  7.8000002e-02],\n",
       "       [ 4.9145398e+04, -6.1059999e+00, -4.5600000e+02],\n",
       "       [ 4.9283766e+04, -5.2230000e+00,  7.5999998e-02],\n",
       "       [ 4.9447633e+04, -4.8439999e+00,  9.7000003e-02],\n",
       "       [ 4.9458527e+04, -4.7319999e+00,  9.4999999e-02],\n",
       "       [ 4.9465496e+04, -4.7989998e+00,  1.0000000e-01],\n",
       "       [ 4.9518430e+04, -2.6750000e+00, -4.9830000e+03],\n",
       "       [ 4.9717684e+04, -4.8509998e+00,  7.9000004e-02],\n",
       "       [ 4.9759617e+04, -5.1669998e+00,  7.9000004e-02],\n",
       "       [ 4.9810586e+04, -4.8709998e+00,  9.7999997e-02],\n",
       "       [ 4.9872484e+04, -4.9910002e+00,  9.7000003e-02],\n",
       "       [ 4.9891410e+04, -4.8260002e+00,  9.4999999e-02],\n",
       "       [ 5.0107609e+04, -4.8369999e+00,  8.3999999e-02],\n",
       "       [ 5.0108609e+04, -4.6739998e+00,  9.7999997e-02],\n",
       "       [ 5.0123605e+04, -5.0270000e+00,  9.6000001e-02],\n",
       "       [ 5.0141516e+04, -5.0710001e+00,  6.6000000e-02],\n",
       "       [ 5.0151543e+04, -2.5030000e+00, -6.6530000e+03],\n",
       "       [ 5.0161602e+04, -5.7950001e+00,  6.6000000e-02],\n",
       "       [ 5.0219441e+04, -5.1079998e+00,  7.1999997e-02],\n",
       "       [ 5.0228508e+04, -4.9480000e+00,  9.8999999e-02],\n",
       "       [ 5.0461598e+04, -5.1040001e+00,  5.4000001e-02],\n",
       "       [ 5.0484703e+04, -4.6929998e+00,  9.6000001e-02],\n",
       "       [ 5.0507527e+04, -4.5500002e+00,  8.6999997e-02],\n",
       "       [ 5.0522562e+04, -4.8280001e+00,  8.6999997e-02],\n",
       "       [ 5.0523473e+04, -4.8810000e+00,  9.0999998e-02],\n",
       "       [ 5.0547578e+04, -4.9460001e+00,  9.7000003e-02],\n",
       "       [ 5.0550531e+04, -4.5560002e+00,  9.2000000e-02],\n",
       "       [ 5.0825516e+04, -3.5090001e+00, -3.7100000e+02],\n",
       "       [ 5.0834594e+04, -4.8140001e+00,  6.1999999e-02],\n",
       "       [ 5.0841551e+04, -4.2820001e+00,  9.0000004e-02],\n",
       "       [ 5.0842578e+04, -5.0879998e+00,  6.1000001e-02],\n",
       "       [ 5.0844508e+04, -4.9050002e+00,  8.1000000e-02],\n",
       "       [ 5.0875641e+04, -4.9870000e+00,  9.8999999e-02],\n",
       "       [ 5.1172562e+04, -5.1380000e+00,  5.5000000e-02],\n",
       "       [ 5.1175605e+04, -4.8299999e+00, -9.5800000e+02],\n",
       "       [ 5.1179582e+04, -5.1459999e+00, -2.4900000e+02],\n",
       "       [ 5.1181582e+04, -4.9180002e+00,  1.0000000e-01],\n",
       "       [ 5.1195695e+04, -5.1440001e+00,  7.1000002e-02],\n",
       "       [ 5.1223527e+04, -5.1820002e+00,  4.5000002e-02],\n",
       "       [ 5.1231562e+04, -5.3260002e+00,  5.7999998e-02],\n",
       "       [ 5.1275449e+04, -5.0009999e+00,  6.3000001e-02],\n",
       "       [ 5.1292480e+04, -4.9840002e+00,  6.4000003e-02],\n",
       "       [ 5.1300508e+04, -5.2240000e+00,  8.2000002e-02],\n",
       "       [ 5.1302379e+04, -5.1640000e+00,  7.4000001e-02],\n",
       "       [ 5.1319414e+04, -1.9990000e+00, -9.9000000e+01],\n",
       "       [ 5.1336383e+04, -5.1009998e+00,  5.9999999e-02]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_windows[dataset_windows.lcid == b\"b'9.5486.943'\"].lc_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "def assert_rank(tensor, expected_rank, name=None):\n",
    "  \"\"\"Raises an exception if the tensor rank is not of the expected rank.\n",
    "\n",
    "  Args:\n",
    "    tensor: A tf.Tensor to check the rank of.\n",
    "    expected_rank: Python integer or list of integers, expected rank.\n",
    "    name: Optional name of the tensor for the error message.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the expected shape doesn't match the actual shape.\n",
    "  \"\"\"\n",
    "  if name is None:\n",
    "    name = tensor.name\n",
    "\n",
    "  expected_rank_dict = {}\n",
    "  if isinstance(expected_rank, six.integer_types):\n",
    "    expected_rank_dict[expected_rank] = True\n",
    "  else:\n",
    "    for x in expected_rank:\n",
    "      expected_rank_dict[x] = True\n",
    "\n",
    "  actual_rank = tensor.shape.ndims\n",
    "  if actual_rank not in expected_rank_dict:\n",
    "    scope_name = tf.get_variable_scope().name\n",
    "    raise ValueError(\n",
    "        \"For the tensor `%s` in scope `%s`, the actual rank \"\n",
    "        \"`%d` (shape = %s) is not equal to the expected rank `%s`\" %\n",
    "        (name, scope_name, actual_rank, str(tensor.shape), str(expected_rank)))\n",
    "  \n",
    "\n",
    "def get_shape_list(tensor, expected_rank=None, name=None):\n",
    "  \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n",
    "\n",
    "  Args:\n",
    "    tensor: A tf.Tensor object to find the shape of.\n",
    "    expected_rank: (optional) int. The expected rank of `tensor`. If this is\n",
    "      specified and the `tensor` has a different rank, and exception will be\n",
    "      thrown.\n",
    "    name: Optional name of the tensor for the error message.\n",
    "\n",
    "  Returns:\n",
    "    A list of dimensions of the shape of tensor. All static dimensions will\n",
    "    be returned as python integers, and dynamic dimensions will be returned\n",
    "    as tf.Tensor scalars.\n",
    "  \"\"\"\n",
    "  if name is None:\n",
    "    name = tensor.name\n",
    "\n",
    "  if expected_rank is not None:\n",
    "    assert_rank(tensor, expected_rank, name)\n",
    "\n",
    "  shape = tensor.shape.as_list()\n",
    "\n",
    "  non_static_indexes = []\n",
    "  for (index, dim) in enumerate(shape):\n",
    "    if dim is None:\n",
    "      non_static_indexes.append(index)\n",
    "\n",
    "  if not non_static_indexes:\n",
    "    return shape\n",
    "\n",
    "  dyn_shape = tf.shape(tensor)\n",
    "  for index in non_static_indexes:\n",
    "    shape[index] = dyn_shape[index]\n",
    "  return shape\n",
    "\n",
    "\n",
    "def create_attention_mask_from_input_mask(from_tensor, to_mask):\n",
    "    \"\"\"Create 3D attention mask from a 2D tensor mask.\n",
    "\n",
    "    Args:\n",
    "    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].\n",
    "    to_mask: int32 Tensor of shape [batch_size, to_seq_length].\n",
    "\n",
    "    Returns:\n",
    "    float Tensor of shape [batch_size, from_seq_length, to_seq_length].\n",
    "    \"\"\"\n",
    "    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n",
    "    batch_size = from_shape[0]\n",
    "    from_seq_length = from_shape[1]\n",
    "\n",
    "    to_shape = get_shape_list(to_mask, expected_rank=2)\n",
    "    to_seq_length = to_shape[1]\n",
    "\n",
    "    to_mask = tf.cast(\n",
    "        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n",
    "\n",
    "    # We don't assume that `from_tensor` is a mask (although it could be). We\n",
    "    # don't actually care if we attend *from* padding tokens (only *to* padding)\n",
    "    # tokens so we create a tensor of all ones.\n",
    "    #\n",
    "    # `broadcast_ones` = [batch_size, from_seq_length, 1]\n",
    "    broadcast_ones = tf.ones(\n",
    "        shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n",
    "\n",
    "    # Here we broadcast along two dimensions to create the mask.\n",
    "    mask = broadcast_ones * to_mask\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 200, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_input_lc['att_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
