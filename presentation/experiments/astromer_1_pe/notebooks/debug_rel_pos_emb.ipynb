{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/dmoreno2016/ASTROMER/astromer_pe/astromer\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from src.data.record import deserialize\n",
    "from src.layers.positional import PositionalEmbedding\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = './data/records/alcock/fold_0/alcock_20/train'\n",
    "\n",
    "rec_paths = []\n",
    "for folder in os.listdir(path_dataset):\n",
    "    if folder.endswith('.csv'):\n",
    "        continue\n",
    "    for x in os.listdir(os.path.join(path_dataset, folder)):\n",
    "        rec_paths.append(os.path.join(path_dataset, folder, x))\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(rec_paths)    \n",
    "dataset = dataset.map(deserialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([635, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lc_info in dataset:\n",
    "    lc_data = lc_info['input']\n",
    "    break\n",
    "\n",
    "lc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 3), dtype=float32, numpy=\n",
       "array([[ 4.8917543e+04, -5.0609999e+00,  3.7999999e-02],\n",
       "       [ 4.8918762e+04, -5.0390000e+00,  3.4000002e-02],\n",
       "       [ 4.8919555e+04, -5.0730000e+00,  8.3999999e-02],\n",
       "       [ 4.8920539e+04, -5.1550002e+00,  2.8999999e-02],\n",
       "       [ 4.8927508e+04, -5.3639998e+00,  6.1999999e-02],\n",
       "       [ 4.8928543e+04, -5.0679998e+00,  4.3000001e-02],\n",
       "       [ 4.8929488e+04, -4.9740000e+00,  6.4000003e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_lc_data = lc_data[0:7,:]\n",
    "toy_lc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7, 1), dtype=float32, numpy=\n",
       "array([[[48917.543],\n",
       "        [48918.76 ],\n",
       "        [48919.555],\n",
       "        [48920.54 ],\n",
       "        [48927.508],\n",
       "        [48928.543],\n",
       "        [48929.49 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_lc_time = toy_lc_data[:,0]\n",
    "toy_lc_flux = toy_lc_data[:,1]\n",
    "\n",
    "toy_lc_time = tf.expand_dims(tf.expand_dims(toy_lc_time, 1), 0)\n",
    "toy_lc_flux = tf.expand_dims(tf.expand_dims(toy_lc_flux, 1), 0)\n",
    "\n",
    "toy_lc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import math\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "Initializer = tf.keras.initializers.Initializer\n",
    "\n",
    "def assert_rank(tensor, expected_rank, name=None):\n",
    "  \"\"\"Raises an exception if the tensor rank is not of the expected rank.\n",
    "\n",
    "  Args:\n",
    "    tensor: A tf.Tensor to check the rank of.\n",
    "    expected_rank: Python integer or list of integers, expected rank.\n",
    "    name: Optional name of the tensor for the error message.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the expected shape doesn't match the actual shape.\n",
    "  \"\"\"\n",
    "  expected_rank_dict = {}\n",
    "  if isinstance(expected_rank, six.integer_types):\n",
    "    expected_rank_dict[expected_rank] = True\n",
    "  else:\n",
    "    for x in expected_rank:\n",
    "      expected_rank_dict[x] = True\n",
    "\n",
    "  actual_rank = tensor.shape.ndims\n",
    "  if actual_rank not in expected_rank_dict:\n",
    "    raise ValueError(\n",
    "        \"For the tensor `%s`, the actual tensor rank `%d` (shape = %s) is not \"\n",
    "        \"equal to the expected tensor rank `%s`\" %\n",
    "        (name, actual_rank, str(tensor.shape), str(expected_rank)))\n",
    "\n",
    "def get_shape_list(tensor, expected_rank=None, name=None):\n",
    "  \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n",
    "\n",
    "  Args:\n",
    "    tensor: A tf.Tensor object to find the shape of.\n",
    "    expected_rank: (optional) int. The expected rank of `tensor`. If this is\n",
    "      specified and the `tensor` has a different rank, and exception will be\n",
    "      thrown.\n",
    "    name: Optional name of the tensor for the error message.\n",
    "\n",
    "  Returns:\n",
    "    A list of dimensions of the shape of tensor. All static dimensions will\n",
    "    be returned as python integers, and dynamic dimensions will be returned\n",
    "    as tf.Tensor scalars.\n",
    "  \"\"\"\n",
    "  if expected_rank is not None:\n",
    "    assert_rank(tensor, expected_rank, name)\n",
    "\n",
    "  shape = tensor.shape.as_list()\n",
    "\n",
    "  non_static_indexes = []\n",
    "  for (index, dim) in enumerate(shape):\n",
    "    if dim is None:\n",
    "      non_static_indexes.append(index)\n",
    "\n",
    "  if not non_static_indexes:\n",
    "    return shape\n",
    "\n",
    "  dyn_shape = tf.shape(tensor)\n",
    "  for index in non_static_indexes:\n",
    "    shape[index] = dyn_shape[index]\n",
    "  return shape\n",
    "\n",
    "def _relative_position_bucket(relative_position,\n",
    "                              bidirectional=True,\n",
    "                              num_buckets=32,\n",
    "                              max_distance=128):\n",
    "  \"\"\"Translate relative position to a bucket number for relative attention.\n",
    "\n",
    "  The relative position is defined as memory_position - query_position, i.e.\n",
    "  the distance in tokens from the attending position to the attended-to\n",
    "  position.\n",
    "\n",
    "  If `bidirectional=False`, then positive relative positions are invalid.\n",
    "\n",
    "  We use smaller buckets for small absolute relative_position and larger\n",
    "  buckets for larger absolute relative_positions.\n",
    "\n",
    "  All relative positions >=max_distance map to the same bucket.\n",
    "\n",
    "  All relative positions <=-max_distance map to the same bucket.\n",
    "\n",
    "  This should allow for more graceful generalization to longer sequences\n",
    "  than the model has been trained on.\n",
    "\n",
    "  Args:\n",
    "    relative_position: An int32 Tensor\n",
    "    bidirectional: A boolean - whether the attention is bidirectional\n",
    "    num_buckets: An integer\n",
    "    max_distance: An integer\n",
    "\n",
    "  Returns:\n",
    "    A Tensor with the same shape as relative_position, containing int32\n",
    "    values in the range [0, num_buckets)\n",
    "  \"\"\"\n",
    "  ret = 0\n",
    "  n = -relative_position\n",
    "  if bidirectional:\n",
    "    num_buckets //= 2\n",
    "    ret += tf.cast(tf.math.less(n, 0), tf.int32) * num_buckets\n",
    "    n = tf.math.abs(n)\n",
    "  else:\n",
    "    n = tf.math.maximum(n, 0)\n",
    "  # now n is in the range [0, inf)\n",
    "  max_exact = num_buckets // 2\n",
    "  is_small = tf.math.less(n, max_exact)\n",
    "  val_if_large = max_exact + tf.dtypes.cast(\n",
    "      tf.math.log(tf.cast(n, tf.float32) / max_exact) /\n",
    "      math.log(max_distance / max_exact) * (num_buckets - max_exact),\n",
    "      tf.int32,\n",
    "  )\n",
    "  val_if_large = tf.math.minimum(val_if_large, num_buckets - 1)\n",
    "  ret += tf.where(is_small, n, val_if_large)\n",
    "  return ret\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package=\"Text\")\n",
    "class RelativePositionBias(tf.keras.layers.Layer):\n",
    "  \"\"\"Relative position embedding via per-head bias in T5 style.\n",
    "\n",
    "  Reference implementation in MeshTF:\n",
    "  https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py#L1000\n",
    "\n",
    "  This layer implements the relative position bias used in \"Exploring the Limits\n",
    "  of Transfer Learning with a Unified Text-to-Text Transformer\"\n",
    "  (https://arxiv.org/abs/1910.10683)\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_heads: int,\n",
    "               relative_attention_num_buckets: int = 32,\n",
    "               relative_attention_max_distance: int = 128,\n",
    "               bidirectional: bool = True,\n",
    "               embeddings_initializer: Optional[Initializer] = None,\n",
    "               **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.num_heads = num_heads\n",
    "    self.relative_attention_num_buckets = relative_attention_num_buckets\n",
    "    self.bidirectional = bidirectional\n",
    "    self.relative_attention_max_distance = relative_attention_max_distance\n",
    "    if embeddings_initializer:\n",
    "      self._embed_init = embeddings_initializer\n",
    "    else:\n",
    "      self._embed_init = tf.keras.initializers.TruncatedNormal(stddev=1.0)\n",
    "    with tf.name_scope(self.name):\n",
    "      self._relative_attention_bias = self.add_weight(\n",
    "          \"rel_embedding\",\n",
    "          shape=[self.relative_attention_num_buckets, self.num_heads],\n",
    "          initializer=self._embed_init,\n",
    "          dtype=self.dtype,\n",
    "          trainable=True)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {\n",
    "        \"num_heads\":\n",
    "            self.num_heads,\n",
    "        \"relative_attention_num_buckets\":\n",
    "            self.relative_attention_num_buckets,\n",
    "        \"relative_attention_max_distance\":\n",
    "            self.relative_attention_max_distance,\n",
    "        \"bidirectional\":\n",
    "            self.bidirectional,\n",
    "        \"embeddings_initializer\":\n",
    "            tf.keras.initializers.serialize(self._embed_init),\n",
    "    }\n",
    "    base_config = super().get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "  def call(self, query: tf.Tensor, key: tf.Tensor):\n",
    "    \"\"\"Implements the forward pass.\n",
    "\n",
    "    Args:\n",
    "      query: query input tensor shape [batch, query length, hidden size].\n",
    "      key: key input tensor shape [batch, key length, hidden size].\n",
    "\n",
    "    Returns:\n",
    "      A tensor in shape of [batch, heads, query length, key length].\n",
    "    \"\"\"\n",
    "    batch_size, qlen = get_shape_list(query)[:2]\n",
    "    klen = get_shape_list(key)[1]\n",
    "    context_position = tf.range(qlen)[:, None]\n",
    "    memory_position = tf.range(klen)[None, :]\n",
    "    relative_position = memory_position - context_position\n",
    "    rp_bucket = _relative_position_bucket(\n",
    "        relative_position,\n",
    "        bidirectional=self.bidirectional,\n",
    "        num_buckets=self.relative_attention_num_buckets,\n",
    "        max_distance=self.relative_attention_max_distance)\n",
    "    values = tf.nn.embedding_lookup(self._relative_attention_bias, rp_bucket)\n",
    "    values = tf.expand_dims(\n",
    "        tf.transpose(values, [2, 0, 1]),\n",
    "        axis=0)  # shape (1, num_heads, qlen, klen)\n",
    "    values = tf.tile(values, [batch_size, 1, 1, 1])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7, 6), dtype=float32, numpy=\n",
       "array([[[ 0.13297616,  3.1281412 , -3.834384  , -0.81204396,\n",
       "         -3.8657029 , -1.9403491 ],\n",
       "        [ 0.13239811,  3.1145434 , -3.8177161 , -0.80851406,\n",
       "         -3.848899  , -1.9319146 ],\n",
       "        [ 0.13329145,  3.1355584 , -3.8434756 , -0.8139694 ,\n",
       "         -3.8748689 , -1.9449499 ],\n",
       "        [ 0.13544598,  3.1862416 , -3.9056017 , -0.82712644,\n",
       "         -3.9375024 , -1.9763882 ],\n",
       "        [ 0.14093739,  3.3154218 , -4.063947  , -0.86066073,\n",
       "         -4.097141  , -2.0565171 ],\n",
       "        [ 0.13316008,  3.1324677 , -3.8396873 , -0.81316715,\n",
       "         -3.8710496 , -1.9430329 ],\n",
       "        [ 0.13069026,  3.0743678 , -3.76847   , -0.79808474,\n",
       "         -3.7992504 , -1.9069941 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wq = tf.keras.layers.Dense(d_model, name='WQ')\n",
    "\n",
    "query = wq(toy_lc_flux)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 7]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_shape_list(query)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
