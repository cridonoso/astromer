{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a240ae6d-2e96-4ea3-b0ad-cc3e1ef2a7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/cdonoso/upastromer/astromer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/cdonoso/miniconda3/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2864227-5b4b-428e-b4cc-c9b625e1f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.data.loaders import get_loader, load_records_distributed, get_validation, run_pipeline\n",
    "from src.data.record import deserialize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb88e1b9-7afe-4220-bcef-a7c4718faaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath='./data/shared/records/bigmacho/train/'\n",
    "# output = get_loader(datapath, \n",
    "#                     batch_size=16, \n",
    "#                     window_size=200,\n",
    "#                     probed_frac=0.5,\n",
    "#                     random_frac=0.2,\n",
    "#                     same_frac=0.2,\n",
    "#                     distributed=True, \n",
    "#                     sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b6d841-b9af-4c5d-89cf-0b84d07ef787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0e7dee6-e5d6-4053-80a8-803dd9830429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading train and validation datasets\n"
     ]
    }
   ],
   "source": [
    "records_dir = './data/shared/records/bigmacho/train/'\n",
    "\n",
    "paths = get_validation(records_dir,\n",
    "                       validation=0.2, \n",
    "                       target_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04720aaa-1e69-4d5e-bd07-f3964eaf6cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling random windows\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(paths['train'][0])\n",
    "raw_dataset = raw_dataset.map(lambda x: deserialize(x, records_dir))\n",
    "raw_dataset = raw_dataset.map(lambda x: run_pipeline(raw_dataset,\n",
    "                                                     batch_size=5,\n",
    "                                                     window_size=200,\n",
    "                                                     probed_frac=0.5,\n",
    "                                                     random_frac=0.2,\n",
    "                                                     same_frac=0.2,\n",
    "                                                     sampling=True,\n",
    "                                                     shuffle=False,\n",
    "                                                     repeat=1,\n",
    "                                                     num_cls=None,\n",
    "                                                     normalize='zero-mean',\n",
    "                                                     cache=False,\n",
    "                                                     aversion='base'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0942f827-b666-4309-9782-7bd1ece03058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35f26f2a-6a9f-439e-a47b-fc7fd8fbbe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_VariantDataset element_spec={'input': TensorSpec(shape=(None, None), dtype=tf.float32, name=None), 'lcid': TensorSpec(shape=(), dtype=tf.string, name=None), 'length': TensorSpec(shape=(), dtype=tf.int32, name=None), 'mask': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "for x in raw_dataset:\n",
    "    print(x)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ffd41-bc80-4854-b22c-e75709d4784f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd392343-404b-4fdb-b944-76d9f8aa0be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
