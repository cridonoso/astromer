{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9008367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/cdonoso/astromer/ASTROMER\n"
     ]
    }
   ],
   "source": [
    "cd /home/users/cdonoso/astromer/ASTROMER/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2119607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56f45298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.encoder import Encoder\n",
    "from core.astromer import get_ASTROMER\n",
    "from core.data import pretraining_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fce98be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing labels\n",
      "[INFO] Processing labels\n"
     ]
    }
   ],
   "source": [
    "datapath = './data/records/alcock/fold_0/alcock_100/'\n",
    "num_cls = pd.read_csv(os.path.join(datapath, 'objects.csv')).shape[0]\n",
    "\n",
    "train_batches = pretraining_records(os.path.join(datapath, 'train'),\n",
    "                                    256, max_obs=200,\n",
    "                                    msk_frac=0., rnd_frac=0., same_frac=0.,\n",
    "                                    sampling=False, shuffle=True,\n",
    "                                    n_classes=num_cls)\n",
    "\n",
    "val_batches = pretraining_records(os.path.join(datapath, 'train'),\n",
    "                                  256, max_obs=200,\n",
    "                                  msk_frac=0., rnd_frac=0., same_frac=0.,\n",
    "                                  sampling=False, shuffle=False,\n",
    "                                  n_classes=num_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06cae9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file = os.path.join('./weights/astromer_10022021/finetuning/alcock_f1/', 'conf.json')\n",
    "with open(conf_file, 'r') as handle:\n",
    "    conf = json.load(handle)\n",
    "    \n",
    "model = get_ASTROMER(num_layers=conf['layers'],\n",
    "                     d_model   =conf['head_dim'],\n",
    "                     num_heads =conf['heads'],\n",
    "                     dff       =conf['dff'],\n",
    "                     base      =conf['base'],\n",
    "                     dropout   =conf['dropout'],\n",
    "                     maxlen    =conf['max_obs'],\n",
    "                     use_leak  =conf['use_leak'])\n",
    "\n",
    "weights_path = '{}/weights'.format('./weights/astromer_10022021/finetuning/alcock_f1/')\n",
    "model.load_weights(weights_path)\n",
    "model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c50de6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.get_layer('encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb57443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie  = Input(shape=(200, 1),\n",
    "              batch_size=None,\n",
    "              name='input')\n",
    "times  = Input(shape=(200, 1),\n",
    "              batch_size=None,\n",
    "              name='times')\n",
    "mask   = Input(shape=(200, 1),\n",
    "              batch_size=None,\n",
    "              name='mask')\n",
    "\n",
    "placeholder = {'input':serie,\n",
    "               'mask_in':mask,\n",
    "               'times':times}\n",
    "\n",
    "mask_in = 1.-placeholder['mask_in']\n",
    "x = encoder(placeholder, training=False)\n",
    "x = x * mask_in\n",
    "x = tf.reduce_sum(x, 1)/tf.reduce_sum(mask_in, 1)\n",
    "\n",
    "x = Dense(1024, name='FCN1')(x)\n",
    "x = Dense(512, name='FCN2')(x)\n",
    "x = Dense(256, name='FCN3')(x)\n",
    "x = Dense(num_cls, name='FCN4')(x)\n",
    "    \n",
    "clf = Model(inputs=placeholder, outputs=x, name=\"MLPCLF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a589148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLPCLF\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 200, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 200, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "times (InputLayer)              [(None, 200, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Encoder)               (None, None, 256)    660736      input[0][0]                      \n",
      "                                                                 mask[0][0]                       \n",
      "                                                                 times[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_6 (TFOpLambda) (None, 200, 1)       0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_6 (TFOpLambda) (None, 200, 256)     0           encoder[2][0]                    \n",
      "                                                                 tf.math.subtract_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_12 (TFOpLamb (None, 256)          0           tf.math.multiply_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_13 (TFOpLamb (None, 1)            0           tf.math.subtract_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_6 (TFOpLambda)  (None, 256)          0           tf.math.reduce_sum_12[0][0]      \n",
      "                                                                 tf.math.reduce_sum_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "FCN1 (Dense)                    (None, 1024)         263168      tf.math.truediv_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "FCN2 (Dense)                    (None, 512)          524800      FCN1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FCN3 (Dense)                    (None, 256)          131328      FCN2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FCN4 (Dense)                    (None, 6)            1542        FCN3[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 1,581,574\n",
      "Trainable params: 920,838\n",
      "Non-trainable params: 660,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca10e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss=CategoricalCrossentropy(from_logits=True),\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6acd20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 3s 288ms/step - loss: 16.9625 - accuracy: 0.1807 - val_loss: 9.9815 - val_accuracy: 0.1896\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 6.8471 - accuracy: 0.1472 - val_loss: 5.2183 - val_accuracy: 0.1821\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 3.2761 - accuracy: 0.1848 - val_loss: 2.6464 - val_accuracy: 0.2074\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 2.7035 - accuracy: 0.2005 - val_loss: 1.7725 - val_accuracy: 0.1786\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 2.0199 - accuracy: 0.2081 - val_loss: 1.8606 - val_accuracy: 0.2820\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.7669 - accuracy: 0.2101 - val_loss: 1.6948 - val_accuracy: 0.2601\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.7147 - accuracy: 0.2389 - val_loss: 1.6360 - val_accuracy: 0.2574\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.6084 - accuracy: 0.3128 - val_loss: 1.5513 - val_accuracy: 0.3333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.5589 - accuracy: 0.2731 - val_loss: 1.4977 - val_accuracy: 0.4079\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.4878 - accuracy: 0.3956 - val_loss: 1.4650 - val_accuracy: 0.4066\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.4661 - accuracy: 0.4079 - val_loss: 1.4242 - val_accuracy: 0.4182\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.4144 - accuracy: 0.4333 - val_loss: 1.3709 - val_accuracy: 0.4497\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.3708 - accuracy: 0.4442 - val_loss: 1.3440 - val_accuracy: 0.4572\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.3470 - accuracy: 0.4456 - val_loss: 1.3123 - val_accuracy: 0.4661\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.3122 - accuracy: 0.4634 - val_loss: 1.2799 - val_accuracy: 0.4778\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.2866 - accuracy: 0.4668 - val_loss: 1.2616 - val_accuracy: 0.4819\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.2730 - accuracy: 0.4586 - val_loss: 1.2492 - val_accuracy: 0.4805\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.2664 - accuracy: 0.4504 - val_loss: 1.2396 - val_accuracy: 0.4771\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.2637 - accuracy: 0.4470 - val_loss: 1.2392 - val_accuracy: 0.4750\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.2644 - accuracy: 0.4408 - val_loss: 1.2557 - val_accuracy: 0.4620\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 1.2713 - accuracy: 0.4374 - val_loss: 1.2771 - val_accuracy: 0.4634\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.2814 - accuracy: 0.4346 - val_loss: 1.2821 - val_accuracy: 0.4613\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.2978 - accuracy: 0.4298 - val_loss: 1.2541 - val_accuracy: 0.4709\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.3397 - accuracy: 0.4148 - val_loss: 1.2000 - val_accuracy: 0.4812\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.3926 - accuracy: 0.4100 - val_loss: 1.3076 - val_accuracy: 0.4613\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.3983 - accuracy: 0.4093 - val_loss: 1.4983 - val_accuracy: 0.4148\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.3754 - accuracy: 0.4107 - val_loss: 1.2098 - val_accuracy: 0.4935\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.2137 - accuracy: 0.4969 - val_loss: 1.1710 - val_accuracy: 0.5441\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.1906 - accuracy: 0.5051 - val_loss: 1.2285 - val_accuracy: 0.4668\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.2360 - accuracy: 0.4387 - val_loss: 1.1461 - val_accuracy: 0.5264\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.1715 - accuracy: 0.4873 - val_loss: 1.1444 - val_accuracy: 0.5209\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.1830 - accuracy: 0.4908 - val_loss: 1.1748 - val_accuracy: 0.4956\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.1836 - accuracy: 0.4942 - val_loss: 1.1617 - val_accuracy: 0.5051\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.1538 - accuracy: 0.5133 - val_loss: 1.1388 - val_accuracy: 0.5106\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.1362 - accuracy: 0.5236 - val_loss: 1.1199 - val_accuracy: 0.5195\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 1s 205ms/step - loss: 1.1237 - accuracy: 0.5229 - val_loss: 1.1055 - val_accuracy: 0.5380\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.1168 - accuracy: 0.5243 - val_loss: 1.1101 - val_accuracy: 0.5346\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.1252 - accuracy: 0.5133 - val_loss: 1.1329 - val_accuracy: 0.5332\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 1s 203ms/step - loss: 1.1377 - accuracy: 0.5161 - val_loss: 1.1403 - val_accuracy: 0.5332\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 1.1368 - accuracy: 0.5147 - val_loss: 1.1225 - val_accuracy: 0.5387\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.1202 - accuracy: 0.5243 - val_loss: 1.1027 - val_accuracy: 0.5483\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 1.1009 - accuracy: 0.5346 - val_loss: 1.0877 - val_accuracy: 0.5565\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0851 - accuracy: 0.5469 - val_loss: 1.0699 - val_accuracy: 0.5667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0693 - accuracy: 0.5626 - val_loss: 1.0523 - val_accuracy: 0.5777\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0620 - accuracy: 0.5715 - val_loss: 1.0482 - val_accuracy: 0.5880\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0627 - accuracy: 0.5743 - val_loss: 1.0461 - val_accuracy: 0.5770\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0653 - accuracy: 0.5667 - val_loss: 1.0442 - val_accuracy: 0.5777\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0711 - accuracy: 0.5599 - val_loss: 1.0411 - val_accuracy: 0.5838\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0804 - accuracy: 0.5510 - val_loss: 1.0337 - val_accuracy: 0.5955\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.1019 - accuracy: 0.5441 - val_loss: 1.0220 - val_accuracy: 0.5914\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.1498 - accuracy: 0.5236 - val_loss: 1.0707 - val_accuracy: 0.5462\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.2236 - accuracy: 0.4702 - val_loss: 1.1727 - val_accuracy: 0.5346\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.1667 - accuracy: 0.5086 - val_loss: 1.1185 - val_accuracy: 0.5455\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 1.0883 - accuracy: 0.5476 - val_loss: 1.0396 - val_accuracy: 0.5483\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0544 - accuracy: 0.5599 - val_loss: 1.0680 - val_accuracy: 0.5832\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0753 - accuracy: 0.5551 - val_loss: 1.0163 - val_accuracy: 0.5804\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 1.0329 - accuracy: 0.5777 - val_loss: 1.0051 - val_accuracy: 0.6016\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0473 - accuracy: 0.5770 - val_loss: 0.9887 - val_accuracy: 0.6105\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0209 - accuracy: 0.5873 - val_loss: 0.9788 - val_accuracy: 0.6215\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0284 - accuracy: 0.6010 - val_loss: 0.9832 - val_accuracy: 0.6057\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 1.0393 - accuracy: 0.5873 - val_loss: 0.9738 - val_accuracy: 0.6126\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0269 - accuracy: 0.5975 - val_loss: 0.9708 - val_accuracy: 0.6119\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.0400 - accuracy: 0.5907 - val_loss: 0.9748 - val_accuracy: 0.6057\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0499 - accuracy: 0.5832 - val_loss: 0.9741 - val_accuracy: 0.5975\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0432 - accuracy: 0.5811 - val_loss: 0.9771 - val_accuracy: 0.5914\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0384 - accuracy: 0.5818 - val_loss: 0.9891 - val_accuracy: 0.5743\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.0348 - accuracy: 0.5770 - val_loss: 0.9925 - val_accuracy: 0.5818\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0256 - accuracy: 0.5832 - val_loss: 0.9826 - val_accuracy: 0.5921\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 1.0210 - accuracy: 0.5907 - val_loss: 0.9705 - val_accuracy: 0.5982\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0164 - accuracy: 0.5907 - val_loss: 0.9581 - val_accuracy: 0.6071\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0021 - accuracy: 0.5996 - val_loss: 0.9459 - val_accuracy: 0.6208\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9862 - accuracy: 0.6003 - val_loss: 0.9403 - val_accuracy: 0.6283\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9836 - accuracy: 0.6071 - val_loss: 0.9429 - val_accuracy: 0.6372\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9877 - accuracy: 0.6044 - val_loss: 0.9467 - val_accuracy: 0.6290\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9943 - accuracy: 0.6016 - val_loss: 0.9501 - val_accuracy: 0.6235\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0037 - accuracy: 0.5927 - val_loss: 0.9548 - val_accuracy: 0.6256\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0066 - accuracy: 0.5982 - val_loss: 0.9588 - val_accuracy: 0.6215\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0048 - accuracy: 0.6010 - val_loss: 0.9562 - val_accuracy: 0.6242\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9910 - accuracy: 0.6078 - val_loss: 0.9425 - val_accuracy: 0.6331\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9749 - accuracy: 0.6140 - val_loss: 0.9310 - val_accuracy: 0.6434\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 1s 187ms/step - loss: 0.9681 - accuracy: 0.6188 - val_loss: 0.9267 - val_accuracy: 0.6461\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9873 - accuracy: 0.5921 - val_loss: 0.9354 - val_accuracy: 0.6345\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 1.0258 - accuracy: 0.5791 - val_loss: 0.9774 - val_accuracy: 0.5982\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0618 - accuracy: 0.5832 - val_loss: 0.9729 - val_accuracy: 0.6112\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0445 - accuracy: 0.5914 - val_loss: 1.0144 - val_accuracy: 0.6016\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9371 - accuracy: 0.6256 - val_loss: 0.9286 - val_accuracy: 0.6119\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 1.0103 - accuracy: 0.5921 - val_loss: 1.0159 - val_accuracy: 0.6105\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9596 - accuracy: 0.6235 - val_loss: 0.9047 - val_accuracy: 0.6701\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 1s 202ms/step - loss: 0.9411 - accuracy: 0.6263 - val_loss: 0.8957 - val_accuracy: 0.6810\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9500 - accuracy: 0.6311 - val_loss: 0.9338 - val_accuracy: 0.6420\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9740 - accuracy: 0.5941 - val_loss: 0.9277 - val_accuracy: 0.6434\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0077 - accuracy: 0.6010 - val_loss: 0.9486 - val_accuracy: 0.6345\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.0222 - accuracy: 0.6037 - val_loss: 0.9240 - val_accuracy: 0.6523\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9538 - accuracy: 0.6318 - val_loss: 0.9331 - val_accuracy: 0.6715\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.9679 - accuracy: 0.6146 - val_loss: 0.9062 - val_accuracy: 0.6646\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.9979 - accuracy: 0.6044 - val_loss: 0.9003 - val_accuracy: 0.6489\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9756 - accuracy: 0.6222 - val_loss: 0.9261 - val_accuracy: 0.6242\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 1.0099 - accuracy: 0.6051 - val_loss: 1.0090 - val_accuracy: 0.5982\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9842 - accuracy: 0.6037 - val_loss: 0.9267 - val_accuracy: 0.6386\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0017 - accuracy: 0.5852 - val_loss: 0.9362 - val_accuracy: 0.6188\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9725 - accuracy: 0.6023 - val_loss: 0.9409 - val_accuracy: 0.6372\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0296 - accuracy: 0.6057 - val_loss: 0.9403 - val_accuracy: 0.6174\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9753 - accuracy: 0.6318 - val_loss: 0.9322 - val_accuracy: 0.6598\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9284 - accuracy: 0.6372 - val_loss: 0.8984 - val_accuracy: 0.6448\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.9327 - accuracy: 0.6372 - val_loss: 0.8890 - val_accuracy: 0.6701\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9348 - accuracy: 0.6413 - val_loss: 0.8973 - val_accuracy: 0.6619\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9121 - accuracy: 0.6434 - val_loss: 0.8752 - val_accuracy: 0.6783\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9480 - accuracy: 0.6188 - val_loss: 0.8990 - val_accuracy: 0.6516\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9440 - accuracy: 0.6174 - val_loss: 0.8954 - val_accuracy: 0.6557\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.9886 - accuracy: 0.6235 - val_loss: 0.9165 - val_accuracy: 0.6338\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9556 - accuracy: 0.6290 - val_loss: 0.8701 - val_accuracy: 0.6769\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.9690 - accuracy: 0.6222 - val_loss: 0.9412 - val_accuracy: 0.6366\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 1s 202ms/step - loss: 0.9087 - accuracy: 0.6393 - val_loss: 0.8704 - val_accuracy: 0.6831\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9497 - accuracy: 0.6099 - val_loss: 0.8833 - val_accuracy: 0.6598\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9625 - accuracy: 0.6010 - val_loss: 0.9150 - val_accuracy: 0.6318\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9641 - accuracy: 0.6201 - val_loss: 0.9118 - val_accuracy: 0.6461\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9754 - accuracy: 0.6270 - val_loss: 0.9092 - val_accuracy: 0.6427\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9216 - accuracy: 0.6578 - val_loss: 0.9029 - val_accuracy: 0.6667\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9052 - accuracy: 0.6468 - val_loss: 0.8855 - val_accuracy: 0.6626\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9293 - accuracy: 0.6331 - val_loss: 0.8984 - val_accuracy: 0.6407\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.9449 - accuracy: 0.6126 - val_loss: 0.9019 - val_accuracy: 0.6489\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9751 - accuracy: 0.6270 - val_loss: 0.9061 - val_accuracy: 0.6427\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9617 - accuracy: 0.6359 - val_loss: 0.8698 - val_accuracy: 0.6735\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.9232 - accuracy: 0.6537 - val_loss: 0.8767 - val_accuracy: 0.6851\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.8920 - accuracy: 0.6591 - val_loss: 0.8553 - val_accuracy: 0.6934\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.9137 - accuracy: 0.6420 - val_loss: 0.8702 - val_accuracy: 0.6701\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9124 - accuracy: 0.6366 - val_loss: 0.8672 - val_accuracy: 0.6783\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9391 - accuracy: 0.6420 - val_loss: 0.8807 - val_accuracy: 0.6598\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9282 - accuracy: 0.6434 - val_loss: 0.8731 - val_accuracy: 0.6762\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9589 - accuracy: 0.6372 - val_loss: 0.8878 - val_accuracy: 0.6605\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9167 - accuracy: 0.6454 - val_loss: 0.8526 - val_accuracy: 0.6975\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.9361 - accuracy: 0.6407 - val_loss: 0.9000 - val_accuracy: 0.6701\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9090 - accuracy: 0.6413 - val_loss: 0.8545 - val_accuracy: 0.6927\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9934 - accuracy: 0.5934 - val_loss: 0.9002 - val_accuracy: 0.6564\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 1.0486 - accuracy: 0.5969 - val_loss: 0.9580 - val_accuracy: 0.6242\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0335 - accuracy: 0.5921 - val_loss: 0.9906 - val_accuracy: 0.6201\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9289 - accuracy: 0.6489 - val_loss: 0.9243 - val_accuracy: 0.6366\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9414 - accuracy: 0.6181 - val_loss: 0.9376 - val_accuracy: 0.6701\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9319 - accuracy: 0.6366 - val_loss: 0.8706 - val_accuracy: 0.6715\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9088 - accuracy: 0.6502 - val_loss: 0.8754 - val_accuracy: 0.6934\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8874 - accuracy: 0.6523 - val_loss: 0.8569 - val_accuracy: 0.6934\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9052 - accuracy: 0.6434 - val_loss: 0.8658 - val_accuracy: 0.6680\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9195 - accuracy: 0.6345 - val_loss: 0.8691 - val_accuracy: 0.6653\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9286 - accuracy: 0.6359 - val_loss: 0.8759 - val_accuracy: 0.6598\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9180 - accuracy: 0.6468 - val_loss: 0.8706 - val_accuracy: 0.6646\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.9159 - accuracy: 0.6516 - val_loss: 0.8636 - val_accuracy: 0.6687\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8933 - accuracy: 0.6591 - val_loss: 0.8506 - val_accuracy: 0.6865\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.8965 - accuracy: 0.6516 - val_loss: 0.8556 - val_accuracy: 0.6742\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9059 - accuracy: 0.6263 - val_loss: 0.8571 - val_accuracy: 0.6715\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9365 - accuracy: 0.6235 - val_loss: 0.8886 - val_accuracy: 0.6537\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9662 - accuracy: 0.6434 - val_loss: 0.8747 - val_accuracy: 0.6674\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9636 - accuracy: 0.6468 - val_loss: 0.9265 - val_accuracy: 0.6783\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8797 - accuracy: 0.6708 - val_loss: 0.8479 - val_accuracy: 0.7016\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9031 - accuracy: 0.6393 - val_loss: 0.8557 - val_accuracy: 0.6906\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8891 - accuracy: 0.6489 - val_loss: 0.8529 - val_accuracy: 0.6920\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9040 - accuracy: 0.6393 - val_loss: 0.8499 - val_accuracy: 0.6940\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9344 - accuracy: 0.6235 - val_loss: 0.8549 - val_accuracy: 0.6851\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9569 - accuracy: 0.6099 - val_loss: 0.8850 - val_accuracy: 0.6571\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9699 - accuracy: 0.6235 - val_loss: 0.9152 - val_accuracy: 0.6393\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9918 - accuracy: 0.6256 - val_loss: 0.9167 - val_accuracy: 0.6454\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9717 - accuracy: 0.6311 - val_loss: 1.0399 - val_accuracy: 0.6277\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9396 - accuracy: 0.6277 - val_loss: 0.9099 - val_accuracy: 0.6441\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.9233 - accuracy: 0.6345 - val_loss: 0.8656 - val_accuracy: 0.6899\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9019 - accuracy: 0.6482 - val_loss: 0.8654 - val_accuracy: 0.6858\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8721 - accuracy: 0.6667 - val_loss: 0.8481 - val_accuracy: 0.7043\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9122 - accuracy: 0.6427 - val_loss: 0.8547 - val_accuracy: 0.6865\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 1s 191ms/step - loss: 0.8885 - accuracy: 0.6530 - val_loss: 0.8397 - val_accuracy: 0.6961\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8995 - accuracy: 0.6530 - val_loss: 0.8469 - val_accuracy: 0.6879\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9052 - accuracy: 0.6509 - val_loss: 0.8513 - val_accuracy: 0.6817\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9058 - accuracy: 0.6496 - val_loss: 0.8502 - val_accuracy: 0.6783\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8978 - accuracy: 0.6516 - val_loss: 0.8509 - val_accuracy: 0.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "6/6 [==============================] - 1s 202ms/step - loss: 0.8881 - accuracy: 0.6619 - val_loss: 0.8469 - val_accuracy: 0.6838\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.8895 - accuracy: 0.6585 - val_loss: 0.8489 - val_accuracy: 0.6790\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8916 - accuracy: 0.6400 - val_loss: 0.8490 - val_accuracy: 0.6762\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.9129 - accuracy: 0.6201 - val_loss: 0.8631 - val_accuracy: 0.6626\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9357 - accuracy: 0.6407 - val_loss: 0.8968 - val_accuracy: 0.6516\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.9733 - accuracy: 0.6229 - val_loss: 0.8726 - val_accuracy: 0.6838\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8694 - accuracy: 0.6858 - val_loss: 0.8520 - val_accuracy: 0.6831\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8893 - accuracy: 0.6441 - val_loss: 0.8622 - val_accuracy: 0.6804\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.8678 - accuracy: 0.6571 - val_loss: 0.8478 - val_accuracy: 0.6961\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8914 - accuracy: 0.6489 - val_loss: 0.8459 - val_accuracy: 0.6954\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.8780 - accuracy: 0.6571 - val_loss: 0.8363 - val_accuracy: 0.6920\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8967 - accuracy: 0.6359 - val_loss: 0.8480 - val_accuracy: 0.6776\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9102 - accuracy: 0.6372 - val_loss: 0.8689 - val_accuracy: 0.6660\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9298 - accuracy: 0.6482 - val_loss: 0.8640 - val_accuracy: 0.6687\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.9304 - accuracy: 0.6482 - val_loss: 0.8552 - val_accuracy: 0.7036\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8732 - accuracy: 0.6749 - val_loss: 0.8424 - val_accuracy: 0.7043\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8836 - accuracy: 0.6585 - val_loss: 0.8468 - val_accuracy: 0.6961\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8701 - accuracy: 0.6550 - val_loss: 0.8345 - val_accuracy: 0.6940\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8934 - accuracy: 0.6509 - val_loss: 0.8409 - val_accuracy: 0.6940\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8813 - accuracy: 0.6585 - val_loss: 0.8341 - val_accuracy: 0.6961\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9097 - accuracy: 0.6475 - val_loss: 0.8391 - val_accuracy: 0.6913\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9033 - accuracy: 0.6496 - val_loss: 0.8389 - val_accuracy: 0.6934\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9269 - accuracy: 0.6496 - val_loss: 0.8527 - val_accuracy: 0.6797\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9204 - accuracy: 0.6557 - val_loss: 0.8388 - val_accuracy: 0.7002\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 1s 192ms/step - loss: 0.9205 - accuracy: 0.6557 - val_loss: 0.8659 - val_accuracy: 0.6920\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8843 - accuracy: 0.6619 - val_loss: 0.8710 - val_accuracy: 0.6831\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8973 - accuracy: 0.6434 - val_loss: 0.8765 - val_accuracy: 0.6797\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.9272 - accuracy: 0.6229 - val_loss: 0.8467 - val_accuracy: 0.6893\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9670 - accuracy: 0.6194 - val_loss: 0.8619 - val_accuracy: 0.6694\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9307 - accuracy: 0.6420 - val_loss: 0.9208 - val_accuracy: 0.6502\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9008 - accuracy: 0.6502 - val_loss: 0.8438 - val_accuracy: 0.6934\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8678 - accuracy: 0.6694 - val_loss: 0.8432 - val_accuracy: 0.7077\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8929 - accuracy: 0.6530 - val_loss: 0.8588 - val_accuracy: 0.6742\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.8943 - accuracy: 0.6324 - val_loss: 0.8481 - val_accuracy: 0.6762\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9078 - accuracy: 0.6448 - val_loss: 0.8771 - val_accuracy: 0.6564\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.9779 - accuracy: 0.6215 - val_loss: 0.8896 - val_accuracy: 0.6509\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8962 - accuracy: 0.6694 - val_loss: 0.8704 - val_accuracy: 0.6920\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8621 - accuracy: 0.6715 - val_loss: 0.8336 - val_accuracy: 0.7002\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8712 - accuracy: 0.6749 - val_loss: 0.8490 - val_accuracy: 0.7009\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8600 - accuracy: 0.6687 - val_loss: 0.8376 - val_accuracy: 0.7009\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8687 - accuracy: 0.6619 - val_loss: 0.8296 - val_accuracy: 0.6968\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8716 - accuracy: 0.6797 - val_loss: 0.8305 - val_accuracy: 0.6940\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8797 - accuracy: 0.6701 - val_loss: 0.8355 - val_accuracy: 0.6886\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.8780 - accuracy: 0.6646 - val_loss: 0.8361 - val_accuracy: 0.6865\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8871 - accuracy: 0.6626 - val_loss: 0.8442 - val_accuracy: 0.6762\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.8904 - accuracy: 0.6612 - val_loss: 0.8508 - val_accuracy: 0.6721\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8889 - accuracy: 0.6639 - val_loss: 0.8497 - val_accuracy: 0.6810\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.8852 - accuracy: 0.6632 - val_loss: 0.8467 - val_accuracy: 0.6865\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8890 - accuracy: 0.6537 - val_loss: 0.8395 - val_accuracy: 0.6906\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9301 - accuracy: 0.6167 - val_loss: 0.8355 - val_accuracy: 0.6872\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.9973 - accuracy: 0.6037 - val_loss: 0.9631 - val_accuracy: 0.6270\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 1.0907 - accuracy: 0.5982 - val_loss: 1.1526 - val_accuracy: 0.5373\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.0850 - accuracy: 0.5544 - val_loss: 0.9107 - val_accuracy: 0.6721\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9480 - accuracy: 0.6263 - val_loss: 0.9268 - val_accuracy: 0.6612\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9325 - accuracy: 0.6338 - val_loss: 0.8807 - val_accuracy: 0.6817\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.9204 - accuracy: 0.6311 - val_loss: 0.9560 - val_accuracy: 0.6242\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.9347 - accuracy: 0.6167 - val_loss: 0.8879 - val_accuracy: 0.6708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.8932 - accuracy: 0.6468 - val_loss: 0.8517 - val_accuracy: 0.6988\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8689 - accuracy: 0.6749 - val_loss: 0.8494 - val_accuracy: 0.6988\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.8707 - accuracy: 0.6571 - val_loss: 0.8459 - val_accuracy: 0.6831\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8779 - accuracy: 0.6660 - val_loss: 0.8487 - val_accuracy: 0.6824\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.8710 - accuracy: 0.6667 - val_loss: 0.8342 - val_accuracy: 0.6954\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.8767 - accuracy: 0.6687 - val_loss: 0.8316 - val_accuracy: 0.6934\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8856 - accuracy: 0.6653 - val_loss: 0.8327 - val_accuracy: 0.6872\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.8884 - accuracy: 0.6598 - val_loss: 0.8401 - val_accuracy: 0.6879\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.8843 - accuracy: 0.6626 - val_loss: 0.8436 - val_accuracy: 0.6879\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8769 - accuracy: 0.6612 - val_loss: 0.8380 - val_accuracy: 0.6940\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8740 - accuracy: 0.6612 - val_loss: 0.8332 - val_accuracy: 0.6968\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.8766 - accuracy: 0.6605 - val_loss: 0.8298 - val_accuracy: 0.6886\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 1s 192ms/step - loss: 0.8861 - accuracy: 0.6598 - val_loss: 0.8311 - val_accuracy: 0.6845\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.8981 - accuracy: 0.6543 - val_loss: 0.8423 - val_accuracy: 0.6776\n"
     ]
    }
   ],
   "source": [
    "estop = EarlyStopping(monitor='val_loss',\n",
    "                      min_delta=0,\n",
    "                      patience=30,\n",
    "                      verbose=0,\n",
    "                      mode='auto',\n",
    "                      baseline=None,\n",
    "                      restore_best_weights=True)\n",
    "    \n",
    "_ = clf.fit(train_batches,\n",
    "            epochs=1000,\n",
    "            callbacks=[estop],\n",
    "            validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bbb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
