{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f82b6f2",
   "metadata": {},
   "source": [
    "# Creating records \n",
    "## Pipeline 2.0\n",
    "##### ASTROMER dev team\n",
    "\n",
    "*JAN 17 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135c8403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/astromer\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/astromer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb0e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from src.data.record import DataPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dd79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METAPATH = './data/raw_data/alcock/metadata.csv'\n",
    "# LCDIR = 'LCs/' \n",
    "LCDIR = './data/raw_data/alcock/LCs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dfb7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Class'] = pd.Categorical(metadata['Class'])\n",
    "metadata['Label'] = metadata['Class'].cat.codes\n",
    "metadata['Path'] = metadata['Path'].apply(lambda x: os.path.join(LCDIR, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234d8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>22.4385.13</td>\n",
       "      <td>LPV</td>\n",
       "      <td>./data/raw_data/alcock/LCs/22.4385.13.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Class                                       Path  Band  Label\n",
       "7509  22.4385.13   LPV  ./data/raw_data/alcock/LCs/22.4385.13.dat   1.0      3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sample()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d039028e",
   "metadata": {},
   "source": [
    "### Using DataPipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a39da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "pipeline = DataPipeline(metadata=metadata, \n",
    "                        context_features=['ID', 'Label', 'Class'],\n",
    "                        sequential_features=['mjd', 'mag'],)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "064aad8b",
   "metadata": {},
   "source": [
    "To create training, validation, and testing splits we need to use the `train_val_test` method \n",
    "```\n",
    "train_val_test(val_frac=0.2,\n",
    "               test_frac=0.2,\n",
    "               test_meta=None,\n",
    "               val_meta=None,\n",
    "               shuffle=True,\n",
    "               id_column_name=None,\n",
    "               k_fold=1)\n",
    "``` \n",
    "where `val_frac` and `test_frac` are percentages containing the fraction of the metadata to be used as validation and testing subset respectively. \n",
    "\n",
    "Additionally, you can use `val_meta` and `test_meta` to use a preselected subset. **Notice that if you employ your own test/val subset, you should match one of the identifier columns of the main DataFrame** (by default it will assume the first column of the dataset is the identifier). \n",
    "\n",
    "Both `test_meta` and `val_meta` must be list of `DataFrames`\n",
    "\n",
    "For cross-validation purposes, we can also sample different folds from the same dataset by using the `train_val_test(..., k_fold=1)` parameter.\n",
    "\n",
    "If $k>1$ and **you want to use a predefined test/val selection**, you should pass a list of `DataFrame`s associated with each `test_meta`/`val_meta` fold as appropriate.\n",
    "\n",
    "Don't worry about removing duplicated indices, the `train_val_test` method will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "918c742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = metadata.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f193ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "k_folds = 4\n",
    "\n",
    "pipeline.train_val_test(val_frac=0.2, \n",
    "                        test_meta=[test_metadata], \n",
    "                        k_fold=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "013795b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do 4-folds partitions have the same elements:  False\n",
      "Do 4-folds partitions have the same elements:  False\n",
      "Do 4-folds partitions have the same elements:  False\n"
     ]
    }
   ],
   "source": [
    "a = pipeline.metadata['subset_0']\n",
    "for k in range(k_folds):\n",
    "    if k == 0: continue\n",
    "    b = pipeline.metadata[f'subset_{k}']\n",
    "    c = np.array_equal(a[a != 'test'].values, b[b!= 'test'].values)\n",
    "    a = b\n",
    "    print('Do {}-folds partitions have the same elements: '.format(k_folds), c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9bcf6f3",
   "metadata": {},
   "source": [
    "Now our metadata will contain an extra-column `subset` for the corresponding subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f631c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "      <th>subset_0</th>\n",
       "      <th>subset_1</th>\n",
       "      <th>subset_2</th>\n",
       "      <th>subset_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>6.6940.7522</td>\n",
       "      <td>RRab</td>\n",
       "      <td>./data/raw_data/alcock/LCs/6.6940.7522.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>validation</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>5.4646.26</td>\n",
       "      <td>LPV</td>\n",
       "      <td>./data/raw_data/alcock/LCs/5.4646.26.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>17.2351.24</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/17.2351.24.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID Class                                        Path  Band  \\\n",
       "12966  6.6940.7522  RRab  ./data/raw_data/alcock/LCs/6.6940.7522.dat   1.0   \n",
       "10451    5.4646.26   LPV    ./data/raw_data/alcock/LCs/5.4646.26.dat   1.0   \n",
       "4828    17.2351.24    EC   ./data/raw_data/alcock/LCs/17.2351.24.dat   1.0   \n",
       "\n",
       "       Label    subset_0 subset_1    subset_2 subset_3  \n",
       "12966      4       train    train  validation    train  \n",
       "10451      3  validation    train        test     test  \n",
       "4828       2       train     test  validation    train  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e6e88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17075, 9) (4269, 9) (100, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(13724, 9) (3431, 9) (4289, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(13724, 9) (3431, 9) (4289, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(13724, 9) (3431, 9) (4289, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n"
     ]
    }
   ],
   "source": [
    "for k in range(k_folds):\n",
    "    train_subset = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'train']\n",
    "    val_subset   = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'validation']\n",
    "    test_subset  = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'test']\n",
    "\n",
    "    print(train_subset.shape, val_subset.shape, test_subset.shape)\n",
    "\n",
    "    print('test in train?: ', test_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "          'val in train?: ', val_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "          'val in test?: ', val_subset['ID'].isin(test_subset['ID']).all())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e25b1f",
   "metadata": {},
   "source": [
    "Notice if you want to redo, you must initialize the object `DataPipeline` again"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3377c4fe",
   "metadata": {},
   "source": [
    "Now it is **time to the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "923c9a2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train subset_0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writting train fold 0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/4 [00:16<?, ?it/s]    2023-06-21 08:48:47.100215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:47.293041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:47.293726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:47.299367: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 08:48:47.301907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:47.302580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:47.303129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:49.563427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:49.564038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:49.564600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 08:48:49.565142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13791 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "Writting test fold 3:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/4 [02:05<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 9.38 s, total: 1min 47s\n",
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = pipeline.run(n_jobs=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "671b92d9",
   "metadata": {},
   "source": [
    "### Customize the preprocessing method of DataPipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a1231e7",
   "metadata": {},
   "source": [
    "You must keep the same parameters of the method i.e., `row, context_features, sequential_features`. \n",
    "\n",
    "Also the **output** should be tuple containing the lightcurve (`pd.DataFrame`) and the context values (`dict`)\n",
    "\n",
    "\n",
    "To modify the `process_sample` method we need to create a new class (`MyPipeline`) that inherits from `DataPipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f73c94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipeline(DataPipeline):\n",
    "    @staticmethod\n",
    "    def process_sample(row, context_features, sequential_features):\n",
    "        observations = pd.read_csv(row['Path'])\n",
    "        observations.columns = ['mjd', 'mag', 'errmag']\n",
    "        observations = observations.dropna()\n",
    "        observations.sort_values('mjd')\n",
    "        observations[observations['errmag'] < 1]\n",
    "        context_features_values = row[context_features]\n",
    "        return observations, context_features_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4534f698",
   "metadata": {},
   "source": [
    "Next steps are the same as using the original `DataPipeline` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3fb0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = MyPipeline(metadata=metadata, \n",
    "                             context_features=['ID', 'Label', 'Class'],\n",
    "                             sequential_features=['mjd', 'mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "817b9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing full subset_0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writting full fold 0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/1 [00:29<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 1.37 s, total: 29.9 s\n",
      "Wall time: 30 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = custom_pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb81f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f6480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
