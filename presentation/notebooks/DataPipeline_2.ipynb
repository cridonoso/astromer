{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f82b6f2",
   "metadata": {},
   "source": [
    "# Creating records \n",
    "## Pipeline 2.0\n",
    "##### ASTROMER dev team\n",
    "\n",
    "*July 07 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c8403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb0e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:53:17.920837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 17:53:18.028724: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from src.data.record import DataPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9dd79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METAPATH = './data/raw_data/alcock/new_metadata.parquet'\n",
    "OBSPATH  = './data/raw_data/alcock/parquets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_parquet(METAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfb7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Class'] = pd.Categorical(metadata['Class'])\n",
    "metadata['Label'] = metadata['Class'].cat.codes\n",
    "metadata['Path'] = metadata['Path'].apply(lambda x: os.path.join(OBSPATH, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234d8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>newID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19033</th>\n",
       "      <td>81.8878.45</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/raw_data/alcock/parquets/81.8878.45.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Class                                            Path  Band  \\\n",
       "19033  81.8878.45     0  ./data/raw_data/alcock/parquets/81.8878.45.dat   1.0   \n",
       "\n",
       "       newID  Label  \n",
       "19033  19033      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039028e",
   "metadata": {},
   "source": [
    "### Using DataPipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a39da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of DataPipeline\n",
    "config_path = './data/raw_data/alcock/config.toml'\n",
    "pipeline = DataPipeline(metadata=metadata,\n",
    "                        config_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4df0757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['float', 'float', 'float']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.sequential_features_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064aad8b",
   "metadata": {},
   "source": [
    "To create training, validation, and testing splits we need to use the `train_val_test` method \n",
    "```\n",
    "train_val_test(val_frac=0.2,\n",
    "               test_frac=0.2,\n",
    "               test_meta=None,\n",
    "               val_meta=None,\n",
    "               shuffle=True,\n",
    "               id_column_name=None,\n",
    "               k_fold=1)\n",
    "``` \n",
    "where `val_frac` and `test_frac` are percentages containing the fraction of the metadata to be used as validation and testing subset respectively. \n",
    "\n",
    "Additionally, you can use `val_meta` and `test_meta` to use a preselected subset. **Notice that if you employ your own test/val subset, you should match one of the identifier columns of the main DataFrame** (by default it will assume the first column of the dataset is the identifier). \n",
    "\n",
    "Both `test_meta` and `val_meta` must be list of `DataFrames`\n",
    "\n",
    "For cross-validation purposes, we can also sample different folds from the same dataset by using the `train_val_test(..., k_fold=1)` parameter.\n",
    "\n",
    "If $k>1$ and **you want to use a predefined test/val selection**, you should pass a list of `DataFrame`s associated with each `test_meta`/`val_meta` fold as appropriate.\n",
    "\n",
    "Don't worry about removing duplicated indices, the `train_val_test` method will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918c742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = metadata.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f193ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "k_folds = 3\n",
    "pipeline.train_val_test(val_frac=0.2, \n",
    "                        test_meta=[test_metadata]*k_folds, \n",
    "                        k_fold=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013795b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do 3-folds partitions have the same elements:  False\n",
      "Do 3-folds partitions have the same elements:  False\n"
     ]
    }
   ],
   "source": [
    "a = pipeline.metadata['subset_0']\n",
    "for k in range(k_folds):\n",
    "    if k == 0: continue\n",
    "    b = pipeline.metadata[f'subset_{k}']\n",
    "    c = np.array_equal(a[a != 'test'].values, b[b!= 'test'].values)\n",
    "    a = b\n",
    "    print('Do {}-folds partitions have the same elements: '.format(k_folds), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcf6f3",
   "metadata": {},
   "source": [
    "Now our metadata will contain an extra-column `subset` for the corresponding subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f631c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>newID</th>\n",
       "      <th>Label</th>\n",
       "      <th>subset_0</th>\n",
       "      <th>subset_1</th>\n",
       "      <th>subset_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17937</th>\n",
       "      <td>80.6473.1946</td>\n",
       "      <td>4</td>\n",
       "      <td>./data/raw_data/alcock/parquets/80.6473.1946.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17937</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7746</th>\n",
       "      <td>22.4985.129</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/raw_data/alcock/parquets/22.4985.129.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7746</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14255</th>\n",
       "      <td>76.10084.1146</td>\n",
       "      <td>2</td>\n",
       "      <td>./data/raw_data/alcock/parquets/76.10084.1146.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14255</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID Class                                               Path  \\\n",
       "17937   80.6473.1946     4   ./data/raw_data/alcock/parquets/80.6473.1946.dat   \n",
       "7746     22.4985.129     0    ./data/raw_data/alcock/parquets/22.4985.129.dat   \n",
       "14255  76.10084.1146     2  ./data/raw_data/alcock/parquets/76.10084.1146.dat   \n",
       "\n",
       "       Band  newID  Label subset_0 subset_1    subset_2  \n",
       "17937   1.0  17937      4    train    train       train  \n",
       "7746    1.0   7746      0    train    train       train  \n",
       "14255   1.0  14255      2    train    train  validation  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6e88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17075, 9) (4269, 9) (100, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(17075, 9) (4269, 9) (100, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(17075, 9) (4269, 9) (100, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n"
     ]
    }
   ],
   "source": [
    "for k in range(k_folds):\n",
    "    train_subset = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'train']\n",
    "    val_subset   = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'validation']\n",
    "    test_subset  = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'test']\n",
    "\n",
    "    print(train_subset.shape, val_subset.shape, test_subset.shape)\n",
    "\n",
    "    print('test in train?: ', test_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "          'val in train?: ', val_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "          'val in test?: ', val_subset['ID'].isin(test_subset['ID']).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e25b1f",
   "metadata": {},
   "source": [
    "Notice if you want to redo, you must initialize the object `DataPipeline` again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377c4fe",
   "metadata": {},
   "source": [
    "Now it is **time to the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539e35af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ID', 'Label', 'Class', 'Band'], ['string', 'integer', 'string', 'integer'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.context_features, pipeline.context_features_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923c9a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:53:58,542 - INFO - Starting DataPipeline operations\n",
      "\n",
      "  0%|\u001b[38;2;0;255;0m                                                               \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "Processing fold 0/3:   0%|\u001b[38;2;0;255;0m                                          \u001b[0m| 0/3 [00:02<?, ?it/s]\u001b[0m\u001b[A2023-07-07 17:54:00.960448: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "2023-07-07 17:54:00.960481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (258e82d82bea): /proc/driver/nvidia/version does not exist\n",
      "2023-07-07 17:54:00.960747: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "Processing fold 0/3:  33%|\u001b[38;2;0;255;0m███████████▎                      \u001b[0m| 1/3 [00:11<00:22, 11.37s/it]\u001b[0m\u001b[A\n",
      "Processing fold 1/3:  33%|\u001b[38;2;0;255;0m███████████▎                      \u001b[0m| 1/3 [00:11<00:22, 11.37s/it]\u001b[0m\u001b[A\n",
      "Processing fold 1/3:  67%|\u001b[38;2;0;255;0m██████████████████████▋           \u001b[0m| 2/3 [00:20<00:10, 10.03s/it]\u001b[0m\u001b[A\n",
      "Processing fold 2/3:  67%|\u001b[38;2;0;255;0m██████████████████████▋           \u001b[0m| 2/3 [00:20<00:10, 10.03s/it]\u001b[0m\u001b[A\n",
      "Processing fold 2/3: 100%|\u001b[38;2;0;255;0m██████████████████████████████████\u001b[0m| 3/3 [00:29<00:00,  9.94s/it]\u001b[0m\u001b[A\n",
      "2023-07-07 17:54:28,354 - INFO - Finished execution of DataPipeline operations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 7.95 s, total: 39.6 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = pipeline.run(observations_path=OBSPATH, \n",
    "                   metadata_path=METAPATH,\n",
    "                   n_jobs=8,\n",
    "                   elements_per_shard=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b92d9",
   "metadata": {},
   "source": [
    "### Customize what happens within the preprocess function\n",
    "### (NOT WORKING YET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1231e7",
   "metadata": {},
   "source": [
    "You must keep the same parameters of the method i.e., `row, context_features, sequential_features`. \n",
    "\n",
    "Also the **output** should be tuple containing the lightcurve (`pd.DataFrame`) and the context values (`dict`)\n",
    "\n",
    "\n",
    "To modify the `process_sample` method we need to create a new class (`MyPipeline`) that inherits from `DataPipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f73c94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "class MyPipeline(DataPipeline):\n",
    "    @staticmethod\n",
    "    def preprocess(scan, id_column, sequential_features):\n",
    "        general_fn = pl.col(\"err\") < 1.  # Clean the data on the big lazy dataframe\n",
    "        \n",
    "        def lc_fn(lc):\n",
    "            lc = lc.sort('mjd') \n",
    "            lc = lc.lazy().with_column([\n",
    "        ( pl.col(\"value\") / pl.col(\"value\").first()).alias(\"mjd\")])\n",
    "        per_lc_fn  = lambda lc: lc_fn(lc) #mjd \n",
    "        \n",
    "        processed_obs = scan.filter(general_fn)\n",
    "        processed_obs = processed_obs.drop_nulls()\n",
    "        obs_grouped = processed_obs.groupby(id_column)\n",
    "        obs_grouped.apply(per_lc_fn, schema=None)\n",
    "        return processed_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534f698",
   "metadata": {},
   "source": [
    "Next steps are the same as using the original `DataPipeline` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3fb0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = MyPipeline(metadata=metadata,\n",
    "                             config_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "859de195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "test_metadata = metadata.sample(n=100)\n",
    "k_folds = 3\n",
    "custom_pipeline.train_val_test(val_frac=0.2, \n",
    "                               test_meta=[test_metadata]*k_folds, \n",
    "                               k_fold=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "817b9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 18:00:45,968 - INFO - Starting DataPipeline operations\n",
      "\n",
      "  0%|\u001b[38;2;0;255;0m                                                               \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "Processing fold 0/3:   0%|\u001b[38;2;0;255;0m                                          \u001b[0m| 0/3 [00:02<?, ?it/s]\u001b[0m\u001b[A\n",
      "Processing fold 0/3:  33%|\u001b[38;2;0;255;0m███████████▎                      \u001b[0m| 1/3 [00:11<00:22, 11.44s/it]\u001b[0m\u001b[A\n",
      "Processing fold 1/3:  33%|\u001b[38;2;0;255;0m███████████▎                      \u001b[0m| 1/3 [00:11<00:22, 11.44s/it]\u001b[0m\u001b[A\n",
      "Processing fold 1/3:  67%|\u001b[38;2;0;255;0m██████████████████████▋           \u001b[0m| 2/3 [00:20<00:09,  9.99s/it]\u001b[0m\u001b[A\n",
      "Processing fold 2/3:  67%|\u001b[38;2;0;255;0m██████████████████████▋           \u001b[0m| 2/3 [00:20<00:09,  9.99s/it]\u001b[0m\u001b[A\n",
      "Processing fold 2/3: 100%|\u001b[38;2;0;255;0m██████████████████████████████████\u001b[0m| 3/3 [00:29<00:00,  9.79s/it]\u001b[0m\u001b[A\n",
      "2023-07-07 18:01:15,355 - INFO - Finished execution of DataPipeline operations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 7.91 s, total: 39.2 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = custom_pipeline.run(observations_path=OBSPATH, \n",
    "                           metadata_path=METAPATH,\n",
    "                           n_jobs=8,\n",
    "                           elements_per_shard=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef30a7",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18cb81f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from src.data.record import deserialize\n",
    "import glob\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "622f6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/records_parquet/alcock/fold_0/train/'\n",
    "record_files = glob.glob(os.path.join(root, '*.record'))\n",
    "raw_dataset = tf.data.TFRecordDataset(record_files)\n",
    "raw_dataset = raw_dataset.map(lambda x: deserialize(x, root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76646211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[48823.78  48824.805 48825.805 48828.777 48829.746 48831.727 48832.723\n",
      "  48834.76  48835.652 48835.797 48836.75  48841.74  48842.777 48843.72\n",
      "  48851.746 48854.664 48855.812 48856.695 48884.69  48885.645 48887.77\n",
      "  48888.766 48894.77  48908.48  48915.633 48916.734 48917.55  48919.59\n",
      "  48927.516 48928.555 48929.504 48930.617 48931.516 48933.664 48935.66\n",
      "  48937.723 48938.547 48939.562 48941.617 48947.664 48948.72  48949.555\n",
      "  48964.7   48965.55  48966.543 48984.547 48985.562 48987.57  48988.543\n",
      "  48988.74  48989.56  48996.508 48998.51  48998.734 49000.527 49001.51\n",
      "  49001.707 49002.53  49006.52  49006.71  49007.566 49007.69  49014.71\n",
      "  49015.52  49015.637 49016.547 49016.67  49018.55  49018.676 49020.613\n",
      "  49021.53  49021.656 49025.64  49029.496 49032.516 49033.617 49036.72\n",
      "  49037.484 49040.574 49043.49  49043.61  49044.68  49045.477 49045.613\n",
      "  49046.664 49048.47  49048.605 49049.527 49049.67  49050.67  49053.594\n",
      "  49059.523 49060.504 49061.484 49062.48  49064.582 49065.547 49067.49\n",
      "  49067.605 49068.53  49069.508 49069.62  49074.484 49075.555 49076.535\n",
      "  49076.645 49077.492 49080.562 49082.53  49083.47  49086.484 49088.53\n",
      "  49089.51  49092.55  49094.445 49094.457 49095.45  49096.445 49096.477\n",
      "  49096.55  49097.453 49097.586 49098.445 49098.555 49099.434 49099.54\n",
      "  49100.434 49100.477 49100.54  49101.445 49103.44  49106.523 49107.457\n",
      "  49108.453 49111.508 49112.453 49114.44  49117.477 49118.418 49120.426\n",
      "  49122.457 49123.43  49124.43  49125.426 49126.438 49127.434 49134.43\n",
      "  49135.414 49140.434 49141.836 49142.82  49143.418 49143.82  49144.414\n",
      "  49144.84  49145.41  49145.83  49146.41  49151.824 49152.41  49152.83\n",
      "  49153.43  49154.414 49155.82  49156.38  49161.41  49161.824 49162.797\n",
      "  49169.844 49171.81  49180.75  49181.785 49182.816 49183.723 49184.688\n",
      "  49185.72  49186.715 49188.703 49189.707 49194.74  49196.72  49199.74\n",
      "  49201.668 49201.72  49203.69  49204.703 49208.676 49209.664 49210.676\n",
      "  49211.707 49214.81  49215.71  49216.637 49218.637 49219.66  49220.75\n",
      "  49221.63  49222.633 49223.64  49224.617 49233.6   49252.562 49254.664\n",
      "  49255.566 49256.605 49257.617 49260.574 49264.754 49265.54  49265.62\n",
      "  49266.633 49267.668 49268.582 49269.63  49270.62  49272.625 49273.527\n",
      "  49274.652 49277.684 49280.71  49282.58  49283.492 49285.72  49286.59\n",
      "  49287.586 49287.72  49289.582 49291.516 49302.64  49307.55  49309.582\n",
      "  49311.562 49312.574 49313.547 49315.527 49317.527 49318.668 49372.527\n",
      "  49375.53  49376.547 49377.66  49380.617 49381.664 49384.754 49386.53\n",
      "  49388.664 49390.516 49398.5   49399.496 49404.7   49405.645 49406.71\n",
      "  49409.613 49412.367 49413.7   49415.57  49416.59  49423.56  49424.527\n",
      "  49425.633 49426.53  49428.605 49434.598 49436.61  49438.582 49446.586\n",
      "  49448.508 49449.56  49450.543 49451.53  49452.586 49455.562 49457.516\n",
      "  49458.535 49460.496 49461.527 49462.492 49463.56  49464.496 49465.504\n",
      "  49466.52  49467.555 49472.555 49477.492 49478.496 49479.49  49481.543\n",
      "  49483.52  49485.504 49486.49  49487.516 49488.5   49489.46  49496.477\n",
      "  49498.824 49500.457 49511.82  49512.453 49514.44  49516.438 49517.816\n",
      "  49518.4   49519.37  49520.797 49522.836 49525.84  49527.39  49530.395\n",
      "  49531.82  49532.367 49533.375 49534.375 49536.375 49537.375 49538.707\n",
      "  49540.35  49541.36  49542.363 49546.355 49549.676 49550.734 49550.75\n",
      "  49552.695 49552.71  49553.668 49554.67  49555.715 49556.727 49557.797\n",
      "  49558.77  49559.71  49560.758 49562.793 49566.688 49567.73  49568.77\n",
      "  49569.727 49571.69  49572.72  49573.69  49574.69  49574.707 49577.668\n",
      "  49578.68  49579.688 49580.652 49581.69  49585.695 49586.688 49587.68\n",
      "  49588.72  49589.67  49590.652 49591.676 49592.65  49595.7   49596.703\n",
      "  49598.707 49601.785 49604.69  49605.68  49606.68  49607.586 49608.684\n",
      "  49609.703 49610.664 49611.664 49612.79  49614.664 49616.75  49617.64\n",
      "  49618.637 49619.65  49620.69  49622.754 49623.668 49625.707 49627.676\n",
      "  49628.71  49629.71  49630.637 49633.582 49634.57  49635.645 49636.63\n",
      "  49637.723 49639.633 49640.66  49642.59  49645.633 49645.65  49648.566\n",
      "  49649.56  49653.703 49654.66  49660.695 49665.617 49666.55  49667.684\n",
      "  49670.566 49672.656 49673.63  49673.742 49676.574 49687.61  49688.574\n",
      "  49689.63  49690.56  49691.605 49692.63  49695.61  49696.6   49697.625\n",
      "  49700.566 49702.723 49703.67  49704.58  49706.625 49716.477 49717.7\n",
      "  49723.58  49728.504 49729.742 49730.598 49733.555 49738.668 49741.656\n",
      "  49745.7   49747.656 49749.51  49751.574 49752.707 49755.434 49759.63\n",
      "  49761.727 49762.62  49764.758 49767.69  49784.562 49787.49  49788.637\n",
      "  49790.53  49795.53  49797.555 49799.523 49800.61  49801.55  49805.457\n",
      "  49806.555 49808.605 49809.58  49809.625 49810.598 49815.598 49818.47\n",
      "  49819.55  49825.46  49825.48  49826.55  49829.45  49829.477 49831.51\n",
      "  49836.504 49852.477 49857.465 49866.457 49869.418 49880.445 49887.82\n",
      "  49889.82  49891.824 49895.8   49917.836 49921.785 49927.7   49929.773\n",
      "  49932.66  49933.754 49935.797 49936.785 49937.8   49938.67  49939.7\n",
      "  49941.68  49942.754 49943.746 49944.785 49945.785 49947.73  49948.793\n",
      "  49949.65  49951.668 49953.562 49954.75  49957.613 49961.63  49965.67\n",
      "  49966.73  49967.742 49970.586 49972.64  49974.8   49980.625 49982.75\n",
      "  49986.656 49987.574 49994.6   49996.64  49997.695 49998.715 50003.65\n",
      "  50005.63  50006.617 50007.7   50013.582 50020.465 50021.684 50023.496\n",
      "  50029.562 50031.707 50038.637 50045.62  50046.633 50047.727 50057.59\n",
      "  50061.598 50063.566 50067.555 50071.555 50072.598 50076.543 50078.633\n",
      "  50078.656 50088.582 50089.58  50105.625 50107.645 50108.617 50109.637\n",
      "  50118.58  50123.58  50126.605 50127.613 50128.645 50131.59  50132.53\n",
      "  50134.508 50135.633 50141.527 50143.594 50151.566 50154.473 50157.566\n",
      "  50159.586 50170.61  50172.574 50173.64  50174.535 50179.51  50180.57\n",
      "  50181.543 50185.484 50188.484 50192.46  50196.527 50198.445 50200.484\n",
      "  50201.523 50212.453 50214.473 50216.45  50218.414 50219.453 50221.37\n",
      "  50223.504 50225.37  50227.418 50229.387 50232.418 50234.43  50238.83\n",
      "  50242.38  50244.375 50245.41  50247.426 50254.414 50255.816 50258.84\n",
      "  50259.812 50267.74  50271.8   50277.695 50278.78  50300.832 50302.71\n",
      "  50304.758 50307.69  50308.77  50310.812 50311.777 50320.734 50327.8\n",
      "  50328.707 50330.797 50333.785 50335.727 50342.754 50342.78  50348.574\n",
      "  50349.695 50350.67  50352.617 50353.62  50359.63  50364.543 50366.746\n",
      "  50368.582 50369.61  50370.59  50371.58  50374.59  50376.57  50377.598\n",
      "  50380.57  50384.67  50385.695 50389.543 50395.625 50397.496 50398.51\n",
      "  50399.703 50401.684 50405.547 50406.547 50407.582 50409.555 50410.656\n",
      "  50411.637 50412.69  50417.566 50419.6   50420.598 50422.72  50425.54\n",
      "  50426.594 50428.668 50431.574 50432.605 50433.664 50436.625 50437.58\n",
      "  50438.62  50440.53  50444.57  50445.652 50449.53  50450.715 50451.656\n",
      "  50452.613 50453.63  50455.523 50456.562 50457.566 50461.555 50462.56\n",
      "  50467.582 50468.6   50469.715 50478.547 50479.5   50483.56  50486.58\n",
      "  50493.605 50495.62  50498.48  50507.57  50518.598 50521.57  50526.496\n",
      "  50529.617 50533.54  50535.598 50541.527 50543.62  50547.457 50551.562\n",
      "  50554.47  50563.457 50566.535 50573.418 50577.508 50581.457 50595.44\n",
      "  50608.36  50614.82  50620.383 50636.688 50640.72  50642.76  50648.746\n",
      "  50652.758 50657.766 50660.66  50662.75  50669.773 50674.664 50677.793\n",
      "  50679.797 50681.68  50684.6   50687.246 50689.617 50700.67  50704.594\n",
      "  50713.703 50716.75  50718.74  50720.668 50721.715 50724.664 50726.492\n",
      "  50731.5   50732.67  50733.727 50735.54  50736.688 50737.76  50743.68\n",
      "  50746.7   50759.555 50767.73  50770.56  50774.66  50784.523 50793.527\n",
      "  50796.65  50802.594 50804.637 50809.48  50812.65  50825.543 50830.688\n",
      "  50834.715 50839.555 50841.652 50844.67  50849.438 50861.49  50862.71\n",
      "  50864.742 50866.656 50874.59  50878.61  50881.49  50883.617 50907.55\n",
      "  50910.492 50919.562 50933.49  50942.492 50968.46  51167.684 51167.71\n",
      "  51171.67  51176.637 51180.695 51183.64  51188.598 51193.727 51214.62\n",
      "  51224.6   51228.516 51240.523 51246.547 51249.523 51251.48  51260.54\n",
      "  51275.52  51279.4   51286.5   51289.42  51292.426 51299.453 51302.43\n",
      "  51308.414 51313.375 51317.434 51326.395 51339.387 51366.812 51383.727\n",
      "  51391.785 51401.777 51406.684 51410.766 51420.758 51423.777 51427.64\n",
      "  51432.656 51434.74  51439.625 51440.727 51444.777 51458.637 51462.68\n",
      "  51466.67  51470.71  51472.555 51477.56  51478.76  51482.58  51485.54\n",
      "  51489.57  51492.56  51494.633 51501.69  51510.71  51513.582 51514.72\n",
      "  51526.574 51531.617 51541.547 51546.527]], shape=(1, 823), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x in raw_dataset.take(1):\n",
    "    print(x['input'][..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f201252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
