{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e00616",
   "metadata": {},
   "source": [
    "# Creating records \n",
    "## Pipeline 2.0\n",
    "##### ASTROMER dev team\n",
    "\n",
    "*JAN 17 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c8403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb0e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from src.data.record import DataPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9dd79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METAPATH = './data/raw_data/alcock/metadata.csv'\n",
    "# LCDIR = 'LCs/' \n",
    "LCDIR = './data/raw_data/alcock/LCs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfb7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Class'] = pd.Categorical(metadata['Class'])\n",
    "metadata['Label'] = metadata['Class'].cat.codes\n",
    "metadata['Path'] = metadata['Path'].apply(lambda x: os.path.join(LCDIR, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234d8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>18.3210.910</td>\n",
       "      <td>RRab</td>\n",
       "      <td>./data/raw_data/alcock/LCs/18.3210.910.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Class                                        Path  Band  \\\n",
       "5798  18.3210.910  RRab  ./data/raw_data/alcock/LCs/18.3210.910.dat   1.0   \n",
       "\n",
       "      Label  \n",
       "5798      4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e25f5",
   "metadata": {},
   "source": [
    "### Using DataPipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a39da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "pipeline = DataPipeline(metadata=metadata, \n",
    "                        context_features=['ID', 'Label', 'Class'],\n",
    "                        sequential_features=['mjd', 'mag'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb1c534",
   "metadata": {},
   "source": [
    "To create training, validation, and testing splits we need to use the `train_val_test` method \n",
    "```\n",
    "train_val_test(val_frac=0.2,\n",
    "               test_frac=0.2,\n",
    "               test_meta=None,\n",
    "               val_meta=None,\n",
    "               shuffle=True,\n",
    "               id_column_name=None)\n",
    "``` \n",
    "where `val_frac` and `test_frac` are percentages containing the fraction of the metadata to be used as validation and testing subset respectively. Additionally, you can use `val_meta` and `test_meta` to use your preselected subset. **Notice that if you employ your own test/val subset, you should match one of the identifier columns of the main DataFrame** (by default it will assume the first column of the dataset is the identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d8ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = metadata.sample(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ddcc98",
   "metadata": {},
   "source": [
    "Don't worry about removing duplicated indices, the `train_val_test` method will do it for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b588fde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "pipeline.train_val_test(val_frac=0.2, test_meta=test_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63a339",
   "metadata": {},
   "source": [
    "Now our metadata will contain an extra-column `subset` for the corresponding subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36526fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13406</th>\n",
       "      <td>7.7655.582</td>\n",
       "      <td>RRab</td>\n",
       "      <td>./data/raw_data/alcock/LCs/7.7655.582.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11739</th>\n",
       "      <td>55.3616.278</td>\n",
       "      <td>RRc</td>\n",
       "      <td>./data/raw_data/alcock/LCs/55.3616.278.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20589</th>\n",
       "      <td>9.4518.64</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/9.4518.64.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID Class                                        Path  Band  \\\n",
       "13406   7.7655.582  RRab   ./data/raw_data/alcock/LCs/7.7655.582.dat   1.0   \n",
       "11739  55.3616.278   RRc  ./data/raw_data/alcock/LCs/55.3616.278.dat   1.0   \n",
       "20589    9.4518.64    EC    ./data/raw_data/alcock/LCs/9.4518.64.dat   1.0   \n",
       "\n",
       "       Label      subset  \n",
       "13406      4  validation  \n",
       "11739      5       train  \n",
       "20589      2  validation  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bdc659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17075, 6) (4269, 6) (100, 6)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n"
     ]
    }
   ],
   "source": [
    "train_subset = pipeline.metadata[pipeline.metadata['subset'] == 'train']\n",
    "val_subset   = pipeline.metadata[pipeline.metadata['subset'] == 'validation']\n",
    "test_subset  = pipeline.metadata[pipeline.metadata['subset'] == 'test']\n",
    "\n",
    "print(train_subset.shape, val_subset.shape, test_subset.shape)\n",
    "\n",
    "print('test in train?: ', test_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "      'val in train?: ', val_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "      'val in test?: ', val_subset['ID'].isin(test_subset['ID']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923c9a2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing data...\n",
      "[INFO] Writing records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/21444 [00:00<?, ?it/s]2023-01-17 15:12:58.726941: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "2023-01-17 15:12:58.726982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e1977df45e7c): /proc/driver/nvidia/version does not exist\n",
      "2023-01-17 15:12:58.727304: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "100%|████████████████████████████████████████████████| 21444/21444 [00:06<00:00, 3192.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 1.24 s, total: 23.5 s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba9ea5",
   "metadata": {},
   "source": [
    "### Customize the preprocessing method of DataPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9b782",
   "metadata": {},
   "source": [
    "You must keep the same parameters of the method i.e., `row, context_features, sequential_features`. \n",
    "\n",
    "Also the **output** should be tuple containing the lightcurve (`pd.DataFrame`) and the context values (`dict`)\n",
    "\n",
    "\n",
    "To modify the `process_sample` method we need to create a new class (`MyPipeline`) that inherits from `DataPipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4be98e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipeline(DataPipeline):\n",
    "    @staticmethod\n",
    "    def process_sample(row, context_features, sequential_features):\n",
    "        observations = pd.read_csv(row['Path'])\n",
    "        observations.columns = ['mjd', 'mag', 'errmag']\n",
    "        observations = observations.dropna()\n",
    "        observations.sort_values('mjd')\n",
    "        observations[observations['errmag'] < 1]\n",
    "        context_features_values = row[context_features]\n",
    "        return observations, context_features_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b5259",
   "metadata": {},
   "source": [
    "Next steps are the same as using the original `DataPipeline` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "600fdbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = MyPipeline(metadata=metadata, \n",
    "                             context_features=['ID', 'Label', 'Class'],\n",
    "                             sequential_features=['mjd', 'mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "817b9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing data...\n",
      "[INFO] Writing records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 21444/21444 [00:08<00:00, 2488.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 1.27 s, total: 23.4 s\n",
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = custom_pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0b7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e93f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e76b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc1b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
