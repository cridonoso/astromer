{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f82b6f2",
   "metadata": {},
   "source": [
    "# Creating records \n",
    "## Pipeline 2.0\n",
    "##### ASTROMER dev team\n",
    "\n",
    "*JAN 17 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb0e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from src.data.record import DataPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9dd79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METAPATH = './data/raw_data/alcock/metadata.csv'\n",
    "# LCDIR = 'LCs/' \n",
    "LCDIR = './data/raw_data/alcock/LCs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfb7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Class'] = pd.Categorical(metadata['Class'])\n",
    "metadata['Label'] = metadata['Class'].cat.codes\n",
    "metadata['Path'] = metadata['Path'].apply(lambda x: os.path.join(LCDIR, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234d8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21150</th>\n",
       "      <td>9.5245.1147</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/9.5245.1147.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID Class                                        Path  Band  \\\n",
       "21150  9.5245.1147    EC  ./data/raw_data/alcock/LCs/9.5245.1147.dat   1.0   \n",
       "\n",
       "       Label  \n",
       "21150      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039028e",
   "metadata": {},
   "source": [
    "### Using DataPipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a39da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "pipeline = DataPipeline(metadata=metadata, \n",
    "                        context_features=['ID', 'Label', 'Class'],\n",
    "                        sequential_features=['mjd', 'mag'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064aad8b",
   "metadata": {},
   "source": [
    "To create training, validation, and testing splits we need to use the `train_val_test` method \n",
    "```\n",
    "train_val_test(val_frac=0.2,\n",
    "               test_frac=0.2,\n",
    "               test_meta=None,\n",
    "               val_meta=None,\n",
    "               shuffle=True,\n",
    "               id_column_name=None)\n",
    "``` \n",
    "where `val_frac` and `test_frac` are percentages containing the fraction of the metadata to be used as validation and testing subset respectively. Additionally, you can use `val_meta` and `test_meta` to use your preselected subset. **Notice that if you employ your own test/val subset, you should match one of the identifier columns of the main DataFrame** (by default it will assume the first column of the dataset is the identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918c742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = metadata.sample(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85146592",
   "metadata": {},
   "source": [
    "Don't worry about removing duplicated indices, the `train_val_test` method will do it for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f193ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "pipeline.train_val_test(val_frac=0.2, test_meta=test_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcf6f3",
   "metadata": {},
   "source": [
    "Now our metadata will contain an extra-column `subset` for the corresponding subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f631c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "      <th>subset</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10698</th>\n",
       "      <td>5.4889.71</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/5.4889.71.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12780</th>\n",
       "      <td>6.6811.668</td>\n",
       "      <td>RRab</td>\n",
       "      <td>./data/raw_data/alcock/LCs/6.6811.668.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1.4171.110</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/1.4171.110.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Class                                       Path  Band  \\\n",
       "10698   5.4889.71    EC   ./data/raw_data/alcock/LCs/5.4889.71.dat   1.0   \n",
       "12780  6.6811.668  RRab  ./data/raw_data/alcock/LCs/6.6811.668.dat   1.0   \n",
       "481    1.4171.110    EC  ./data/raw_data/alcock/LCs/1.4171.110.dat   1.0   \n",
       "\n",
       "       Label subset  fold  \n",
       "10698      2  train     0  \n",
       "12780      4  train     0  \n",
       "481        2  train     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6e88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17075, 7) (4269, 7) (100, 7)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n"
     ]
    }
   ],
   "source": [
    "train_subset = pipeline.metadata[pipeline.metadata['subset'] == 'train']\n",
    "val_subset   = pipeline.metadata[pipeline.metadata['subset'] == 'validation']\n",
    "test_subset  = pipeline.metadata[pipeline.metadata['subset'] == 'test']\n",
    "\n",
    "print(train_subset.shape, val_subset.shape, test_subset.shape)\n",
    "\n",
    "print('test in train?: ', test_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "      'val in train?: ', val_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "      'val in test?: ', val_subset['ID'].isin(test_subset['ID']).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff341e1",
   "metadata": {},
   "source": [
    "For cross-validation purposes, we can also sample different folds from the same dataset by using `pipeline.resample_folds(n_folds=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2689a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating 2 random folds\n",
      "Not implemented yet hehehe...\n"
     ]
    }
   ],
   "source": [
    "pipeline.resample_folds(n_folds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fc1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3377c4fe",
   "metadata": {},
   "source": [
    "now it is time for running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923c9a2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writting test fold 0:   0%|\u001b[38;2;0;255;0m                                            \u001b[0m| 0/1 [00:27<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 1.36 s, total: 19.3 s\n",
      "Wall time: 27.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b92d9",
   "metadata": {},
   "source": [
    "### Customize the preprocessing method of DataPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1231e7",
   "metadata": {},
   "source": [
    "You must keep the same parameters of the method i.e., `row, context_features, sequential_features`. \n",
    "\n",
    "Also the **output** should be tuple containing the lightcurve (`pd.DataFrame`) and the context values (`dict`)\n",
    "\n",
    "\n",
    "To modify the `process_sample` method we need to create a new class (`MyPipeline`) that inherits from `DataPipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f73c94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipeline(DataPipeline):\n",
    "    @staticmethod\n",
    "    def process_sample(row, context_features, sequential_features):\n",
    "        observations = pd.read_csv(row['Path'])\n",
    "        observations.columns = ['mjd', 'mag', 'errmag']\n",
    "        observations = observations.dropna()\n",
    "        observations.sort_values('mjd')\n",
    "        observations[observations['errmag'] < 1]\n",
    "        context_features_values = row[context_features]\n",
    "        return observations, context_features_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534f698",
   "metadata": {},
   "source": [
    "Next steps are the same as using the original `DataPipeline` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3fb0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = MyPipeline(metadata=metadata, \n",
    "                             context_features=['ID', 'Label', 'Class'],\n",
    "                             sequential_features=['mjd', 'mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "817b9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing data...\n",
      "[INFO] Writing records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 21444/21444 [00:08<00:00, 2488.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 1.27 s, total: 23.4 s\n",
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = custom_pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0b7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb81f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f6480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
