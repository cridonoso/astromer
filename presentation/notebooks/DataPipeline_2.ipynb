{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f82b6f2",
   "metadata": {},
   "source": [
    "# Creating records \n",
    "## Pipeline 2.0\n",
    "##### ASTROMER dev team\n",
    "\n",
    "*JAN 17 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c8403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fb0e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from src.data.record import DataPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9dd79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METAPATH = './data/raw_data/alcock/metadata.csv'\n",
    "# LCDIR = 'LCs/' \n",
    "LCDIR = './data/raw_data/alcock/LCs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ff57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dfb7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Class'] = pd.Categorical(metadata['Class'])\n",
    "metadata['Label'] = metadata['Class'].cat.codes\n",
    "metadata['Path'] = metadata['Path'].apply(lambda x: os.path.join(LCDIR, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "234d8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19819</th>\n",
       "      <td>82.8166.96</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/82.8166.96.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Class                                       Path  Band  \\\n",
       "19819  82.8166.96    EC  ./data/raw_data/alcock/LCs/82.8166.96.dat   1.0   \n",
       "\n",
       "       Label  \n",
       "19819      2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039028e",
   "metadata": {},
   "source": [
    "### Using DataPipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a39da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "pipeline = DataPipeline(metadata=metadata, \n",
    "                        context_features=['ID', 'Label', 'Class'],\n",
    "                        sequential_features=['mjd', 'mag'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064aad8b",
   "metadata": {},
   "source": [
    "To create training, validation, and testing splits we need to use the `train_val_test` method \n",
    "```\n",
    "train_val_test(val_frac=0.2,\n",
    "               test_frac=0.2,\n",
    "               test_meta=None,\n",
    "               val_meta=None,\n",
    "               shuffle=True,\n",
    "               id_column_name=None,\n",
    "               k_fold=1)\n",
    "``` \n",
    "where `val_frac` and `test_frac` are percentages containing the fraction of the metadata to be used as validation and testing subset respectively. \n",
    "\n",
    "Additionally, you can use `val_meta` and `test_meta` to use a preselected subset. **Notice that if you employ your own test/val subset, you should match one of the identifier columns of the main DataFrame** (by default it will assume the first column of the dataset is the identifier). \n",
    "\n",
    "Both `test_meta` and `val_meta` must be list of `DataFrames`\n",
    "\n",
    "For cross-validation purposes, we can also sample different folds from the same dataset by using the `train_val_test(..., k_fold=1)` parameter.\n",
    "\n",
    "If $k>1$ and **you want to use a predefined test/val selection**, you should pass a list of `DataFrame`s associated with each `test_meta`/`val_meta` fold as appropriate.\n",
    "\n",
    "Don't worry about removing duplicated indices, the `train_val_test` method will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "918c742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = metadata.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f193ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "k_folds = 4\n",
    "\n",
    "pipeline.train_val_test(val_frac=0.2, \n",
    "                        test_meta=[test_metadata], \n",
    "                        k_fold=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "013795b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do 4-folds partitions have the same elements:  False\n",
      "Do 4-folds partitions have the same elements:  False\n",
      "Do 4-folds partitions have the same elements:  False\n"
     ]
    }
   ],
   "source": [
    "a = pipeline.metadata['subset_0']\n",
    "for k in range(k_folds):\n",
    "    if k == 0: continue\n",
    "    b = pipeline.metadata[f'subset_{k}']\n",
    "    c = np.array_equal(a[a != 'test'].values, b[b!= 'test'].values)\n",
    "    a = b\n",
    "    print('Do {}-folds partitions have the same elements: '.format(k_folds), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcf6f3",
   "metadata": {},
   "source": [
    "Now our metadata will contain an extra-column `subset` for the corresponding subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23f631c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>Label</th>\n",
       "      <th>subset_0</th>\n",
       "      <th>subset_1</th>\n",
       "      <th>subset_2</th>\n",
       "      <th>subset_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1.4296.203</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/1.4296.203.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>validation</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>12.10316.1458</td>\n",
       "      <td>RRc</td>\n",
       "      <td>./data/raw_data/alcock/LCs/12.10316.1458.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8608</th>\n",
       "      <td>23.4152.491</td>\n",
       "      <td>EC</td>\n",
       "      <td>./data/raw_data/alcock/LCs/23.4152.491.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID Class                                          Path  Band  \\\n",
       "569      1.4296.203    EC     ./data/raw_data/alcock/LCs/1.4296.203.dat   1.0   \n",
       "2400  12.10316.1458   RRc  ./data/raw_data/alcock/LCs/12.10316.1458.dat   1.0   \n",
       "8608    23.4152.491    EC    ./data/raw_data/alcock/LCs/23.4152.491.dat   1.0   \n",
       "\n",
       "      Label    subset_0 subset_1    subset_2 subset_3  \n",
       "569       2       train    train  validation     test  \n",
       "2400      5       train    train       train    train  \n",
       "8608      2  validation    train       train     test  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e6e88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17075, 9) (4269, 9) (100, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(13724, 9) (3431, 9) (4289, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(13724, 9) (3431, 9) (4289, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n",
      "(13724, 9) (3431, 9) (4289, 9)\n",
      "test in train?:  False \n",
      " val in train?:  False \n",
      " val in test?:  False\n"
     ]
    }
   ],
   "source": [
    "for k in range(k_folds):\n",
    "    train_subset = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'train']\n",
    "    val_subset   = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'validation']\n",
    "    test_subset  = pipeline.metadata[pipeline.metadata[f'subset_{k}'] == 'test']\n",
    "\n",
    "    print(train_subset.shape, val_subset.shape, test_subset.shape)\n",
    "\n",
    "    print('test in train?: ', test_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "          'val in train?: ', val_subset['ID'].isin(train_subset['ID']).all(),'\\n',\n",
    "          'val in test?: ', val_subset['ID'].isin(test_subset['ID']).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e25b1f",
   "metadata": {},
   "source": [
    "Notice if you want to redo, you must initialize the object `DataPipeline` again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377c4fe",
   "metadata": {},
   "source": [
    "Now it is **time to the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "923c9a2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writting test fold 3:   0%|\u001b[38;2;0;255;0m                                                                                                                                           \u001b[0m| 0/4 [01:46<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 5.82 s, total: 1min 16s\n",
      "Wall time: 1min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b92d9",
   "metadata": {},
   "source": [
    "### Customize the preprocessing method of DataPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1231e7",
   "metadata": {},
   "source": [
    "You must keep the same parameters of the method i.e., `row, context_features, sequential_features`. \n",
    "\n",
    "Also the **output** should be tuple containing the lightcurve (`pd.DataFrame`) and the context values (`dict`)\n",
    "\n",
    "\n",
    "To modify the `process_sample` method we need to create a new class (`MyPipeline`) that inherits from `DataPipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f73c94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipeline(DataPipeline):\n",
    "    @staticmethod\n",
    "    def process_sample(row, context_features, sequential_features):\n",
    "        observations = pd.read_csv(row['Path'])\n",
    "        observations.columns = ['mjd', 'mag', 'errmag']\n",
    "        observations = observations.dropna()\n",
    "        observations.sort_values('mjd')\n",
    "        observations[observations['errmag'] < 1]\n",
    "        context_features_values = row[context_features]\n",
    "        return observations, context_features_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534f698",
   "metadata": {},
   "source": [
    "Next steps are the same as using the original `DataPipeline` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3fb0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = MyPipeline(metadata=metadata, \n",
    "                             context_features=['ID', 'Label', 'Class'],\n",
    "                             sequential_features=['mjd', 'mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "817b9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing data...\n",
      "[INFO] Writing records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 21444/21444 [00:08<00:00, 2488.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 1.27 s, total: 23.4 s\n",
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = custom_pipeline.run(n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0b7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb81f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f6480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
