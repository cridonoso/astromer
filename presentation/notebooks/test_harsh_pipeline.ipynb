{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/astromer/presentation/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/astromer\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from src.data.record import DataPipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import polars as pl\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "# sys.path.append('/home/Samsung2TB/')\n",
    "# sys.path.append('/home/Samsung2TB/astromer/')\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from src.data.record import DataPipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from time import time\n",
    "import logging \n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local path\n",
    "local_path = '/home/ubuntu/astromer/data/raw_data/alcock/'\n",
    "\n",
    "# Define Metadata and LCDIR paths\n",
    "METAPATH = join(local_path, 'new_metadata.parquet')\n",
    "LCDIR =  join(local_path, 'parquets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>newID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3319.10</td>\n",
       "      <td>LPV</td>\n",
       "      <td>1.3319.10.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3441.15</td>\n",
       "      <td>Cep_0</td>\n",
       "      <td>1.3441.15.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3441.25</td>\n",
       "      <td>LPV</td>\n",
       "      <td>1.3441.25.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3441.45</td>\n",
       "      <td>Cep_0</td>\n",
       "      <td>1.3441.45.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3441.1031</td>\n",
       "      <td>RRab</td>\n",
       "      <td>1.3441.1031.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21439</th>\n",
       "      <td>9.5608.870</td>\n",
       "      <td>RRab</td>\n",
       "      <td>9.5608.870.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21439</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21440</th>\n",
       "      <td>9.5608.946</td>\n",
       "      <td>RRab</td>\n",
       "      <td>9.5608.946.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21441</th>\n",
       "      <td>9.5609.22</td>\n",
       "      <td>EC</td>\n",
       "      <td>9.5609.22.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21441</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>9.5609.790</td>\n",
       "      <td>RRab</td>\n",
       "      <td>9.5609.790.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21442</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21443</th>\n",
       "      <td>9.5609.798</td>\n",
       "      <td>RRab</td>\n",
       "      <td>9.5609.798.dat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21443</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21444 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Class             Path  Band  newID  Label\n",
       "0        1.3319.10    LPV    1.3319.10.dat   1.0      0      3\n",
       "1        1.3441.15  Cep_0    1.3441.15.dat   1.0      1      0\n",
       "2        1.3441.25    LPV    1.3441.25.dat   1.0      2      3\n",
       "3        1.3441.45  Cep_0    1.3441.45.dat   1.0      3      0\n",
       "4      1.3441.1031   RRab  1.3441.1031.dat   1.0      4      4\n",
       "...            ...    ...              ...   ...    ...    ...\n",
       "21439   9.5608.870   RRab   9.5608.870.dat   1.0  21439      4\n",
       "21440   9.5608.946   RRab   9.5608.946.dat   1.0  21440      4\n",
       "21441    9.5609.22     EC    9.5609.22.dat   1.0  21441      2\n",
       "21442   9.5609.790   RRab   9.5609.790.dat   1.0  21442      4\n",
       "21443   9.5609.798   RRab   9.5609.798.dat   1.0  21443      4\n",
       "\n",
       "[21444 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read metadata\n",
    "metadata = pd.read_parquet(METAPATH)\n",
    "metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process metadata\n",
    "metadata['Class'] = pd.Categorical(metadata['Class'])\n",
    "metadata['Label'] = metadata['Class'].cat.codes\n",
    "metadata['Path'] = metadata['Path'].apply(lambda x: os.path.join(LCDIR, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the metadata\n",
    "metadata_sample = metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Path</th>\n",
       "      <th>Band</th>\n",
       "      <th>newID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3319.10</td>\n",
       "      <td>LPV</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3441.15</td>\n",
       "      <td>Cep_0</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3441.25</td>\n",
       "      <td>LPV</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3441.45</td>\n",
       "      <td>Cep_0</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3441.1031</td>\n",
       "      <td>RRab</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21439</th>\n",
       "      <td>9.5608.870</td>\n",
       "      <td>RRab</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21439</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21440</th>\n",
       "      <td>9.5608.946</td>\n",
       "      <td>RRab</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21441</th>\n",
       "      <td>9.5609.22</td>\n",
       "      <td>EC</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21441</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>9.5609.790</td>\n",
       "      <td>RRab</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21442</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21443</th>\n",
       "      <td>9.5609.798</td>\n",
       "      <td>RRab</td>\n",
       "      <td>/home/ubuntu/astromer/data/raw_data/alcock/par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21443</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21444 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Class                                               Path  \\\n",
       "0        1.3319.10    LPV  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "1        1.3441.15  Cep_0  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "2        1.3441.25    LPV  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "3        1.3441.45  Cep_0  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "4      1.3441.1031   RRab  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "...            ...    ...                                                ...   \n",
       "21439   9.5608.870   RRab  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "21440   9.5608.946   RRab  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "21441    9.5609.22     EC  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "21442   9.5609.790   RRab  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "21443   9.5609.798   RRab  /home/ubuntu/astromer/data/raw_data/alcock/par...   \n",
       "\n",
       "       Band  newID  Label  \n",
       "0       1.0      0      3  \n",
       "1       1.0      1      0  \n",
       "2       1.0      2      3  \n",
       "3       1.0      3      0  \n",
       "4       1.0      4      4  \n",
       "...     ...    ...    ...  \n",
       "21439   1.0  21439      4  \n",
       "21440   1.0  21440      4  \n",
       "21441   1.0  21441      2  \n",
       "21442   1.0  21442      4  \n",
       "21443   1.0  21443      4  \n",
       "\n",
       "[21444 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 21444 samples loaded\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of DataPipeline\n",
    "myPipeline = DataPipeline(metadata=metadata_sample, \n",
    "                            context_features=['ID', 'Label', 'Class'],\n",
    "                            sequential_features=['mjd', 'mag'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using ID col as sample identifier\n",
      "[INFO] Shuffling\n",
      "[INFO] Shuffling\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare for k-fold cross-validation\n",
    "test_metadata = metadata_sample.sample(n=1000)\n",
    "k_folds = 2\n",
    "# Split the data into training, validation, and test sets\n",
    "myPipeline.train_val_test(val_frac=0.2, \n",
    "                        test_meta=[test_metadata], \n",
    "                        k_fold=k_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 13:42:28,802 - INFO - Starting the writing process for the config file.\n",
      "2023-06-21 13:42:28,804 - INFO - Config file written successfully to ./config.toml\n"
     ]
    }
   ],
   "source": [
    "# Save the configuration into a .toml file\n",
    "config_file = './config.toml'\n",
    "myPipeline.write_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]2023-06-21 13:42:30,130 - INFO - Reading parquet files\n",
      "2023-06-21 13:42:30,158 - INFO - Processing train subset_0\n",
      "Processing train subset_0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]2023-06-21 13:42:30,168 - INFO - Writting train fold 0\n",
      "Writting train fold 0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]    2023-06-21 13:42:30,170 - INFO - Processing validation subset_0\n",
      "Processing validation subset_0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]2023-06-21 13:42:30,175 - INFO - Writting validation fold 0\n",
      "Writting validation fold 0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]    2023-06-21 13:42:30,177 - INFO - Processing test subset_0\n",
      "Processing test subset_0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]  2023-06-21 13:42:30,181 - INFO - Writting test fold 0\n",
      "Writting test fold 0:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]    2023-06-21 13:42:30,184 - INFO - Processing train subset_1\n",
      "Processing train subset_1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]2023-06-21 13:42:30,190 - INFO - Writting train fold 1\n",
      "Writting train fold 1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]    2023-06-21 13:42:30,191 - INFO - Processing validation subset_1\n",
      "Processing validation subset_1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]2023-06-21 13:42:30,196 - INFO - Writting validation fold 1\n",
      "Writting validation fold 1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]    2023-06-21 13:42:30,198 - INFO - Processing test subset_1\n",
      "Processing test subset_1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]  2023-06-21 13:42:30,204 - INFO - Writting test fold 1\n",
      "Writting test fold 1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]    2023-06-21 13:42:30,206 - INFO - Finished execution of DataPipeline operations\n",
      "2023-06-21 13:42:30,207 - INFO - Starting the writing process for the config file.\n",
      "2023-06-21 13:42:30,208 - INFO - Config file written successfully to ./config.toml\n",
      "2023-06-21 13:42:30,208 - INFO - Config file written\n",
      "Writting test fold 1:   0%|\u001b[38;2;0;255;0m          \u001b[0m| 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08166670799255371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create TFRecord files and measure time taken\n",
    "a = time()\n",
    "var = myPipeline.run(LCDIR, METAPATH, n_jobs=2,)\n",
    "b = time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 13:42:42,726 - INFO - Starting to read the file from ./records/output/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 13:42:42.773458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:42.782311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:42.782899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:42.783933: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 13:42:42.784474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:42.785092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:42.785640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:43.448669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:43.449282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:43.449824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 13:42:43.450353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13791 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "2023-06-21 13:42:43,740 - INFO - Successfully read the file from ./records/output/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's read back the records and process them\n",
    "record_file = \"./records/output/\"\n",
    "# Read the .record file\n",
    "raw_dataset = myPipeline.open_and_read_record(record_file)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "record_files = glob.glob('/home/ubuntu/astromer/records/output/*.record')\n",
    "raw_dataset = tf.data.TFRecordDataset(record_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 13:42:51,636 - INFO - Reading config from file.\n",
      "2023-06-21 13:42:51,637 - INFO - Config read successfully.\n",
      "2023-06-21 13:42:51.642214: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: mjd\n",
      "Sequence: SparseTensor(indices=tf.Tensor([], shape=(0, 2), dtype=int64), values=tf.Tensor([], shape=(0,), dtype=float32), dense_shape=tf.Tensor([0 0], shape=(2,), dtype=int64))\n",
      "Dense sequence: []\n",
      "Casted sequence: []\n",
      "Key: mag\n",
      "Sequence: SparseTensor(indices=tf.Tensor([], shape=(0, 2), dtype=int64), values=tf.Tensor([], shape=(0,), dtype=float32), dense_shape=tf.Tensor([0 0], shape=(2,), dtype=int64))\n",
      "Dense sequence: []\n",
      "Casted sequence: []\n",
      "[<tf.Tensor: shape=(0, 0), dtype=float32, numpy=array([], shape=(0, 0), dtype=float32)>, <tf.Tensor: shape=(0, 0), dtype=float32, numpy=array([], shape=(0, 0), dtype=float32)>]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28498/1942238312.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprocessed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/astromer/src/data/record.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Stack sequence features along a new third dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_inp_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;31m# Add sequence to the input dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "from src.data.record import deserialize\n",
    "processed_data = []\n",
    "for raw_record in raw_dataset:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    processed_data.append(deserialize(example.SerializeToString()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_p38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
