<p align="center">
    <img src="./presentation/figures/branding/banner.png"> 
</p>

![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)

This is the latest source code of <b>Astromer</b> used by authors to run experiments and analysis. Use this code if you want to adapt or extend functionalities of <b>Astromer</b>. Our Python package contains a snapshot of this repository in its stable version. 

## About ASTROMER

ASTROMER is a deep learning model that can encode single-band light curves using internal representations. The encoding process consists of creating embeddings of light curves, which are features that summarize the variability of the brightness over time.   
<p align="center">
<img src="./presentation/figures/branding/astromer-arch-trans.png"> 
</p>
Training ASTROMER from scratch can be expensive. However, we provide pre-trained weights that can be used to load representations already adjusted on millions of samples. Users can then easily fine-tune the model on new data. Fine-tuning involves training the pre-trained model on new datasets, which are typically smaller than the pre-training dataset.

## Weights

| Version Tag | Pretraining data | Description | Test RMSE/R-square | Link |
| --- | --- | --- | --- | --- |
| v0 | MACHO | Paper's model | 0.147/0.80 | [Download Weights](https://github.com/astromer-science/weights/raw/main/macho_a0.zip)
| v1*  | MACHO | Mask token and residual connections. | 0.113/0.73 | [Download Weights](https://github.com/astromer-science/weights/raw/main/macho_a1.zip)

\* best performance up to date
## Directory tree
```
ðŸ“¦astromer
 â”£ ðŸ“‚data
 â”ƒ â”£ ðŸ“œ get_data.sh: download data (raw and preprocessed) from gdrive
 â”ƒ â”£ ðŸ“œ config.toml: config template for converting parquet to records
 â”ƒ â”— ðŸ“œ README.md: instructions how to use get_data.sh 
 â”£ ðŸ“‚ presentation: everything that depends on the model code (i.e., pipelines, figures, visualization notebooks...)
 â”ƒ â”£ ðŸ“‚ results: experiments folder
 â”ƒ â”£ ðŸ“‚ figures
 â”ƒ â”£ ðŸ“‚ notebooks: util notebooks to visualize data, model features and results
 â”ƒ â”£ ðŸ“‚ pipelines:
 â”ƒ â”ƒ â”— ðŸ“‚ pipeline_0
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ finetune.py: Script for running finetunining step on a pretrained model
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ classify.py: Script for running classification on a pretrained/finetuned model
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ utils.py: utils functions for pipeline_0
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ run-gpu-{ID}.bash: bash script to run the whole pipeline on several pre-trained models
 â”ƒ â”ƒ â”— ðŸ“‚ steps: functions that are invariant to the pipeline and will be always used 
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ load_data.py: functions to easily load records
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ metrics.py: functions to get general metrics and tensorboard logs 
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ model_design.py: function to easily load Astromer
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œ utils.py: function for custom training [DEPRECATED]
 â”ƒ â”ƒ â”— ðŸ“œ utils.py: useful and general functions to create pipelines
 â”ƒ â”£ ðŸ“‚ scripts:
 â”ƒ â”ƒ â”— ðŸ“œ create_records.py: Script for creating records. It assumes data is in parquet format using the standard structure.
 â”ƒ â”ƒ â”— ðŸ“œ create_sset.py: Script for creating pretraining subsets with different number of samples  
 â”ƒ â”ƒ â”— ðŸ“œ pretrain.py: Script for pretrain a model from scratch
 â”ƒ â”ƒ â”— ðŸ“œ test_model.py: Evaluate a pre-trained model on a testing set (tf.record)
 â”ƒ â”ƒ â”— ðŸ“œ to_parquet.py: Transform old-version raw data to new structure based on parquet files
 â”£ ðŸ“‚ src: Model source code
 â”ƒ â”— ðŸ“‚ data: functions related to data manipulation
 â”ƒ â”ƒ â”£ ðŸ“œ loaders.py: main script containing functions to load and format data
 â”ƒ â”ƒ â”£ ðŸ“œ masking.py: masking functions inspired on BERT training strategy
 â”ƒ â”ƒ â”£ ðŸ“œ preprocessing.py: general functions to standardize, cut windows, among others.
 â”ƒ â”ƒ â”— ðŸ“œ record.py: functions to create and load tensorflow record files
 â”ƒ â”ƒ â”— ðŸ“œ zero.py: old functions to load tf.records. [not being used in this implementation]
 â”ƒ â”— ðŸ“‚ layers: Custom layers used to build ASTROMER model
 â”ƒ â”ƒ â”£ ðŸ“œ attblock.py: Attention block definition. Each block contain self-attention heads, normalization and transformation layers.
 â”ƒ â”ƒ â”£ ðŸ“œ attention.py: Multi-head self-attention layers.
 â”ƒ â”ƒ â”£ ðŸ“œ custom_rnn.py: Normalized LSTM [not being used in this implementation].
 â”ƒ â”ƒ â”£ ðŸ“œ encoders.py: Astromer encoder definition. It also contains encoder alternatives that inherit from the parent class.
 â”ƒ â”ƒ â”£ ðŸ“œ input.py: Input transformation layers
 â”ƒ â”ƒ â”£ ðŸ“œ output.py: Layers that take the embeddings and project them to desired outputs (regression/classification)
 â”ƒ â”ƒ â”— ðŸ“œ positional.py: Positional encoder class
 â”ƒ â”— ðŸ“‚ losses
 â”ƒ â”ƒ â”£ ðŸ“œ bce.py: Masked binary cross-entropy (used with NSP)
 â”ƒ â”ƒ â”— ðŸ“œ rmse.py: Masked root mean square error
 â”ƒ â”— ðŸ“‚ metrics
 â”ƒ â”ƒ â”£ ðŸ“œ acc.py: masked accuracy
 â”ƒ â”ƒ â”— ðŸ“œ r2.py: masked r-square
 â”ƒ â”— ðŸ“‚ models: ASTROMER model architectures
 â”ƒ â”ƒ â”£ ðŸ“œ astromer_0.py: Astromer v0 (Donoso et.al. 2023)
 â”ƒ â”ƒ â”£ ðŸ“œ astromer_1.py: Astromer v1 (Donoso et.al. 2024 in PROGRESS)
 â”ƒ â”— ðŸ“‚ training
 â”ƒ â”ƒ â”— ðŸ“œ scheduler.py: Custom scheduler presented in https://arxiv.org/abs/1706.03762
 â”ƒ â”£ ðŸ“œ __init__.py
 â”ƒ â”— ðŸ“œ utils.py: universal functions to use on different ASTROMER modules
 â”£ ðŸ“œ .gitignore: files that should not be considered during a GitHub push
 â”£ ðŸ“œ requirements.txt: python dependencies
 â”— ðŸ“œ README.md: what you are currently reading
 ```
## Get started

Use conda to create a virtual environment, for example:
```
conda create -n astromer python==3.9
```
Then install all the python packages use `requirements.txt`
```
pip install -r requirements.txt
```


## Contributing

Contributions are always welcome!

Issues and featuring can be directly published in this repository
via [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests). 
Similarly, New pre-trained weights must be uploaded to the [weights repo](https://github.com/astromer-science/weights) using the same mechanism.
